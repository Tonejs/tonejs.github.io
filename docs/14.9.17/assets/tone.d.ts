// Generated by dts-bundle v0.7.3
// Dependencies for this module:
//   ../../../../standardized-audio-context

declare module 'tone' {
    export { getContext, setContext } from "tone/core/Global";
    export * from "tone/classes";
    export * from "tone/version";
    import { ToneAudioBuffer } from "tone/core/context/ToneAudioBuffer";
    export { start } from "tone/core/Global";
    import { Seconds } from "tone/core/type/Units";
    export { supported } from "tone/core/context/AudioContext";
    import type { TransportClass } from "tone/core/clock/Transport";
    import type { DestinationClass } from "tone/core/context/Destination";
    import type { DrawClass } from "tone/core/util/Draw";
    import type { ListenerClass } from "tone/core/context/Listener";
    /**
        * The current audio context time of the global {@link BaseContext}.
        * @see {@link Context.now}
        * @category Core
        */
    export function now(): Seconds;
    /**
        * The current audio context time of the global {@link Context} without the {@link Context.lookAhead}
        * @see {@link Context.immediate}
        * @category Core
        */
    export function immediate(): Seconds;
    /**
        * The Transport object belonging to the global Tone.js Context.
        * @see {@link TransportClass}
        * @category Core
        * @deprecated Use {@link getTransport} instead
        */
    export const Transport: TransportClass;
    /**
        * The Transport object belonging to the global Tone.js Context.
        * @see {@link TransportClass}
        * @category Core
        */
    export function getTransport(): TransportClass;
    /**
        * The Destination (output) belonging to the global Tone.js Context.
        * @see {@link DestinationClass}
        * @category Core
        * @deprecated Use {@link getDestination} instead
        */
    export const Destination: DestinationClass;
    /**
        * @deprecated Use {@link getDestination} instead
        */
    export const Master: DestinationClass;
    /**
        * The Destination (output) belonging to the global Tone.js Context.
        * @see {@link DestinationClass}
        * @category Core
        */
    export function getDestination(): DestinationClass;
    /**
        * The {@link ListenerClass} belonging to the global Tone.js Context.
        * @category Core
        * @deprecated Use {@link getListener} instead
        */
    export const Listener: ListenerClass;
    /**
        * The {@link ListenerClass} belonging to the global Tone.js Context.
        * @category Core
        */
    export function getListener(): ListenerClass;
    /**
        * Draw is used to synchronize the draw frame with the Transport's callbacks.
        * @see {@link DrawClass}
        * @category Core
        * @deprecated Use {@link getDraw} instead
        */
    export const Draw: DrawClass;
    /**
        * Get the singleton attached to the global context.
        * Draw is used to synchronize the draw frame with the Transport's callbacks.
        * @see {@link DrawClass}
        * @category Core
        */
    export function getDraw(): DrawClass;
    /**
        * A reference to the global context
        * @see {@link Context}
        * @deprecated Use {@link getContext} instead
        */
    export const context: import("./classes").BaseContext;
    /**
        * Promise which resolves when all of the loading promises are resolved.
        * Alias for static {@link ToneAudioBuffer.loaded} method.
        * @category Core
        */
    export function loaded(): Promise<void>;
    import { ToneAudioBuffers } from "tone/core/context/ToneAudioBuffers";
    import { ToneBufferSource } from "tone/source/buffer/ToneBufferSource";
    /** @deprecated Use {@link ToneAudioBuffer} */
    export const Buffer: typeof ToneAudioBuffer;
    /** @deprecated Use {@link ToneAudioBuffers} */
    export const Buffers: typeof ToneAudioBuffers;
    /** @deprecated Use {@link ToneBufferSource} */
    export const BufferSource: typeof ToneBufferSource;
}

declare module 'tone/core/Global' {
    import { AnyAudioContext } from "tone/core/context/AudioContext";
    import { BaseContext } from "tone/core/context/BaseContext";
    /**
        * Returns the default system-wide {@link Context}
        * @category Core
        */
    export function getContext(): BaseContext;
    /**
        * Set the default audio context
        * @param context
        * @param disposeOld Pass `true` if you don't need the old context to dispose it.
        * @category Core
        */
    export function setContext(context: BaseContext | AnyAudioContext, disposeOld?: boolean): void;
    /**
        * Most browsers will not play _any_ audio until a user
        * clicks something (like a play button). Invoke this method
        * on a click or keypress event handler to start the audio context.
        * More about the Autoplay policy
        * [here](https://developers.google.com/web/updates/2017/09/autoplay-policy-changes#webaudio)
        * @example
        * document.querySelector("button").addEventListener("click", async () => {
        * 	await Tone.start();
        * 	console.log("context started");
        * });
        * @category Core
        */
    export function start(): Promise<void>;
}

declare module 'tone/classes' {
    export * from "tone/core/index";
    export * from "tone/source/index";
    export * from "tone/signal/index";
    export * from "tone/instrument/index";
    export * from "tone/event/index";
    export * from "tone/effect/index";
    export * from "tone/component/index";
}

declare module 'tone/version' {
    export const version: string;
}

declare module 'tone/core/context/ToneAudioBuffer' {
    import { Tone } from "tone/core/Tone";
    import { Samples, Seconds } from "tone/core/type/Units";
    interface ToneAudioBufferOptions {
            url?: string | AudioBuffer | ToneAudioBuffer;
            reverse: boolean;
            onload: (buffer?: ToneAudioBuffer) => void;
            onerror: (error: Error) => void;
    }
    /**
        * AudioBuffer loading and storage. ToneAudioBuffer is used internally by all
        * classes that make requests for audio files such as Tone.Player,
        * Tone.Sampler and Tone.Convolver.
        * @example
        * const buffer = new Tone.ToneAudioBuffer("https://tonejs.github.io/audio/casio/A1.mp3", () => {
        * 	console.log("loaded");
        * });
        * @category Core
        */
    export class ToneAudioBuffer extends Tone {
            readonly name: string;
            /**
                * Callback when the buffer is loaded.
                */
            onload: (buffer: ToneAudioBuffer) => void;
            /**
                *
                * @param url The url to load, or the audio buffer to set.
                * @param onload A callback which is invoked after the buffer is loaded.
                *                           It's recommended to use `ToneAudioBuffer.on('load', callback)` instead
                *                           since it will give you a callback when _all_ buffers are loaded.
                * @param onerror The callback to invoke if there is an error
                */
            constructor(url?: string | ToneAudioBuffer | AudioBuffer, onload?: (buffer: ToneAudioBuffer) => void, onerror?: (error: Error) => void);
            constructor(options?: Partial<ToneAudioBufferOptions>);
            static getDefaults(): ToneAudioBufferOptions;
            /**
                * The sample rate of the AudioBuffer
                */
            get sampleRate(): number;
            /**
                * Pass in an AudioBuffer or ToneAudioBuffer to set the value of this buffer.
                */
            set(buffer: AudioBuffer | ToneAudioBuffer): this;
            /**
                * The audio buffer stored in the object.
                */
            get(): AudioBuffer | undefined;
            /**
                * Makes an fetch request for the selected url then decodes the file as an audio buffer.
                * Invokes the callback once the audio buffer loads.
                * @param url The url of the buffer to load. filetype support depends on the browser.
                * @returns A Promise which resolves with this ToneAudioBuffer
                */
            load(url: string): Promise<this>;
            /**
                * clean up
                */
            dispose(): this;
            /**
                * Set the audio buffer from the array.
                * To create a multichannel AudioBuffer, pass in a multidimensional array.
                * @param array The array to fill the audio buffer
                */
            fromArray(array: Float32Array | Float32Array[]): this;
            /**
                * Sums multiple channels into 1 channel
                * @param chanNum Optionally only copy a single channel from the array.
                */
            toMono(chanNum?: number): this;
            /**
                * Get the buffer as an array. Single channel buffers will return a 1-dimensional
                * Float32Array, and multichannel buffers will return multidimensional arrays.
                * @param channel Optionally only copy a single channel from the array.
                */
            toArray(channel?: number): Float32Array | Float32Array[];
            /**
                * Returns the Float32Array representing the PCM audio data for the specific channel.
                * @param  channel  The channel number to return
                * @return The audio as a TypedArray
                */
            getChannelData(channel: number): Float32Array;
            /**
                * Cut a subsection of the array and return a buffer of the
                * subsection. Does not modify the original buffer
                * @param start The time to start the slice
                * @param end The end time to slice. If none is given will default to the end of the buffer
                */
            slice(start: Seconds, end?: Seconds): ToneAudioBuffer;
            /**
                * If the buffer is loaded or not
                */
            get loaded(): boolean;
            /**
                * The duration of the buffer in seconds.
                */
            get duration(): Seconds;
            /**
                * The length of the buffer in samples
                */
            get length(): Samples;
            /**
                * The number of discrete audio channels. Returns 0 if no buffer is loaded.
                */
            get numberOfChannels(): number;
            /**
                * Reverse the buffer.
                */
            get reverse(): boolean;
            set reverse(rev: boolean);
            /**
                * A path which is prefixed before every url.
                */
            static baseUrl: string;
            /**
                * Create a ToneAudioBuffer from the array. To create a multichannel AudioBuffer,
                * pass in a multidimensional array.
                * @param array The array to fill the audio buffer
                * @return A ToneAudioBuffer created from the array
                */
            static fromArray(array: Float32Array | Float32Array[]): ToneAudioBuffer;
            /**
                * Creates a ToneAudioBuffer from a URL, returns a promise which resolves to a ToneAudioBuffer
                * @param  url The url to load.
                * @return A promise which resolves to a ToneAudioBuffer
                */
            static fromUrl(url: string): Promise<ToneAudioBuffer>;
            /**
                * All of the downloads
                */
            static downloads: Array<Promise<void>>;
            /**
                * Loads a url using fetch and returns the AudioBuffer.
                */
            static load(url: string): Promise<AudioBuffer>;
            /**
                * Checks a url's extension to see if the current browser can play that file type.
                * @param url The url/extension to test
                * @return If the file extension can be played
                * @static
                * @example
                * Tone.ToneAudioBuffer.supportsType("wav"); // returns true
                * Tone.ToneAudioBuffer.supportsType("path/to/file.wav"); // returns true
                */
            static supportsType(url: string): boolean;
            /**
                * Returns a Promise which resolves when all of the buffers have loaded
                */
            static loaded(): Promise<void>;
    }
    export {};
}

declare module 'tone/core/type/Units' {
    export * from "tone/core/type/NoteUnits";
    import { Note } from "tone/core/type/NoteUnits";
    /**
        * A number representing a time in seconds
        * @category Unit
        */
    export type Seconds = number;
    /**
        * A number used to measure the intensity of a sound on a logarithmic scale.
        * @category Unit
        */
    export type Decibels = number;
    /**
        * A number that is between [0, 1]
        * @category Unit
        */
    export type NormalRange = number;
    /**
        * A number that is between [-1, 1]
        * @category Unit
        */
    export type AudioRange = number;
    /**
        * Half-step note increments, i.e. 12 is an octave above the root. and 1 is a half-step up.
        * @category Unit
        */
    export type Interval = number;
    /**
        * A number representing the multiplication factor applied to a signal
        * @category Unit
        */
    export type GainFactor = number;
    /**
        * A number greater than or equal to 0.
        * @category Unit
        */
    export type Positive = number;
    /**
        * Represents a subdivision of a measure.
        * The number represents the subdivision. "t" represents a triplet. A "." add a half.
        * e.g. "4n" is a quarter note, "4t" is a quarter note triplet, and "4n." is a dotted quarter note.
        * @category Unit
        */
    export type Subdivision = "1m" | "1n" | "1n." | `${2 | 4 | 8 | 16 | 32 | 64 | 128 | 256}${"n" | "n." | "t"}` | "0";
    /**
        * A time object has a subdivision as the keys and a number as the values.
        * @example
        * Tone.Time({
        * 	"2n": 1,
        * 	"8n": 3
        * }).valueOf(); // 2n + 8n * 3
        * @category Unit
        */
    export type TimeObject = {
            [sub in Subdivision]?: number;
    };
    /**
        * Time can be described in a number of ways. Read more [Time](https://github.com/Tonejs/Tone.js/wiki/Time).
        * * Numbers, which will be taken literally as the time (in seconds).
        * * Notation, ("4n", "8t") describes time in BPM and time signature relative values.
        * * TransportTime, ("4:3:2") will also provide tempo and time signature relative times in the form BARS:QUARTERS:SIXTEENTHS.
        * * Frequency, ("8hz") is converted to the length of the cycle in seconds.
        * * Now-Relative, ("+1") prefix any of the above with "+" and it will be interpreted as "the current time plus whatever expression follows".
        * * Object, ({"4n" : 3, "8t" : -1}). The resulting time is equal to the sum of all of the keys multiplied by the values in the object.
        * * No Argument, for methods which accept time, no argument will be interpreted as "now" (i.e. the currentTime).
        * @category Unit
        */
    export type Time = string | Seconds | TimeObject | Subdivision;
    /**
        * Frequency can be described similar to time, except ultimately the
        * values are converted to frequency instead of seconds. A number
        * is taken literally as the value in hertz. Additionally any of the
        * Time encodings can be used. Note names in the form
        * of NOTE OCTAVE (i.e. C4) are also accepted and converted to their
        * frequency value.
        * @category Unit
        */
    export type Frequency = Subdivision | Note | string | Hertz;
    /**
        *
        * @category Unit
        */
    export type TimeSignature = number | number[];
    /**
        * TransportTime describes a position along the Transport's timeline. It is
        * similar to Time in that it uses all the same encodings, but TransportTime specifically
        * pertains to the Transport's timeline, which is startable, stoppable, loopable, and seekable.
        * [Read more](https://github.com/Tonejs/Tone.js/wiki/TransportTime)
        * @category Unit
        */
    export type TransportTime = Time;
    /**
        * Ticks are the basic subunit of the Transport. They are
        * the smallest unit of time that the Transport supports.
        * @category Unit
        */
    export type Ticks = number;
    /**
        * Beats per minute
        * @category Unit
        */
    export type BPM = number;
    /**
        * Angle between 0 and 360.
        * @category Unit
        */
    export type Degrees = number;
    /**
        * Angle between 0 and 2 * PI.
        * @category Unit
        */
    export type Radians = number;
    /**
        * A colon-separated representation of time in the form of
        * Bars:Beats:Sixteenths.
        * @category Unit
        */
    export type BarsBeatsSixteenths = `${number}:${number}:${number}`;
    /**
        * Sampling is the reduction of a continuous signal to a discrete signal.
        * Audio is typically sampled 44100 times per second.
        * @category Unit
        */
    export type Samples = number;
    /**
        * Hertz are a frequency representation defined as one cycle per second.
        * @category Unit
        */
    export type Hertz = number;
    /**
        * A Cent is 1/100th of a semitone.
        * e.g. a value of 50 cents would be halfway between two intervals.
        * @category Unit
        */
    export type Cents = number;
    /**
        * One millisecond is a thousandth of a second.
        * @category Unit
        */
    export type Milliseconds = number;
    /**
        * A value which is a power of 2
        * @category Unit
        */
    export type PowerOfTwo = number;
    /**
        * Map the unit name to a unit value
        */
    export interface UnitMap {
            number: number;
            decibels: Decibels;
            normalRange: NormalRange;
            audioRange: AudioRange;
            gain: GainFactor;
            positive: Positive;
            time: Time;
            frequency: Frequency;
            transportTime: TransportTime;
            ticks: Ticks;
            bpm: BPM;
            degrees: Degrees;
            radians: Radians;
            samples: Samples;
            hertz: Hertz;
            cents: Cents;
    }
    /**
        * All of the unit types
        * @category Unit
        */
    export type Unit = UnitMap[keyof UnitMap];
    /**
        * All of the unit names
        * @category Unit
        */
    export type UnitName = keyof UnitMap;
}

declare module 'tone/core/context/AudioContext' {
    /**
        * Create a new AudioContext
        */
    export function createAudioContext(options?: AudioContextOptions): AudioContext;
    /**
        * Create a new OfflineAudioContext
        */
    export function createOfflineAudioContext(channels: number, length: number, sampleRate: number): OfflineAudioContext;
    /**
        * Either the online or offline audio context
        */
    export type AnyAudioContext = AudioContext | OfflineAudioContext;
    /**
        * Interface for things that Tone.js adds to the window
        */
    interface ToneWindow extends Window {
            TONE_SILENCE_LOGGING?: boolean;
            TONE_DEBUG_CLASS?: string;
    }
    /**
        * A reference to the window object
        * @hidden
        */
    export const theWindow: ToneWindow | null;
    /**
        * If the browser has a window object which has an AudioContext
        * @hidden
        */
    export const hasAudioContext: boolean | null;
    export function createAudioWorkletNode(context: AnyAudioContext, name: string, options?: Partial<AudioWorkletNodeOptions>): AudioWorkletNode;
    /**
        * This promise resolves to a boolean which indicates if the
        * functionality is supported within the currently used browse.
        * Taken from [standardized-audio-context](https://github.com/chrisguttandin/standardized-audio-context#issupported)
        */
    export { isSupported as supported } from "standardized-audio-context";
}

declare module 'tone/core/clock/Transport' {
    import { TimeClass } from "tone/core/type/Time";
    import { PlaybackState } from "tone/core/util/StateTimeline";
    import { Signal } from "tone/signal/Signal";
    import { ToneWithContext, ToneWithContextOptions } from "tone/core/context/ToneWithContext";
    import { TransportTimeClass } from "tone/core/type/TransportTime";
    import { BarsBeatsSixteenths, BPM, NormalRange, Seconds, Subdivision, Ticks, Time, TimeSignature, TransportTime } from "tone/core/type/Units";
    import { Emitter } from "tone/core/util/Emitter";
    import { TickParam } from "tone/core/clock/TickParam";
    interface TransportOptions extends ToneWithContextOptions {
            bpm: BPM;
            swing: NormalRange;
            swingSubdivision: Subdivision;
            timeSignature: number;
            loopStart: Time;
            loopEnd: Time;
            ppq: number;
    }
    type TransportEventNames = "start" | "stop" | "pause" | "loop" | "loopEnd" | "loopStart" | "ticks";
    type TransportCallback = (time: Seconds) => void;
    /**
        * Transport for timing musical events.
        * Supports tempo curves and time changes. Unlike browser-based timing (setInterval, requestAnimationFrame)
        * Transport timing events pass in the exact time of the scheduled event
        * in the argument of the callback function. Pass that time value to the object
        * you're scheduling. <br><br>
        * A single transport is created for you when the library is initialized.
        * <br><br>
        * The transport emits the events: "start", "stop", "pause", and "loop" which are
        * called with the time of that event as the argument.
        *
        * @example
        * const osc = new Tone.Oscillator().toDestination();
        * // repeated event every 8th note
        * Tone.getTransport().scheduleRepeat((time) => {
        * 	// use the callback time to schedule events
        * 	osc.start(time).stop(time + 0.1);
        * }, "8n");
        * // transport must be started before it starts invoking events
        * Tone.getTransport().start();
        * @category Core
        */
    export class TransportClass extends ToneWithContext<TransportOptions> implements Emitter<TransportEventNames> {
            readonly name: string;
            /**
                * The Beats Per Minute of the Transport.
                * @example
                * const osc = new Tone.Oscillator().toDestination();
                * Tone.getTransport().bpm.value = 80;
                * // start/stop the oscillator every quarter note
                * Tone.getTransport().scheduleRepeat(time => {
                * 	osc.start(time).stop(time + 0.1);
                * }, "4n");
                * Tone.getTransport().start();
                * // ramp the bpm to 120 over 10 seconds
                * Tone.getTransport().bpm.rampTo(120, 10);
                */
            bpm: TickParam<"bpm">;
            constructor(options?: Partial<TransportOptions>);
            static getDefaults(): TransportOptions;
            /**
                * Schedule an event along the timeline.
                * @param callback The callback to be invoked at the time.
                * @param time The time to invoke the callback at.
                * @return The id of the event which can be used for canceling the event.
                * @example
                * // schedule an event on the 16th measure
                * Tone.getTransport().schedule((time) => {
                * 	// invoked on measure 16
                * 	console.log("measure 16!");
                * }, "16:0:0");
                */
            schedule(callback: TransportCallback, time: TransportTime | TransportTimeClass): number;
            /**
                * Schedule a repeated event along the timeline. The event will fire
                * at the `interval` starting at the `startTime` and for the specified
                * `duration`.
                * @param  callback   The callback to invoke.
                * @param  interval   The duration between successive callbacks. Must be a positive number.
                * @param  startTime  When along the timeline the events should start being invoked.
                * @param  duration How long the event should repeat.
                * @return  The ID of the scheduled event. Use this to cancel the event.
                * @example
                * const osc = new Tone.Oscillator().toDestination().start();
                * // a callback invoked every eighth note after the first measure
                * Tone.getTransport().scheduleRepeat((time) => {
                * 	osc.start(time).stop(time + 0.1);
                * }, "8n", "1m");
                */
            scheduleRepeat(callback: TransportCallback, interval: Time | TimeClass, startTime?: TransportTime | TransportTimeClass, duration?: Time): number;
            /**
                * Schedule an event that will be removed after it is invoked.
                * @param callback The callback to invoke once.
                * @param time The time the callback should be invoked.
                * @returns The ID of the scheduled event.
                */
            scheduleOnce(callback: TransportCallback, time: TransportTime | TransportTimeClass): number;
            /**
                * Clear the passed in event id from the timeline
                * @param eventId The id of the event.
                */
            clear(eventId: number): this;
            /**
                * Remove scheduled events from the timeline after
                * the given time. Repeated events will be removed
                * if their startTime is after the given time
                * @param after Clear all events after this time.
                */
            cancel(after?: TransportTime): this;
            /**
                * Returns the playback state of the source, either "started", "stopped", or "paused"
                */
            get state(): PlaybackState;
            /**
                * Start the transport and all sources synced to the transport.
                * @param  time The time when the transport should start.
                * @param  offset The timeline offset to start the transport.
                * @example
                * // start the transport in one second starting at beginning of the 5th measure.
                * Tone.getTransport().start("+1", "4:0:0");
                */
            start(time?: Time, offset?: TransportTime): this;
            /**
                * Stop the transport and all sources synced to the transport.
                * @param time The time when the transport should stop.
                * @example
                * Tone.getTransport().stop();
                */
            stop(time?: Time): this;
            /**
                * Pause the transport and all sources synced to the transport.
                */
            pause(time?: Time): this;
            /**
                * Toggle the current state of the transport. If it is
                * started, it will stop it, otherwise it will start the Transport.
                * @param  time The time of the event
                */
            toggle(time?: Time): this;
            /**
                * The time signature as just the numerator over 4.
                * For example 4/4 would be just 4 and 6/8 would be 3.
                * @example
                * // common time
                * Tone.getTransport().timeSignature = 4;
                * // 7/8
                * Tone.getTransport().timeSignature = [7, 8];
                * // this will be reduced to a single number
                * Tone.getTransport().timeSignature; // returns 3.5
                */
            get timeSignature(): TimeSignature;
            set timeSignature(timeSig: TimeSignature);
            /**
                * When the Transport.loop = true, this is the starting position of the loop.
                */
            get loopStart(): Time;
            set loopStart(startPosition: Time);
            /**
                * When the Transport.loop = true, this is the ending position of the loop.
                */
            get loopEnd(): Time;
            set loopEnd(endPosition: Time);
            /**
                * If the transport loops or not.
                */
            get loop(): boolean;
            set loop(loop: boolean);
            /**
                * Set the loop start and stop at the same time.
                * @example
                * // loop over the first measure
                * Tone.getTransport().setLoopPoints(0, "1m");
                * Tone.getTransport().loop = true;
                */
            setLoopPoints(startPosition: TransportTime, endPosition: TransportTime): this;
            /**
                * The swing value. Between 0-1 where 1 equal to the note + half the subdivision.
                */
            get swing(): NormalRange;
            set swing(amount: NormalRange);
            /**
                * Set the subdivision which the swing will be applied to.
                * The default value is an 8th note. Value must be less
                * than a quarter note.
                */
            get swingSubdivision(): Subdivision;
            set swingSubdivision(subdivision: Subdivision);
            /**
                * The Transport's position in Bars:Beats:Sixteenths.
                * Setting the value will jump to that position right away.
                */
            get position(): BarsBeatsSixteenths | Time;
            set position(progress: Time);
            /**
                * The Transport's position in seconds.
                * Setting the value will jump to that position right away.
                */
            get seconds(): Seconds;
            set seconds(s: Seconds);
            /**
                * The Transport's loop position as a normalized value. Always
                * returns 0 if the Transport.loop = false.
                */
            get progress(): NormalRange;
            /**
                * The Transport's current tick position.
                */
            get ticks(): Ticks;
            set ticks(t: Ticks);
            /**
                * Get the clock's ticks at the given time.
                * @param  time  When to get the tick value
                * @return The tick value at the given time.
                */
            getTicksAtTime(time?: Time): Ticks;
            /**
                * Return the elapsed seconds at the given time.
                * @param  time  When to get the elapsed seconds
                * @return  The number of elapsed seconds
                */
            getSecondsAtTime(time: Time): Seconds;
            /**
                * Pulses Per Quarter note. This is the smallest resolution
                * the Transport timing supports. This should be set once
                * on initialization and not set again. Changing this value
                * after other objects have been created can cause problems.
                */
            get PPQ(): number;
            set PPQ(ppq: number);
            /**
                * Returns the time aligned to the next subdivision
                * of the Transport. If the Transport is not started,
                * it will return 0.
                * Note: this will not work precisely during tempo ramps.
                * @param  subdivision  The subdivision to quantize to
                * @return  The context time of the next subdivision.
                * @example
                * // the transport must be started, otherwise returns 0
                * Tone.getTransport().start();
                * Tone.getTransport().nextSubdivision("4n");
                */
            nextSubdivision(subdivision?: Time): Seconds;
            /**
                * Attaches the signal to the tempo control signal so that
                * any changes in the tempo will change the signal in the same
                * ratio.
                *
                * @param signal
                * @param ratio Optionally pass in the ratio between the two signals.
                * 			Otherwise it will be computed based on their current values.
                */
            syncSignal(signal: Signal<any>, ratio?: number): this;
            /**
                * Unsyncs a previously synced signal from the transport's control.
                * @see {@link syncSignal}.
                */
            unsyncSignal(signal: Signal<any>): this;
            /**
                * Clean up.
                */
            dispose(): this;
            on: (event: TransportEventNames, callback: (...args: any[]) => void) => this;
            once: (event: TransportEventNames, callback: (...args: any[]) => void) => this;
            off: (event: TransportEventNames, callback?: ((...args: any[]) => void) | undefined) => this;
            emit: (event: any, ...args: any[]) => this;
    }
    export {};
}

declare module 'tone/core/context/Destination' {
    import { Volume } from "tone/component/channel/Volume";
    import { Decibels } from "tone/core/type/Units";
    import { Gain } from "tone/core/context/Gain";
    import { Param } from "tone/core/context/Param";
    import { ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    interface DestinationOptions extends ToneAudioNodeOptions {
            volume: Decibels;
            mute: boolean;
    }
    /**
        * A single master output which is connected to the
        * AudioDestinationNode (aka your speakers).
        * It provides useful conveniences such as the ability
        * to set the volume and mute the entire application.
        * It also gives you the ability to apply master effects to your application.
        *
        * @example
        * const oscillator = new Tone.Oscillator().start();
        * // the audio will go from the oscillator to the speakers
        * oscillator.connect(Tone.getDestination());
        * // a convenience for connecting to the master output is also provided:
        * oscillator.toDestination();
        * @category Core
        */
    export class DestinationClass extends ToneAudioNode<DestinationOptions> {
            readonly name: string;
            input: Volume;
            output: Gain;
            /**
                * The volume of the master output in decibels. -Infinity is silent, and 0 is no change.
                * @example
                * const osc = new Tone.Oscillator().toDestination();
                * osc.start();
                * // ramp the volume down to silent over 10 seconds
                * Tone.getDestination().volume.rampTo(-Infinity, 10);
                */
            volume: Param<"decibels">;
            constructor(options: Partial<DestinationOptions>);
            static getDefaults(): DestinationOptions;
            /**
                * Mute the output.
                * @example
                * const oscillator = new Tone.Oscillator().start().toDestination();
                * setTimeout(() => {
                * 	// mute the output
                * 	Tone.Destination.mute = true;
                * }, 1000);
                */
            get mute(): boolean;
            set mute(mute: boolean);
            /**
                * Add a master effects chain. NOTE: this will disconnect any nodes which were previously
                * chained in the master effects chain.
                * @param args All arguments will be connected in a row and the Master will be routed through it.
                * @example
                * // route all audio through a filter and compressor
                * const lowpass = new Tone.Filter(800, "lowpass");
                * const compressor = new Tone.Compressor(-18);
                * Tone.Destination.chain(lowpass, compressor);
                */
            chain(...args: Array<AudioNode | ToneAudioNode>): this;
            /**
                * The maximum number of channels the system can output
                * @example
                * console.log(Tone.Destination.maxChannelCount);
                */
            get maxChannelCount(): number;
            /**
                * Clean up
                */
            dispose(): this;
    }
    export {};
}

declare module 'tone/core/util/Draw' {
    import { ToneWithContext, ToneWithContextOptions } from "tone/core/context/ToneWithContext";
    import { Seconds, Time } from "tone/core/type/Units";
    /**
        * Draw is useful for synchronizing visuals and audio events.
        * Callbacks from Tone.Transport or any of the Tone.Event classes
        * always happen _before_ the scheduled time and are not synchronized
        * to the animation frame so they are not good for triggering tightly
        * synchronized visuals and sound. Draw makes it easy to schedule
        * callbacks using the AudioContext time and uses requestAnimationFrame.
        * @example
        * Tone.Transport.schedule((time) => {
        * 	// use the time argument to schedule a callback with Draw
        * 	Tone.Draw.schedule(() => {
        * 		// do drawing or DOM manipulation here
        * 		console.log(time);
        * 	}, time);
        * }, "+0.5");
        * Tone.Transport.start();
        * @category Core
        */
    export class DrawClass extends ToneWithContext<ToneWithContextOptions> {
            readonly name: string;
            /**
                * The duration after which events are not invoked.
                */
            expiration: Seconds;
            /**
                * The amount of time before the scheduled time
                * that the callback can be invoked. Default is
                * half the time of an animation frame (0.008 seconds).
                */
            anticipation: Seconds;
            /**
                * Schedule a function at the given time to be invoked
                * on the nearest animation frame.
                * @param  callback  Callback is invoked at the given time.
                * @param  time      The time relative to the AudioContext time to invoke the callback.
                * @example
                * Tone.Transport.scheduleRepeat(time => {
                * 	Tone.Draw.schedule(() => console.log(time), time);
                * }, 1);
                * Tone.Transport.start();
                */
            schedule(callback: () => void, time: Time): this;
            /**
                * Cancel events scheduled after the given time
                * @param  after  Time after which scheduled events will be removed from the scheduling timeline.
                */
            cancel(after?: Time): this;
            dispose(): this;
    }
}

declare module 'tone/core/context/Listener' {
    import { ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { Param } from "tone/core/context/Param";
    export interface ListenerOptions extends ToneAudioNodeOptions {
            positionX: number;
            positionY: number;
            positionZ: number;
            forwardX: number;
            forwardY: number;
            forwardZ: number;
            upX: number;
            upY: number;
            upZ: number;
    }
    /**
        * Tone.Listener is a thin wrapper around the AudioListener. Listener combined
        * with {@link Panner3D} makes up the Web Audio API's 3D panning system. Panner3D allows you
        * to place sounds in 3D and Listener allows you to navigate the 3D sound environment from
        * a first-person perspective. There is only one listener per audio context.
        */
    export class ListenerClass extends ToneAudioNode<ListenerOptions> {
            readonly name: string;
            /**
                * The listener has no inputs or outputs.
                */
            output: undefined;
            input: undefined;
            readonly positionX: Param;
            readonly positionY: Param;
            readonly positionZ: Param;
            readonly forwardX: Param;
            readonly forwardY: Param;
            readonly forwardZ: Param;
            readonly upX: Param;
            readonly upY: Param;
            readonly upZ: Param;
            static getDefaults(): ListenerOptions;
            dispose(): this;
    }
}

declare module 'tone/core/context/ToneAudioBuffers' {
    import { Tone } from "tone/core/Tone";
    import { ToneAudioBuffer } from "tone/core/context/ToneAudioBuffer";
    export interface ToneAudioBuffersUrlMap {
            [name: string]: string | AudioBuffer | ToneAudioBuffer;
            [name: number]: string | AudioBuffer | ToneAudioBuffer;
    }
    interface ToneAudioBuffersOptions {
            urls: ToneAudioBuffersUrlMap;
            onload: () => void;
            onerror?: (error: Error) => void;
            baseUrl: string;
    }
    /**
        * A data structure for holding multiple buffers in a Map-like datastructure.
        *
        * @example
        * const pianoSamples = new Tone.ToneAudioBuffers({
        * 	A1: "https://tonejs.github.io/audio/casio/A1.mp3",
        * 	A2: "https://tonejs.github.io/audio/casio/A2.mp3",
        * }, () => {
        * 	const player = new Tone.Player().toDestination();
        * 	// play one of the samples when they all load
        * 	player.buffer = pianoSamples.get("A2");
        * 	player.start();
        * });
        * @example
        * // To pass in additional parameters in the second parameter
        * const buffers = new Tone.ToneAudioBuffers({
        * 	 urls: {
        * 		 A1: "A1.mp3",
        * 		 A2: "A2.mp3",
        * 	 },
        * 	 onload: () => console.log("loaded"),
        * 	 baseUrl: "https://tonejs.github.io/audio/casio/"
        * });
        * @category Core
        */
    export class ToneAudioBuffers extends Tone {
            readonly name: string;
            /**
                * A path which is prefixed before every url.
                */
            baseUrl: string;
            /**
                * @param  urls  An object literal or array of urls to load.
                * @param onload  The callback to invoke when the buffers are loaded.
                * @param baseUrl A prefix url to add before all the urls
                */
            constructor(urls?: ToneAudioBuffersUrlMap, onload?: () => void, baseUrl?: string);
            constructor(options?: Partial<ToneAudioBuffersOptions>);
            static getDefaults(): ToneAudioBuffersOptions;
            /**
                * True if the buffers object has a buffer by that name.
                * @param  name  The key or index of the buffer.
                */
            has(name: string | number): boolean;
            /**
                * Get a buffer by name. If an array was loaded,
                * then use the array index.
                * @param  name  The key or index of the buffer.
                */
            get(name: string | number): ToneAudioBuffer;
            /**
                * If the buffers are loaded or not
                */
            get loaded(): boolean;
            /**
                * Add a buffer by name and url to the Buffers
                * @param  name      A unique name to give the buffer
                * @param  url  Either the url of the bufer, or a buffer which will be added with the given name.
                * @param  callback  The callback to invoke when the url is loaded.
                * @param  onerror  Invoked if the buffer can't be loaded
                */
            add(name: string | number, url: string | AudioBuffer | ToneAudioBuffer, callback?: () => void, onerror?: (e: Error) => void): this;
            dispose(): this;
    }
    export {};
}

declare module 'tone/source/buffer/ToneBufferSource' {
    import { Param } from "tone/core/context/Param";
    import { ToneAudioBuffer } from "tone/core/context/ToneAudioBuffer";
    import { GainFactor, Positive, Seconds, Time } from "tone/core/type/Units";
    import { OneShotSource, OneShotSourceCurve, OneShotSourceOptions } from "tone/source/OneShotSource";
    export type ToneBufferSourceCurve = OneShotSourceCurve;
    export interface ToneBufferSourceOptions extends OneShotSourceOptions {
            url: string | AudioBuffer | ToneAudioBuffer;
            curve: ToneBufferSourceCurve;
            playbackRate: Positive;
            fadeIn: Time;
            fadeOut: Time;
            loopStart: Time;
            loopEnd: Time;
            loop: boolean;
            onload: () => void;
            onerror: (error: Error) => void;
    }
    /**
        * Wrapper around the native BufferSourceNode.
        * @category Source
        */
    export class ToneBufferSource extends OneShotSource<ToneBufferSourceOptions> {
            readonly name: string;
            protected _internalChannels: AudioBufferSourceNode[];
            /**
                * The frequency of the oscillator
                */
            readonly playbackRate: Param<"positive">;
            /**
                * @param url The buffer to play or url to load
                * @param onload The callback to invoke when the buffer is done playing.
                */
            constructor(url?: ToneAudioBuffer | AudioBuffer | string, onload?: () => void);
            constructor(options?: Partial<ToneBufferSourceOptions>);
            static getDefaults(): ToneBufferSourceOptions;
            /**
                * The fadeIn time of the amplitude envelope.
                */
            get fadeIn(): Time;
            set fadeIn(t: Time);
            /**
                * The fadeOut time of the amplitude envelope.
                */
            get fadeOut(): Time;
            set fadeOut(t: Time);
            /**
                * The curve applied to the fades, either "linear" or "exponential"
                */
            get curve(): ToneBufferSourceCurve;
            set curve(t: ToneBufferSourceCurve);
            /**
                * Start the buffer
                * @param  time When the player should start.
                * @param  offset The offset from the beginning of the sample to start at.
                * @param  duration How long the sample should play. If no duration is given, it will default to the full length of the sample (minus any offset)
                * @param  gain  The gain to play the buffer back at.
                */
            start(time?: Time, offset?: Time, duration?: Time, gain?: GainFactor): this;
            protected _stopSource(time?: Seconds): void;
            /**
                * If loop is true, the loop will start at this position.
                */
            get loopStart(): Time;
            set loopStart(loopStart: Time);
            /**
                * If loop is true, the loop will end at this position.
                */
            get loopEnd(): Time;
            set loopEnd(loopEnd: Time);
            /**
                * The audio buffer belonging to the player.
                */
            get buffer(): ToneAudioBuffer;
            set buffer(buffer: ToneAudioBuffer);
            /**
                * If the buffer should loop once it's over.
                */
            get loop(): boolean;
            set loop(loop: boolean);
            /**
                * Clean up.
                */
            dispose(): this;
    }
}

declare module 'tone/core/context/BaseContext' {
    import { Seconds } from "tone/core/type/Units";
    import { Emitter } from "tone/core/util/Emitter";
    import { AnyAudioContext } from "tone/core/context/AudioContext";
    type Draw = import("../util/Draw").DrawClass;
    type Destination = import("./Destination").DestinationClass;
    type Transport = import("../clock/Transport").TransportClass;
    type Listener = import("./Listener").ListenerClass;
    export type ExcludedFromBaseAudioContext = "onstatechange" | "addEventListener" | "removeEventListener" | "listener" | "dispatchEvent" | "audioWorklet" | "destination" | "createScriptProcessor";
    export type BaseAudioContextSubset = Omit<BaseAudioContext, ExcludedFromBaseAudioContext>;
    export type ContextLatencyHint = AudioContextLatencyCategory;
    export abstract class BaseContext extends Emitter<"statechange" | "tick"> implements BaseAudioContextSubset {
        abstract createAnalyser(): AnalyserNode;
        abstract createOscillator(): OscillatorNode;
        abstract createBufferSource(): AudioBufferSourceNode;
        abstract createBiquadFilter(): BiquadFilterNode;
        abstract createBuffer(_numberOfChannels: number, _length: number, _sampleRate: number): AudioBuffer;
        abstract createChannelMerger(_numberOfInputs?: number | undefined): ChannelMergerNode;
        abstract createChannelSplitter(_numberOfOutputs?: number | undefined): ChannelSplitterNode;
        abstract createConstantSource(): ConstantSourceNode;
        abstract createConvolver(): ConvolverNode;
        abstract createDelay(_maxDelayTime?: number | undefined): DelayNode;
        abstract createDynamicsCompressor(): DynamicsCompressorNode;
        abstract createGain(): GainNode;
        abstract createIIRFilter(_feedForward: number[] | Float32Array, _feedback: number[] | Float32Array): IIRFilterNode;
        abstract createPanner(): PannerNode;
        abstract createPeriodicWave(_real: number[] | Float32Array, _imag: number[] | Float32Array, _constraints?: PeriodicWaveConstraints | undefined): PeriodicWave;
        abstract createStereoPanner(): StereoPannerNode;
        abstract createWaveShaper(): WaveShaperNode;
        abstract createMediaStreamSource(_stream: MediaStream): MediaStreamAudioSourceNode;
        abstract createMediaElementSource(_element: HTMLMediaElement): MediaElementAudioSourceNode;
        abstract createMediaStreamDestination(): MediaStreamAudioDestinationNode;
        abstract decodeAudioData(_audioData: ArrayBuffer): Promise<AudioBuffer>;
        abstract createAudioWorkletNode(_name: string, _options?: Partial<AudioWorkletNodeOptions>): AudioWorkletNode;
        abstract get rawContext(): AnyAudioContext;
        abstract addAudioWorkletModule(_url: string): Promise<void>;
        abstract lookAhead: number;
        abstract latencyHint: ContextLatencyHint | Seconds;
        abstract resume(): Promise<void>;
        abstract setTimeout(_fn: (...args: any[]) => void, _timeout: Seconds): number;
        abstract clearTimeout(_id: number): this;
        abstract setInterval(_fn: (...args: any[]) => void, _interval: Seconds): number;
        abstract clearInterval(_id: number): this;
        abstract getConstant(_val: number): AudioBufferSourceNode;
        abstract get currentTime(): Seconds;
        abstract get state(): AudioContextState;
        abstract get sampleRate(): number;
        abstract get listener(): Listener;
        abstract get transport(): Transport;
        abstract get draw(): Draw;
        abstract get destination(): Destination;
        abstract now(): Seconds;
        abstract immediate(): Seconds;
        toJSON(): Record<string, any>;
        readonly isOffline: boolean;
    }
    export {};
}

declare module 'tone/core/index' {
    export * from "tone/core/clock/Clock";
    export * from "tone/core/context/Context";
    export * from "tone/core/context/BaseContext";
    export * from "tone/core/context/Delay";
    export * from "tone/core/context/Gain";
    export * from "tone/core/context/Offline";
    export * from "tone/core/context/OfflineContext";
    export * from "tone/core/context/Param";
    export * from "tone/core/context/ToneAudioBuffer";
    export * from "tone/core/context/ToneAudioBuffers";
    export * from "tone/core/context/ToneAudioNode";
    export * from "tone/core/type/Frequency";
    export * from "tone/core/type/Midi";
    export * from "tone/core/type/Time";
    export * from "tone/core/type/Ticks";
    export * from "tone/core/type/TransportTime";
    import "./util/Draw";
    export * from "tone/core/util/Emitter";
    export * from "tone/core/util/IntervalTimeline";
    export * from "tone/core/util/StateTimeline";
    export * from "tone/core/util/Timeline";
    export * from "tone/core/util/TypeCheck";
    export { dbToGain, gainToDb, intervalToFrequencyRatio, ftom, mtof } from "tone/core/type/Conversions";
    export { optionsFromArguments, defaultArg } from "tone/core/util/Defaults";
    import * as Unit from "tone/core/type/Units";
    export { Unit };
    import * as debug from "tone/core/util/Debug";
    /** @internal */
    export { debug };
}

declare module 'tone/source/index' {
    export * from "tone/source/Noise";
    export * from "tone/source/UserMedia";
    export * from "tone/source/oscillator/Oscillator";
    export * from "tone/source/oscillator/AMOscillator";
    export * from "tone/source/oscillator/FMOscillator";
    export * from "tone/source/oscillator/PulseOscillator";
    export * from "tone/source/oscillator/FatOscillator";
    export * from "tone/source/oscillator/PWMOscillator";
    export * from "tone/source/oscillator/OmniOscillator";
    export * from "tone/source/oscillator/ToneOscillatorNode";
    export * from "tone/source/oscillator/LFO";
    export * from "tone/source/buffer/ToneBufferSource";
    export * from "tone/source/buffer/Player";
    export * from "tone/source/buffer/Players";
    export * from "tone/source/buffer/GrainPlayer";
}

declare module 'tone/signal/index' {
    export * from "tone/signal/Add";
    export * from "tone/signal/Abs";
    export * from "tone/signal/AudioToGain";
    export * from "tone/signal/GainToAudio";
    export * from "tone/signal/GreaterThan";
    export * from "tone/signal/GreaterThanZero";
    export * from "tone/signal/Multiply";
    export * from "tone/signal/Negate";
    export * from "tone/signal/Pow";
    export * from "tone/signal/Signal";
    export * from "tone/signal/Scale";
    export * from "tone/signal/ScaleExp";
    export * from "tone/signal/Subtract";
    export * from "tone/signal/SyncedSignal";
    export * from "tone/signal/WaveShaper";
    export * from "tone/signal/Zero";
}

declare module 'tone/instrument/index' {
    export * from "tone/instrument/AMSynth";
    export * from "tone/instrument/DuoSynth";
    export * from "tone/instrument/FMSynth";
    export * from "tone/instrument/MetalSynth";
    export * from "tone/instrument/MembraneSynth";
    export * from "tone/instrument/MonoSynth";
    export * from "tone/instrument/NoiseSynth";
    export * from "tone/instrument/PluckSynth";
    export * from "tone/instrument/PolySynth";
    export * from "tone/instrument/Sampler";
    export * from "tone/instrument/Synth";
}

declare module 'tone/event/index' {
    export * from "tone/event/Loop";
    export * from "tone/event/Part";
    export * from "tone/event/Pattern";
    export * from "tone/event/Sequence";
    export * from "tone/event/ToneEvent";
}

declare module 'tone/effect/index' {
    export * from "tone/effect/AutoFilter";
    export * from "tone/effect/AutoPanner";
    export * from "tone/effect/AutoWah";
    export * from "tone/effect/BitCrusher";
    export * from "tone/effect/Chebyshev";
    export * from "tone/effect/Chorus";
    export * from "tone/effect/Distortion";
    export * from "tone/effect/FeedbackDelay";
    export * from "tone/effect/FrequencyShifter";
    export * from "tone/effect/Freeverb";
    export * from "tone/effect/JCReverb";
    export * from "tone/effect/PingPongDelay";
    export * from "tone/effect/PitchShift";
    export * from "tone/effect/Phaser";
    export * from "tone/effect/Reverb";
    export * from "tone/effect/StereoWidener";
    export * from "tone/effect/Tremolo";
    export * from "tone/effect/Vibrato";
}

declare module 'tone/component/index' {
    export * from "tone/component/analysis/Analyser";
    export * from "tone/component/analysis/Meter";
    export * from "tone/component/analysis/FFT";
    export * from "tone/component/analysis/DCMeter";
    export * from "tone/component/analysis/Waveform";
    export * from "tone/component/analysis/Follower";
    export * from "tone/component/channel/Channel";
    export * from "tone/component/channel/CrossFade";
    export * from "tone/component/channel/Merge";
    export * from "tone/component/channel/MidSideMerge";
    export * from "tone/component/channel/MidSideSplit";
    export * from "tone/component/channel/Mono";
    export * from "tone/component/channel/MultibandSplit";
    export * from "tone/component/channel/Panner";
    export * from "tone/component/channel/Panner3D";
    export * from "tone/component/channel/PanVol";
    export * from "tone/component/channel/Recorder";
    export * from "tone/component/channel/Solo";
    export * from "tone/component/channel/Split";
    export * from "tone/component/channel/Volume";
    export * from "tone/component/dynamics/Compressor";
    export * from "tone/component/dynamics/Gate";
    export * from "tone/component/dynamics/Limiter";
    export * from "tone/component/dynamics/MidSideCompressor";
    export * from "tone/component/dynamics/MultibandCompressor";
    export * from "tone/component/envelope/AmplitudeEnvelope";
    export * from "tone/component/envelope/Envelope";
    export * from "tone/component/envelope/FrequencyEnvelope";
    export * from "tone/component/filter/EQ3";
    export * from "tone/component/filter/Filter";
    export * from "tone/component/filter/OnePoleFilter";
    export * from "tone/component/filter/FeedbackCombFilter";
    export * from "tone/component/filter/LowpassCombFilter";
    export * from "tone/component/filter/Convolver";
    export * from "tone/component/filter/BiquadFilter";
}

declare module 'tone/core/Tone' {
    export interface BaseToneOptions {
    }
    /**
        * Tone is the base class of all other classes.
        *
        * @category Core
        * @constructor
        */
    export abstract class Tone {
            /**
                * The version number semver
                */
            static version: string;
            /**
                * The name of the class
                */
            protected abstract name: string;
            /**
                * Returns all of the default options belonging to the class.
                */
            static getDefaults(): BaseToneOptions;
            /**
                * Set this debug flag to log all events that happen in this class.
                */
            debug: boolean;
            /**
                * Prints the outputs to the console log for debugging purposes.
                * Prints the contents only if either the object has a property
                * called `debug` set to true, or a variable called TONE_DEBUG_CLASS
                * is set to the name of the class.
                * @example
                * const osc = new Tone.Oscillator();
                * // prints all logs originating from this oscillator
                * osc.debug = true;
                * // calls to start/stop will print in the console
                * osc.start();
                */
            protected log(...args: any[]): void;
            /**
                * disconnect and dispose.
                */
            dispose(): this;
            /**
                * Indicates if the instance was disposed. 'Disposing' an
                * instance means that all of the Web Audio nodes that were
                * created for the instance are disconnected and freed for garbage collection.
                */
            get disposed(): boolean;
            /**
                * Convert the class to a string
                * @example
                * const osc = new Tone.Oscillator();
                * console.log(osc.toString());
                */
            toString(): string;
    }
}

declare module 'tone/core/type/NoteUnits' {
    type Letter = "C" | "D" | "E" | "F" | "G" | "A" | "B";
    type Accidental = "bb" | "b" | "" | "#" | "x";
    type Octave = -4 | -3 | -2 | -1 | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11;
    /**
        * A note in Scientific pitch notation.
        * The pitch class + octave number
        * e.g. "C4", "D#3", "G-1"
        * @category Unit
        */
    export type Note = `${Letter}${Accidental}${Octave}`;
    type IntegerRange<N extends number, A extends any[] = []> = A["length"] extends N ? A[number] : IntegerRange<N, [...A, A["length"]]>;
    /**
        * A number representing a midi note. Integers between 0-127
        * @category Unit
        */
    export type MidiNote = IntegerRange<128>;
    export {};
}

declare module 'tone/core/type/Time' {
    import { TimeBaseClass, TimeBaseUnit, TimeExpression, TimeValue } from "tone/core/type/TimeBase";
    import { BarsBeatsSixteenths, MidiNote, Seconds, Subdivision, Ticks, Time } from "tone/core/type/Units";
    /**
        * TimeClass is a primitive type for encoding and decoding Time values.
        * TimeClass can be passed into the parameter of any method which takes time as an argument.
        * @param  val    The time value.
        * @param  units  The units of the value.
        * @example
        * const time = Tone.Time("4n"); // a quarter note
        * @category Unit
        */
    export class TimeClass<Type extends Seconds | Ticks = Seconds, Unit extends string = TimeBaseUnit> extends TimeBaseClass<Type, Unit> {
            readonly name: string;
            protected _getExpressions(): TimeExpression<Type>;
            /**
                * Quantize the time by the given subdivision. Optionally add a
                * percentage which will move the time value towards the ideal
                * quantized value by that percentage.
                * @param  subdiv    The subdivision to quantize to
                * @param  percent  Move the time value towards the quantized value by a percentage.
                * @example
                * Tone.Time(21).quantize(2); // returns 22
                * Tone.Time(0.6).quantize("4n", 0.5); // returns 0.55
                */
            quantize(subdiv: Time, percent?: number): Type;
            /**
                * Convert a Time to Notation. The notation values are will be the
                * closest representation between 1m to 128th note.
                * @return {Notation}
                * @example
                * // if the Transport is at 120bpm:
                * Tone.Time(2).toNotation(); // returns "1m"
                */
            toNotation(): Subdivision;
            /**
                * Return the time encoded as Bars:Beats:Sixteenths.
                */
            toBarsBeatsSixteenths(): BarsBeatsSixteenths;
            /**
                * Return the time in ticks.
                */
            toTicks(): Ticks;
            /**
                * Return the time in seconds.
                */
            toSeconds(): Seconds;
            /**
                * Return the value as a midi note.
                */
            toMidi(): MidiNote;
            protected _now(): Type;
    }
    /**
        * Create a TimeClass from a time string or number. The time is computed against the
        * global Tone.Context. To use a specific context, use {@link TimeClass}
        * @param value A value which represents time
        * @param units The value's units if they can't be inferred by the value.
        * @category Unit
        * @example
        * const time = Tone.Time("4n").toSeconds();
        * console.log(time);
        * @example
        * const note = Tone.Time(1).toNotation();
        * console.log(note);
        * @example
        * const freq = Tone.Time(0.5).toFrequency();
        * console.log(freq);
        */
    export function Time(value?: TimeValue, units?: TimeBaseUnit): TimeClass<Seconds>;
}

declare module 'tone/core/util/StateTimeline' {
    import { Seconds } from "tone/core/type/Units";
    import { Timeline, TimelineEvent } from "tone/core/util/Timeline";
    export type BasicPlaybackState = "started" | "stopped";
    export type PlaybackState = BasicPlaybackState | "paused";
    export interface StateTimelineEvent extends TimelineEvent {
            state: PlaybackState;
    }
    /**
        * A Timeline State. Provides the methods: `setStateAtTime("state", time)` and `getValueAtTime(time)`
        * @param initial The initial state of the StateTimeline.  Defaults to `undefined`
        * @internal
        */
    export class StateTimeline<AdditionalOptions extends Record<string, any> = Record<string, any>> extends Timeline<StateTimelineEvent & AdditionalOptions> {
            readonly name: string;
            constructor(initial?: PlaybackState);
            /**
                * Returns the scheduled state scheduled before or at
                * the given time.
                * @param  time  The time to query.
                * @return  The name of the state input in setStateAtTime.
                */
            getValueAtTime(time: Seconds): PlaybackState;
            /**
                * Add a state to the timeline.
                * @param  state The name of the state to set.
                * @param  time  The time to query.
                * @param options Any additional options that are needed in the timeline.
                */
            setStateAtTime(state: PlaybackState, time: Seconds, options?: AdditionalOptions): this;
            /**
                * Return the event before the time with the given state
                * @param  state The state to look for
                * @param  time  When to check before
                * @return  The event with the given state before the time
                */
            getLastState(state: PlaybackState, time: number): StateTimelineEvent & AdditionalOptions | undefined;
            /**
                * Return the event after the time with the given state
                * @param  state The state to look for
                * @param  time  When to check from
                * @return  The event with the given state after the time
                */
            getNextState(state: PlaybackState, time: number): StateTimelineEvent & AdditionalOptions | undefined;
    }
}

declare module 'tone/signal/Signal' {
    import { AbstractParam } from "tone/core/context/AbstractParam";
    import { Param } from "tone/core/context/Param";
    import { InputNode, OutputNode, ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { Time, UnitMap, UnitName } from "tone/core/type/Units";
    import { ToneConstantSource } from "tone/signal/ToneConstantSource";
    export interface SignalOptions<TypeName extends UnitName> extends ToneAudioNodeOptions {
            value: UnitMap[TypeName];
            units: TypeName;
            convert: boolean;
            minValue?: number;
            maxValue?: number;
    }
    /**
        * A signal is an audio-rate value. Tone.Signal is a core component of the library.
        * Unlike a number, Signals can be scheduled with sample-level accuracy. Tone.Signal
        * has all of the methods available to native Web Audio
        * [AudioParam](http://webaudio.github.io/web-audio-api/#the-audioparam-interface)
        * as well as additional conveniences. Read more about working with signals
        * [here](https://github.com/Tonejs/Tone.js/wiki/Signals).
        *
        * @example
        * const osc = new Tone.Oscillator().toDestination().start();
        * // a scheduleable signal which can be connected to control an AudioParam or another Signal
        * const signal = new Tone.Signal({
        * 	value: "C4",
        * 	units: "frequency"
        * }).connect(osc.frequency);
        * // the scheduled ramp controls the connected signal
        * signal.rampTo("C2", 4, "+0.5");
        * @category Signal
        */
    export class Signal<TypeName extends UnitName = "number"> extends ToneAudioNode<SignalOptions<any>> implements AbstractParam<TypeName> {
            readonly name: string;
            /**
                * Indicates if the value should be overridden on connection.
                */
            readonly override: boolean;
            /**
                * The constant source node which generates the signal
                */
            protected _constantSource: ToneConstantSource<TypeName>;
            readonly output: OutputNode;
            protected _param: Param<TypeName>;
            readonly input: InputNode;
            /**
                * @param value Initial value of the signal
                * @param units The unit name, e.g. "frequency"
                */
            constructor(value?: UnitMap[TypeName], units?: TypeName);
            constructor(options?: Partial<SignalOptions<TypeName>>);
            static getDefaults(): SignalOptions<any>;
            connect(destination: InputNode, outputNum?: number, inputNum?: number): this;
            dispose(): this;
            setValueAtTime(value: UnitMap[TypeName], time: Time): this;
            getValueAtTime(time: Time): UnitMap[TypeName];
            setRampPoint(time: Time): this;
            linearRampToValueAtTime(value: UnitMap[TypeName], time: Time): this;
            exponentialRampToValueAtTime(value: UnitMap[TypeName], time: Time): this;
            exponentialRampTo(value: UnitMap[TypeName], rampTime: Time, startTime?: Time): this;
            linearRampTo(value: UnitMap[TypeName], rampTime: Time, startTime?: Time): this;
            targetRampTo(value: UnitMap[TypeName], rampTime: Time, startTime?: Time): this;
            exponentialApproachValueAtTime(value: UnitMap[TypeName], time: Time, rampTime: Time): this;
            setTargetAtTime(value: UnitMap[TypeName], startTime: Time, timeConstant: number): this;
            setValueCurveAtTime(values: UnitMap[TypeName][], startTime: Time, duration: Time, scaling?: number): this;
            cancelScheduledValues(time: Time): this;
            cancelAndHoldAtTime(time: Time): this;
            rampTo(value: UnitMap[TypeName], rampTime: Time, startTime?: Time): this;
            get value(): UnitMap[TypeName];
            set value(value: UnitMap[TypeName]);
            get convert(): boolean;
            set convert(convert: boolean);
            get units(): UnitName;
            get overridden(): boolean;
            set overridden(overridden: boolean);
            get maxValue(): number;
            get minValue(): number;
            /**
                * @see {@link Param.apply}.
                */
            apply(param: Param | AudioParam): this;
    }
    /**
        * When connecting from a signal, it's necessary to zero out the node destination
        * node if that node is also a signal. If the destination is not 0, then the values
        * will be summed. This method insures that the output of the destination signal will
        * be the same as the source signal, making the destination signal a pass through node.
        * @param signal The output signal to connect from
        * @param destination the destination to connect to
        * @param outputNum the optional output number
        * @param inputNum the input number
        */
    export function connectSignal(signal: OutputNode, destination: InputNode, outputNum?: number, inputNum?: number): void;
}

declare module 'tone/core/context/ToneWithContext' {
    import { Tone } from "tone/core/Tone";
    import { TimeClass } from "tone/core/type/Time";
    import { Frequency, Hertz, Seconds, Ticks, Time } from "tone/core/type/Units";
    import { RecursivePartial } from "tone/core/util/Interface";
    import { BaseContext } from "tone/core/context/BaseContext";
    /**
        * A unit which process audio
        */
    export interface ToneWithContextOptions {
            context: BaseContext;
    }
    /**
        * The Base class for all nodes that have an AudioContext.
        */
    export abstract class ToneWithContext<Options extends ToneWithContextOptions> extends Tone {
            /**
                * The context belonging to the node.
                */
            readonly context: BaseContext;
            /**
                * The default context to use if no AudioContext is passed in to the constructor.
                * Probably should not be set manually. Used internally.
                * @hidden
                */
            readonly defaultContext?: BaseContext;
            /**
                * Pass in a constructor as the first argument
                */
            constructor(context?: BaseContext);
            constructor(options?: Partial<ToneWithContextOptions>);
            static getDefaults(): ToneWithContextOptions;
            /**
                * Return the current time of the Context clock plus the lookAhead.
                * @example
                * setInterval(() => {
                * 	console.log(Tone.now());
                * }, 100);
                */
            now(): Seconds;
            /**
                * Return the current time of the Context clock without any lookAhead.
                * @example
                * setInterval(() => {
                * 	console.log(Tone.immediate());
                * }, 100);
                */
            immediate(): Seconds;
            /**
                * The duration in seconds of one sample.
                */
            get sampleTime(): Seconds;
            /**
                * The number of seconds of 1 processing block (128 samples)
                * @example
                * console.log(Tone.Destination.blockTime);
                */
            get blockTime(): Seconds;
            /**
                * Convert the incoming time to seconds.
                * This is calculated against the current {@link TransportClass} bpm
                * @example
                * const gain = new Tone.Gain();
                * setInterval(() => console.log(gain.toSeconds("4n")), 100);
                * // ramp the tempo to 60 bpm over 30 seconds
                * Tone.getTransport().bpm.rampTo(60, 30);
                */
            toSeconds(time?: Time): Seconds;
            /**
                * Convert the input to a frequency number
                * @example
                * const gain = new Tone.Gain();
                * console.log(gain.toFrequency("4n"));
                */
            toFrequency(freq: Frequency): Hertz;
            /**
                * Convert the input time into ticks
                * @example
                * const gain = new Tone.Gain();
                * console.log(gain.toTicks("4n"));
                */
            toTicks(time?: Time | TimeClass): Ticks;
            /**
                * Get a subset of the properties which are in the partial props
                */
            protected _getPartialProperties(props: Options): Partial<Options>;
            /**
                * Get the object's attributes.
                * @example
                * const osc = new Tone.Oscillator();
                * console.log(osc.get());
                */
            get(): Options;
            /**
                * Set multiple properties at once with an object.
                * @example
                * const filter = new Tone.Filter().toDestination();
                * // set values using an object
                * filter.set({
                * 	frequency: "C6",
                * 	type: "highpass"
                * });
                * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/Analogsynth_octaves_highmid.mp3").connect(filter);
                * player.autostart = true;
                */
            set(props: RecursivePartial<Options>): this;
    }
}

declare module 'tone/core/type/TransportTime' {
    import { Seconds, Ticks } from "tone/core/type/Units";
    import { TimeClass } from "tone/core/type/Time";
    import { TimeBaseUnit, TimeValue } from "tone/core/type/TimeBase";
    /**
        * TransportTime is a time along the Transport's
        * timeline. It is similar to Tone.Time, but instead of evaluating
        * against the AudioContext's clock, it is evaluated against
        * the Transport's position. See [TransportTime wiki](https://github.com/Tonejs/Tone.js/wiki/TransportTime).
        * @category Unit
        */
    export class TransportTimeClass<Type extends Seconds | Ticks = Seconds> extends TimeClass<Type> {
            readonly name: string;
            /**
                * Return the current time in whichever context is relevant
                */
            protected _now(): Type;
    }
    /**
        * TransportTime is a time along the Transport's
        * timeline. It is similar to Tone.Time, but instead of evaluating
        * against the AudioContext's clock, it is evaluated against
        * the Transport's position. See [TransportTime wiki](https://github.com/Tonejs/Tone.js/wiki/TransportTime).
        * @category Unit
        */
    export function TransportTime(value?: TimeValue, units?: TimeBaseUnit): TransportTimeClass;
}

declare module 'tone/core/util/Emitter' {
    import { Tone } from "tone/core/Tone";
    export interface EmitterEventObject {
            [event: string]: Array<(...args: any[]) => void>;
    }
    /**
        * Emitter gives classes which extend it
        * the ability to listen for and emit events.
        * Inspiration and reference from Jerome Etienne's [MicroEvent](https://github.com/jeromeetienne/microevent.js).
        * MIT (c) 2011 Jerome Etienne.
        * @category Core
        */
    export class Emitter<EventType extends string = string> extends Tone {
            readonly name: string;
            /**
                * Bind a callback to a specific event.
                * @param  event     The name of the event to listen for.
                * @param  callback  The callback to invoke when the event is emitted
                */
            on(event: EventType, callback: (...args: any[]) => void): this;
            /**
                * Bind a callback which is only invoked once
                * @param  event     The name of the event to listen for.
                * @param  callback  The callback to invoke when the event is emitted
                */
            once(event: EventType, callback: (...args: any[]) => void): this;
            /**
                * Remove the event listener.
                * @param  event     The event to stop listening to.
                * @param  callback  The callback which was bound to the event with Emitter.on.
                *                   If no callback is given, all callbacks events are removed.
                */
            off(event: EventType, callback?: (...args: any[]) => void): this;
            /**
                * Invoke all of the callbacks bound to the event
                * with any arguments passed in.
                * @param  event  The name of the event.
                * @param args The arguments to pass to the functions listening.
                */
            emit(event: any, ...args: any[]): this;
            /**
                * Add Emitter functions (on/off/emit) to the object
                */
            static mixin(constr: any): void;
            /**
                * Clean up
                */
            dispose(): this;
    }
}

declare module 'tone/core/clock/TickParam' {
    import { AutomationEvent, Param, ParamOptions } from "tone/core/context/Param";
    import { Seconds, Ticks, Time, UnitMap, UnitName } from "tone/core/type/Units";
    import { Timeline } from "tone/core/util/Timeline";
    type TickAutomationEvent = AutomationEvent & {
            ticks: number;
    };
    interface TickParamOptions<TypeName extends UnitName> extends ParamOptions<TypeName> {
            multiplier: number;
    }
    /**
        * A Param class just for computing ticks. Similar to the {@link Param} class,
        * but offers conversion to BPM values as well as ability to compute tick
        * duration and elapsed ticks
        */
    export class TickParam<TypeName extends "hertz" | "bpm"> extends Param<TypeName> {
            readonly name: string;
            /**
                * The timeline which tracks all of the automations.
                */
            protected _events: Timeline<TickAutomationEvent>;
            /**
                * @param value The initial value of the signal
                */
            constructor(value?: number);
            constructor(options: Partial<TickParamOptions<TypeName>>);
            static getDefaults(): TickParamOptions<any>;
            setTargetAtTime(value: UnitMap[TypeName], time: Time, constant: number): this;
            setValueAtTime(value: UnitMap[TypeName], time: Time): this;
            linearRampToValueAtTime(value: UnitMap[TypeName], time: Time): this;
            exponentialRampToValueAtTime(value: UnitMap[TypeName], time: Time): this;
            /**
                * Returns the tick value at the time. Takes into account
                * any automation curves scheduled on the signal.
                * @param  time The time to get the tick count at
                * @return The number of ticks which have elapsed at the time given any automations.
                */
            getTicksAtTime(time: Time): Ticks;
            /**
                * Return the elapsed time of the number of ticks from the given time
                * @param ticks The number of ticks to calculate
                * @param  time The time to get the next tick from
                * @return The duration of the number of ticks from the given time in seconds
                */
            getDurationOfTicks(ticks: Ticks, time: Time): Seconds;
            /**
                * Given a tick, returns the time that tick occurs at.
                * @return The time that the tick occurs.
                */
            getTimeOfTick(tick: Ticks): Seconds;
            /**
                * Convert some number of ticks their the duration in seconds accounting
                * for any automation curves starting at the given time.
                * @param  ticks The number of ticks to convert to seconds.
                * @param  when  When along the automation timeline to convert the ticks.
                * @return The duration in seconds of the ticks.
                */
            ticksToTime(ticks: Ticks, when: Time): Seconds;
            /**
                * The inverse of {@link ticksToTime}. Convert a duration in
                * seconds to the corresponding number of ticks accounting for any
                * automation curves starting at the given time.
                * @param  duration The time interval to convert to ticks.
                * @param  when When along the automation timeline to convert the ticks.
                * @return The duration in ticks.
                */
            timeToTicks(duration: Time, when: Time): Ticks;
            /**
                * Convert from the type when the unit value is BPM
                */
            protected _fromType(val: UnitMap[TypeName]): number;
            /**
                * Special case of type conversion where the units === "bpm"
                */
            protected _toType(val: number): UnitMap[TypeName];
            /**
                * A multiplier on the bpm value. Useful for setting a PPQ relative to the base frequency value.
                */
            get multiplier(): number;
            set multiplier(m: number);
    }
    export {};
}

declare module 'tone/component/channel/Volume' {
    import { Gain } from "tone/core/context/Gain";
    import { Param } from "tone/core/context/Param";
    import { ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { Decibels } from "tone/core/type/Units";
    interface VolumeOptions extends ToneAudioNodeOptions {
            volume: Decibels;
            mute: boolean;
    }
    /**
        * Volume is a simple volume node, useful for creating a volume fader.
        *
        * @example
        * const vol = new Tone.Volume(-12).toDestination();
        * const osc = new Tone.Oscillator().connect(vol).start();
        * @category Component
        */
    export class Volume extends ToneAudioNode<VolumeOptions> {
            readonly name: string;
            /**
                * the output node
                */
            output: Gain<"decibels">;
            /**
                * Input and output are the same
                */
            input: Gain<"decibels">;
            /**
                * The volume control in decibels.
                * @example
                * const vol = new Tone.Volume().toDestination();
                * const osc = new Tone.Oscillator().connect(vol).start();
                * vol.volume.value = -20;
                */
            volume: Param<"decibels">;
            /**
                * @param volume the initial volume in decibels
                */
            constructor(volume?: Decibels);
            constructor(options?: Partial<VolumeOptions>);
            static getDefaults(): VolumeOptions;
            /**
                * Mute the output.
                * @example
                * const vol = new Tone.Volume(-12).toDestination();
                * const osc = new Tone.Oscillator().connect(vol).start();
                * // mute the output
                * vol.mute = true;
                */
            get mute(): boolean;
            set mute(mute: boolean);
            /**
                * clean up
                */
            dispose(): this;
    }
    export {};
}

declare module 'tone/core/context/Gain' {
    import { Param } from "tone/core/context/Param";
    import { UnitMap, UnitName } from "tone/core/type/Units";
    import { ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    interface GainOptions<TypeName extends UnitName> extends ToneAudioNodeOptions {
            gain: UnitMap[TypeName];
            units: TypeName;
            convert: boolean;
            minValue?: number;
            maxValue?: number;
    }
    /**
        * A thin wrapper around the Native Web Audio GainNode.
        * The GainNode is a basic building block of the Web Audio
        * API and is useful for routing audio and adjusting gains.
        * @category Core
        * @example
        * return Tone.Offline(() => {
        * 	const gainNode = new Tone.Gain(0).toDestination();
        * 	const osc = new Tone.Oscillator(30).connect(gainNode).start();
        * 	gainNode.gain.rampTo(1, 0.1);
        * 	gainNode.gain.rampTo(0, 0.4, 0.2);
        * }, 0.7, 1);
        */
    export class Gain<TypeName extends "gain" | "decibels" | "normalRange" = "gain"> extends ToneAudioNode<GainOptions<TypeName>> {
            readonly name: string;
            /**
                * The gain parameter of the gain node.
                * @example
                * const gainNode = new Tone.Gain(0).toDestination();
                * const osc = new Tone.Oscillator().connect(gainNode).start();
                * gainNode.gain.rampTo(1, 0.1);
                * gainNode.gain.rampTo(0, 2, "+0.5");
                */
            readonly gain: Param<TypeName>;
            readonly input: GainNode;
            readonly output: GainNode;
            /**
                * @param  gain The initial gain of the GainNode
                * @param units The units of the gain parameter.
                */
            constructor(gain?: UnitMap[TypeName], units?: TypeName);
            constructor(options?: Partial<GainOptions<TypeName>>);
            static getDefaults(): GainOptions<any>;
            /**
                * Clean up.
                */
            dispose(): this;
    }
    export {};
}

declare module 'tone/core/context/Param' {
    import { AbstractParam } from "tone/core/context/AbstractParam";
    import { Positive, Time, UnitMap, UnitName } from "tone/core/type/Units";
    import { Timeline } from "tone/core/util/Timeline";
    import { ToneWithContext, ToneWithContextOptions } from "tone/core/context/ToneWithContext";
    export interface ParamOptions<TypeName extends UnitName> extends ToneWithContextOptions {
            units: TypeName;
            value?: UnitMap[TypeName];
            param: AudioParam | Param<TypeName>;
            convert: boolean;
            minValue?: number;
            maxValue?: number;
            swappable?: boolean;
    }
    /**
        * the possible automation types
        */
    type AutomationType = "linearRampToValueAtTime" | "exponentialRampToValueAtTime" | "setValueAtTime" | "setTargetAtTime" | "cancelScheduledValues";
    interface TargetAutomationEvent {
            type: "setTargetAtTime";
            time: number;
            value: number;
            constant: number;
    }
    interface NormalAutomationEvent {
            type: Exclude<AutomationType, "setTargetAtTime">;
            time: number;
            value: number;
    }
    /**
        * The events on the automation
        */
    export type AutomationEvent = NormalAutomationEvent | TargetAutomationEvent;
    /**
        * Param wraps the native Web Audio's AudioParam to provide
        * additional unit conversion functionality. It also
        * serves as a base-class for classes which have a single,
        * automatable parameter.
        * @category Core
        */
    export class Param<TypeName extends UnitName = "number"> extends ToneWithContext<ParamOptions<TypeName>> implements AbstractParam<TypeName> {
            readonly name: string;
            readonly input: GainNode | AudioParam;
            readonly units: UnitName;
            convert: boolean;
            overridden: boolean;
            /**
                * The timeline which tracks all of the automations.
                */
            protected _events: Timeline<AutomationEvent>;
            /**
                * The native parameter to control
                */
            protected _param: AudioParam;
            /**
                * The default value before anything is assigned
                */
            protected _initialValue: number;
            /**
                * If the underlying AudioParam can be swapped out
                * using the setParam method.
                */
            protected readonly _swappable: boolean;
            /**
                * @param param The AudioParam to wrap
                * @param units The unit name
                * @param convert Whether or not to convert the value to the target units
                */
            constructor(param: AudioParam, units?: TypeName, convert?: boolean);
            constructor(options: Partial<ParamOptions<TypeName>>);
            static getDefaults(): ParamOptions<any>;
            get value(): UnitMap[TypeName];
            set value(value: UnitMap[TypeName]);
            get minValue(): number;
            get maxValue(): number;
            /**
                * Convert the given value from the type specified by Param.units
                * into the destination value (such as Gain or Frequency).
                */
            protected _fromType(val: UnitMap[TypeName]): number;
            /**
                * Convert the parameters value into the units specified by Param.units.
                */
            protected _toType(val: number): UnitMap[TypeName];
            setValueAtTime(value: UnitMap[TypeName], time: Time): this;
            getValueAtTime(time: Time): UnitMap[TypeName];
            setRampPoint(time: Time): this;
            linearRampToValueAtTime(value: UnitMap[TypeName], endTime: Time): this;
            exponentialRampToValueAtTime(value: UnitMap[TypeName], endTime: Time): this;
            exponentialRampTo(value: UnitMap[TypeName], rampTime: Time, startTime?: Time): this;
            linearRampTo(value: UnitMap[TypeName], rampTime: Time, startTime?: Time): this;
            targetRampTo(value: UnitMap[TypeName], rampTime: Time, startTime?: Time): this;
            exponentialApproachValueAtTime(value: UnitMap[TypeName], time: Time, rampTime: Time): this;
            setTargetAtTime(value: UnitMap[TypeName], startTime: Time, timeConstant: Positive): this;
            setValueCurveAtTime(values: UnitMap[TypeName][], startTime: Time, duration: Time, scaling?: number): this;
            cancelScheduledValues(time: Time): this;
            cancelAndHoldAtTime(time: Time): this;
            rampTo(value: UnitMap[TypeName], rampTime?: Time, startTime?: Time): this;
            /**
                * Apply all of the previously scheduled events to the passed in Param or AudioParam.
                * The applied values will start at the context's current time and schedule
                * all of the events which are scheduled on this Param onto the passed in param.
                */
            apply(param: Param | AudioParam): this;
            /**
                * Replace the Param's internal AudioParam. Will apply scheduled curves
                * onto the parameter and replace the connections.
                */
            setParam(param: AudioParam): this;
            dispose(): this;
            get defaultValue(): UnitMap[TypeName];
            protected _exponentialApproach(t0: number, v0: number, v1: number, timeConstant: number, t: number): number;
            protected _linearInterpolate(t0: number, v0: number, t1: number, v1: number, t: number): number;
            protected _exponentialInterpolate(t0: number, v0: number, t1: number, v1: number, t: number): number;
    }
    export {};
}

declare module 'tone/core/context/ToneAudioNode' {
    import { Param } from "tone/core/context/Param";
    import { ToneWithContext, ToneWithContextOptions } from "tone/core/context/ToneWithContext";
    export type InputNode = ToneAudioNode | AudioNode | Param<any> | AudioParam;
    export type OutputNode = ToneAudioNode | AudioNode;
    /**
        * The possible options for this node
        */
    export type ToneAudioNodeOptions = ToneWithContextOptions;
    /**
        * ToneAudioNode is the base class for classes which process audio.
        * @category Core
        */
    export abstract class ToneAudioNode<Options extends ToneAudioNodeOptions = ToneAudioNodeOptions> extends ToneWithContext<Options> {
            /**
                * The name of the class
                */
            abstract readonly name: string;
            /**
                * The input node or nodes. If the object is a source,
                * it does not have any input and this.input is undefined.
                */
            abstract input: InputNode | undefined;
            /**
                * The output nodes. If the object is a sink,
                * it does not have any output and this.output is undefined.
                */
            abstract output: OutputNode | undefined;
            /**
                * The number of inputs feeding into the AudioNode.
                * For source nodes, this will be 0.
                * @example
                * const node = new Tone.Gain();
                * console.log(node.numberOfInputs);
                */
            get numberOfInputs(): number;
            /**
                * The number of outputs of the AudioNode.
                * @example
                * const node = new Tone.Gain();
                * console.log(node.numberOfOutputs);
                */
            get numberOfOutputs(): number;
            /**
                * List all of the node that must be set to match the ChannelProperties
                */
            protected _internalChannels: OutputNode[];
            /**
                * channelCount is the number of channels used when up-mixing and down-mixing
                * connections to any inputs to the node. The default value is 2 except for
                * specific nodes where its value is specially determined.
                */
            get channelCount(): number;
            set channelCount(channelCount: number);
            /**
                * channelCountMode determines how channels will be counted when up-mixing and
                * down-mixing connections to any inputs to the node.
                * The default value is "max". This attribute has no effect for nodes with no inputs.
                * * "max" - computedNumberOfChannels is the maximum of the number of channels of all connections to an input. In this mode channelCount is ignored.
                * * "clamped-max" - computedNumberOfChannels is determined as for "max" and then clamped to a maximum value of the given channelCount.
                * * "explicit" - computedNumberOfChannels is the exact value as specified by the channelCount.
                */
            get channelCountMode(): ChannelCountMode;
            set channelCountMode(channelCountMode: ChannelCountMode);
            /**
                * channelInterpretation determines how individual channels will be treated
                * when up-mixing and down-mixing connections to any inputs to the node.
                * The default value is "speakers".
                */
            get channelInterpretation(): ChannelInterpretation;
            set channelInterpretation(channelInterpretation: ChannelInterpretation);
            /**
                * connect the output of a ToneAudioNode to an AudioParam, AudioNode, or ToneAudioNode
                * @param destination The output to connect to
                * @param outputNum The output to connect from
                * @param inputNum The input to connect to
                */
            connect(destination: InputNode, outputNum?: number, inputNum?: number): this;
            /**
                * Connect the output to the context's destination node.
                * @example
                * const osc = new Tone.Oscillator("C2").start();
                * osc.toDestination();
                */
            toDestination(): this;
            /**
                * Connect the output to the context's destination node.
                * @see {@link toDestination}
                * @deprecated
                */
            toMaster(): this;
            /**
                * disconnect the output
                */
            disconnect(destination?: InputNode, outputNum?: number, inputNum?: number): this;
            /**
                * Connect the output of this node to the rest of the nodes in series.
                * @example
                * const player = new Tone.Player("https://tonejs.github.io/audio/drum-samples/handdrum-loop.mp3");
                * player.autostart = true;
                * const filter = new Tone.AutoFilter(4).start();
                * const distortion = new Tone.Distortion(0.5);
                * // connect the player to the filter, distortion and then to the master output
                * player.chain(filter, distortion, Tone.Destination);
                */
            chain(...nodes: InputNode[]): this;
            /**
                * connect the output of this node to the rest of the nodes in parallel.
                * @example
                * const player = new Tone.Player("https://tonejs.github.io/audio/drum-samples/conga-rhythm.mp3");
                * player.autostart = true;
                * const pitchShift = new Tone.PitchShift(4).toDestination();
                * const filter = new Tone.Filter("G5").toDestination();
                * // connect a node to the pitch shift and filter in parallel
                * player.fan(pitchShift, filter);
                */
            fan(...nodes: InputNode[]): this;
            /**
                * Dispose and disconnect
                */
            dispose(): this;
    }
    /**
        * connect together all of the arguments in series
        * @param nodes
        */
    export function connectSeries(...nodes: InputNode[]): void;
    /**
        * Connect two nodes together so that signal flows from the
        * first node to the second. Optionally specify the input and output channels.
        * @param srcNode The source node
        * @param dstNode The destination node
        * @param outputNumber The output channel of the srcNode
        * @param inputNumber The input channel of the dstNode
        */
    export function connect(srcNode: OutputNode, dstNode: InputNode, outputNumber?: number, inputNumber?: number): void;
    /**
        * Disconnect a node from all nodes or optionally include a destination node and input/output channels.
        * @param srcNode The source node
        * @param dstNode The destination node
        * @param outputNumber The output channel of the srcNode
        * @param inputNumber The input channel of the dstNode
        */
    export function disconnect(srcNode: OutputNode, dstNode?: InputNode, outputNumber?: number, inputNumber?: number): void;
    /**
        * Connect the output of one or more source nodes to a single destination node
        * @param nodes One or more source nodes followed by one destination node
        * @example
        * const player = new Tone.Player("https://tonejs.github.io/audio/drum-samples/conga-rhythm.mp3");
        * const player1 = new Tone.Player("https://tonejs.github.io/audio/drum-samples/conga-rhythm.mp3");
        * const filter = new Tone.Filter("G5").toDestination();
        * // connect nodes to a common destination
        * Tone.fanIn(player, player1, filter);
        */
    export function fanIn(...nodes: OutputNode[]): void;
}

declare module 'tone/source/OneShotSource' {
    import { Gain } from "tone/core/context/Gain";
    import { ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { GainFactor, Seconds, Time } from "tone/core/type/Units";
    import { BasicPlaybackState } from "tone/core/util/StateTimeline";
    export type OneShotSourceCurve = "linear" | "exponential";
    type onEndedCallback = (source: OneShotSource<any>) => void;
    export interface OneShotSourceOptions extends ToneAudioNodeOptions {
            onended: onEndedCallback;
            fadeIn: Time;
            fadeOut: Time;
            curve: OneShotSourceCurve;
    }
    /**
        * Base class for fire-and-forget nodes
        */
    export abstract class OneShotSource<Options extends ToneAudioNodeOptions> extends ToneAudioNode<Options> {
            /**
                * The callback to invoke after the
                * source is done playing.
                */
            onended: onEndedCallback;
            /**
                * Sources do not have input nodes
                */
            input: undefined;
            /**
                * The start time
                */
            protected _startTime: number;
            /**
                * The stop time
                */
            protected _stopTime: number;
            /**
                * The public output node
                */
            output: Gain;
            /**
                * The output gain node.
                */
            protected _gainNode: Gain<"gain">;
            /**
                * The fadeIn time of the amplitude envelope.
                */
            protected _fadeIn: Time;
            /**
                * The fadeOut time of the amplitude envelope.
                */
            protected _fadeOut: Time;
            /**
                * The curve applied to the fades, either "linear" or "exponential"
                */
            protected _curve: OneShotSourceCurve;
            constructor(options: OneShotSourceOptions);
            static getDefaults(): OneShotSourceOptions;
            /**
                * Stop the source node
                */
            protected abstract _stopSource(time: Seconds): void;
            /**
                * Start the source node at the given time
                * @param  time When to start the node
                */
            protected abstract start(time?: Time): this;
            /**
                * Start the source at the given time
                * @param  time When to start the source
                */
            protected _startGain(time: Seconds, gain?: GainFactor): this;
            /**
                * Stop the source node at the given time.
                * @param time When to stop the source
                */
            stop(time?: Time): this;
            /**
                * Stop the source at the given time
                * @param  time When to stop the source
                */
            protected _stopGain(time: Seconds): this;
            /**
                * Invoke the onended callback
                */
            protected _onended(): void;
            /**
                * Get the playback state at the given time
                */
            getStateAtTime: (time: Time) => BasicPlaybackState;
            /**
                * Get the playback state at the current time
                */
            get state(): BasicPlaybackState;
            /**
                * Cancel a scheduled stop event
                */
            cancelStop(): this;
            dispose(): this;
    }
    export {};
}

declare module 'tone/core/clock/Clock' {
    import { ToneWithContext, ToneWithContextOptions } from "tone/core/context/ToneWithContext";
    import { Frequency, Hertz, Seconds, Ticks, Time } from "tone/core/type/Units";
    import { Emitter } from "tone/core/util/Emitter";
    import { PlaybackState } from "tone/core/util/StateTimeline";
    import { TickSignal } from "tone/core/clock/TickSignal";
    type ClockCallback = (time: Seconds, ticks?: Ticks) => void;
    interface ClockOptions extends ToneWithContextOptions {
            frequency: Hertz;
            callback: ClockCallback;
            units: "hertz" | "bpm";
    }
    type ClockEvent = "start" | "stop" | "pause";
    /**
        * A sample accurate clock which provides a callback at the given rate.
        * While the callback is not sample-accurate (it is still susceptible to
        * loose JS timing), the time passed in as the argument to the callback
        * is precise. For most applications, it is better to use Tone.Transport
        * instead of the Clock by itself since you can synchronize multiple callbacks.
        * @example
        * // the callback will be invoked approximately once a second
        * // and will print the time exactly once a second apart.
        * const clock = new Tone.Clock(time => {
        * 	console.log(time);
        * }, 1);
        * clock.start();
        * @category Core
        */
    export class Clock<TypeName extends "bpm" | "hertz" = "hertz"> extends ToneWithContext<ClockOptions> implements Emitter<ClockEvent> {
            readonly name: string;
            /**
                * The callback function to invoke at the scheduled tick.
                */
            callback: ClockCallback;
            /**
                * The rate the callback function should be invoked.
                */
            frequency: TickSignal<TypeName>;
            /**
                * @param callback The callback to be invoked with the time of the audio event
                * @param frequency The rate of the callback
                */
            constructor(callback?: ClockCallback, frequency?: Frequency);
            constructor(options: Partial<ClockOptions>);
            static getDefaults(): ClockOptions;
            /**
                * Returns the playback state of the source, either "started", "stopped" or "paused".
                */
            get state(): PlaybackState;
            /**
                * Start the clock at the given time. Optionally pass in an offset
                * of where to start the tick counter from.
                * @param  time    The time the clock should start
                * @param offset  Where the tick counter starts counting from.
                */
            start(time?: Time, offset?: Ticks): this;
            /**
                * Stop the clock. Stopping the clock resets the tick counter to 0.
                * @param time The time when the clock should stop.
                * @example
                * const clock = new Tone.Clock(time => {
                * 	console.log(time);
                * }, 1);
                * clock.start();
                * // stop the clock after 10 seconds
                * clock.stop("+10");
                */
            stop(time?: Time): this;
            /**
                * Pause the clock. Pausing does not reset the tick counter.
                * @param time The time when the clock should stop.
                */
            pause(time?: Time): this;
            /**
                * The number of times the callback was invoked. Starts counting at 0
                * and increments after the callback was invoked.
                */
            get ticks(): Ticks;
            set ticks(t: Ticks);
            /**
                * The time since ticks=0 that the Clock has been running. Accounts for tempo curves
                */
            get seconds(): Seconds;
            set seconds(s: Seconds);
            /**
                * Return the elapsed seconds at the given time.
                * @param  time  When to get the elapsed seconds
                * @return  The number of elapsed seconds
                */
            getSecondsAtTime(time: Time): Seconds;
            /**
                * Set the clock's ticks at the given time.
                * @param  ticks The tick value to set
                * @param  time  When to set the tick value
                */
            setTicksAtTime(ticks: Ticks, time: Time): this;
            /**
                * Get the time of the given tick. The second argument
                * is when to test before. Since ticks can be set (with setTicksAtTime)
                * there may be multiple times for a given tick value.
                * @param  tick The tick number.
                * @param  before When to measure the tick value from.
                * @return The time of the tick
                */
            getTimeOfTick(tick: Ticks, before?: number): Seconds;
            /**
                * Get the clock's ticks at the given time.
                * @param  time  When to get the tick value
                * @return The tick value at the given time.
                */
            getTicksAtTime(time?: Time): Ticks;
            /**
                * Get the time of the next tick
                * @param  offset The tick number.
                */
            nextTickTime(offset: Ticks, when: Time): Seconds;
            /**
                * Returns the scheduled state at the given time.
                * @param  time  The time to query.
                * @return  The name of the state input in setStateAtTime.
                * @example
                * const clock = new Tone.Clock();
                * clock.start("+0.1");
                * clock.getStateAtTime("+0.1"); // returns "started"
                */
            getStateAtTime(time: Time): PlaybackState;
            /**
                * Clean up
                */
            dispose(): this;
            on: (event: ClockEvent, callback: (...args: any[]) => void) => this;
            once: (event: ClockEvent, callback: (...args: any[]) => void) => this;
            off: (event: ClockEvent, callback?: ((...args: any[]) => void) | undefined) => this;
            emit: (event: any, ...args: any[]) => this;
    }
    export {};
}

declare module 'tone/core/context/Context' {
    import { TickerClockSource } from "tone/core/clock/Ticker";
    import { Seconds } from "tone/core/type/Units";
    import { AnyAudioContext } from "tone/core/context/AudioContext";
    import { BaseContext, ContextLatencyHint } from "tone/core/context/BaseContext";
    type Transport = import("../clock/Transport").TransportClass;
    type Destination = import("./Destination").DestinationClass;
    type Listener = import("./Listener").ListenerClass;
    type Draw = import("../util/Draw").DrawClass;
    export interface ContextOptions {
            clockSource: TickerClockSource;
            latencyHint: ContextLatencyHint;
            lookAhead: Seconds;
            updateInterval: Seconds;
            context: AnyAudioContext;
    }
    export interface ContextTimeoutEvent {
            callback: (...args: any[]) => void;
            id: number;
            time: Seconds;
    }
    /**
        * Wrapper around the native AudioContext.
        * @category Core
        */
    export class Context extends BaseContext {
            readonly name: string;
            /**
                * private reference to the BaseAudioContext
                */
            protected readonly _context: AnyAudioContext;
            /**
                * Indicates if the context is an OfflineAudioContext or an AudioContext
                */
            readonly isOffline: boolean;
            constructor(context?: AnyAudioContext);
            constructor(options?: Partial<ContextOptions>);
            static getDefaults(): ContextOptions;
            createAnalyser(): AnalyserNode;
            createOscillator(): OscillatorNode;
            createBufferSource(): AudioBufferSourceNode;
            createBiquadFilter(): BiquadFilterNode;
            createBuffer(numberOfChannels: number, length: number, sampleRate: number): AudioBuffer;
            createChannelMerger(numberOfInputs?: number | undefined): ChannelMergerNode;
            createChannelSplitter(numberOfOutputs?: number | undefined): ChannelSplitterNode;
            createConstantSource(): ConstantSourceNode;
            createConvolver(): ConvolverNode;
            createDelay(maxDelayTime?: number | undefined): DelayNode;
            createDynamicsCompressor(): DynamicsCompressorNode;
            createGain(): GainNode;
            createIIRFilter(feedForward: number[] | Float32Array, feedback: number[] | Float32Array): IIRFilterNode;
            createPanner(): PannerNode;
            createPeriodicWave(real: number[] | Float32Array, imag: number[] | Float32Array, constraints?: PeriodicWaveConstraints | undefined): PeriodicWave;
            createStereoPanner(): StereoPannerNode;
            createWaveShaper(): WaveShaperNode;
            createMediaStreamSource(stream: MediaStream): MediaStreamAudioSourceNode;
            createMediaElementSource(element: HTMLMediaElement): MediaElementAudioSourceNode;
            createMediaStreamDestination(): MediaStreamAudioDestinationNode;
            decodeAudioData(audioData: ArrayBuffer): Promise<AudioBuffer>;
            /**
                * The current time in seconds of the AudioContext.
                */
            get currentTime(): Seconds;
            /**
                * The current time in seconds of the AudioContext.
                */
            get state(): AudioContextState;
            /**
                * The current time in seconds of the AudioContext.
                */
            get sampleRate(): number;
            /**
                * The listener
                */
            get listener(): Listener;
            set listener(l: Listener);
            /**
                * There is only one Transport per Context. It is created on initialization.
                */
            get transport(): Transport;
            set transport(t: Transport);
            /**
                * This is the Draw object for the context which is useful for synchronizing the draw frame with the Tone.js clock.
                */
            get draw(): Draw;
            set draw(d: Draw);
            /**
                * A reference to the Context's destination node.
                */
            get destination(): Destination;
            set destination(d: Destination);
            /**
                * Create an audio worklet node from a name and options. The module
                * must first be loaded using {@link addAudioWorkletModule}.
                */
            createAudioWorkletNode(name: string, options?: Partial<AudioWorkletNodeOptions>): AudioWorkletNode;
            /**
                * Add an AudioWorkletProcessor module
                * @param url The url of the module
                */
            addAudioWorkletModule(url: string): Promise<void>;
            /**
                * Returns a promise which resolves when all of the worklets have been loaded on this context
                */
            protected workletsAreReady(): Promise<void>;
            /**
                * How often the interval callback is invoked.
                * This number corresponds to how responsive the scheduling
                * can be. Setting to 0 will result in the lowest practial interval
                * based on context properties. context.updateInterval + context.lookAhead
                * gives you the total latency between scheduling an event and hearing it.
                */
            get updateInterval(): Seconds;
            set updateInterval(interval: Seconds);
            /**
                * What the source of the clock is, either "worker" (default),
                * "timeout", or "offline" (none).
                */
            get clockSource(): TickerClockSource;
            set clockSource(type: TickerClockSource);
            /**
                * The amount of time into the future events are scheduled. Giving Web Audio
                * a short amount of time into the future to schedule events can reduce clicks and
                * improve performance. This value can be set to 0 to get the lowest latency.
                * Adjusting this value also affects the {@link updateInterval}.
                */
            get lookAhead(): Seconds;
            set lookAhead(time: Seconds);
            /**
                * The type of playback, which affects tradeoffs between audio
                * output latency and responsiveness.
                * In addition to setting the value in seconds, the latencyHint also
                * accepts the strings "interactive" (prioritizes low latency),
                * "playback" (prioritizes sustained playback), "balanced" (balances
                * latency and performance).
                * @example
                * // prioritize sustained playback
                * const context = new Tone.Context({ latencyHint: "playback" });
                * // set this context as the global Context
                * Tone.setContext(context);
                * // the global context is gettable with Tone.getContext()
                * console.log(Tone.getContext().latencyHint);
                */
            get latencyHint(): ContextLatencyHint | Seconds;
            /**
                * The unwrapped AudioContext or OfflineAudioContext
                */
            get rawContext(): AnyAudioContext;
            /**
                * The current audio context time plus a short {@link lookAhead}.
                * @example
                * setInterval(() => {
                * 	console.log("now", Tone.now());
                * }, 100);
                */
            now(): Seconds;
            /**
                * The current audio context time without the {@link lookAhead}.
                * In most cases it is better to use {@link now} instead of {@link immediate} since
                * with {@link now} the {@link lookAhead} is applied equally to _all_ components including internal components,
                * to making sure that everything is scheduled in sync. Mixing {@link now} and {@link immediate}
                * can cause some timing issues. If no lookAhead is desired, you can set the {@link lookAhead} to `0`.
                */
            immediate(): Seconds;
            /**
                * Starts the audio context from a suspended state. This is required
                * to initially start the AudioContext.
                * @see {@link start}
                */
            resume(): Promise<void>;
            /**
                * Close the context. Once closed, the context can no longer be used and
                * any AudioNodes created from the context will be silent.
                */
            close(): Promise<void>;
            /**
                * **Internal** Generate a looped buffer at some constant value.
                */
            getConstant(val: number): AudioBufferSourceNode;
            /**
                * Clean up. Also closes the audio context.
                */
            dispose(): this;
            /**
                * A setTimeout which is guaranteed by the clock source.
                * Also runs in the offline context.
                * @param  fn       The callback to invoke
                * @param  timeout  The timeout in seconds
                * @returns ID to use when invoking Context.clearTimeout
                */
            setTimeout(fn: (...args: any[]) => void, timeout: Seconds): number;
            /**
                * Clears a previously scheduled timeout with Tone.context.setTimeout
                * @param  id  The ID returned from setTimeout
                */
            clearTimeout(id: number): this;
            /**
                * Clear the function scheduled by {@link setInterval}
                */
            clearInterval(id: number): this;
            /**
                * Adds a repeating event to the context's callback clock
                */
            setInterval(fn: (...args: any[]) => void, interval: Seconds): number;
    }
    export {};
}

declare module 'tone/core/context/Delay' {
    import { Param } from "tone/core/context/Param";
    import { Seconds, Time } from "tone/core/type/Units";
    import { ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    export interface DelayOptions extends ToneAudioNodeOptions {
            delayTime: Time;
            maxDelay: Time;
    }
    /**
        * Wrapper around Web Audio's native [DelayNode](http://webaudio.github.io/web-audio-api/#the-delaynode-interface).
        * @category Core
        * @example
        * return Tone.Offline(() => {
        * 	const delay = new Tone.Delay(0.1).toDestination();
        * 	// connect the signal to both the delay and the destination
        * 	const pulse = new Tone.PulseOscillator().connect(delay).toDestination();
        * 	// start and stop the pulse
        * 	pulse.start(0).stop(0.01);
        * }, 0.5, 1);
        */
    export class Delay extends ToneAudioNode<DelayOptions> {
            readonly name: string;
            /**
                * The amount of time the incoming signal is delayed.
                * @example
                * const delay = new Tone.Delay().toDestination();
                * // modulate the delayTime between 0.1 and 1 seconds
                * const delayLFO = new Tone.LFO(0.5, 0.1, 1).start().connect(delay.delayTime);
                * const pulse = new Tone.PulseOscillator().connect(delay).start();
                * // the change in delayTime causes the pitch to go up and down
                */
            readonly delayTime: Param<"time">;
            readonly input: DelayNode;
            readonly output: DelayNode;
            /**
                * @param delayTime The delay applied to the incoming signal.
                * @param maxDelay The maximum delay time.
                */
            constructor(delayTime?: Time, maxDelay?: Time);
            constructor(options?: Partial<DelayOptions>);
            static getDefaults(): DelayOptions;
            /**
                * The maximum delay time. This cannot be changed after
                * the value is passed into the constructor.
                */
            get maxDelay(): Seconds;
            /**
                * Clean up.
                */
            dispose(): this;
    }
}

declare module 'tone/core/context/Offline' {
    import { Seconds } from "tone/core/type/Units";
    import { OfflineContext } from "tone/core/context/OfflineContext";
    import { ToneAudioBuffer } from "tone/core/context/ToneAudioBuffer";
    /**
      * Generate a buffer by rendering all of the Tone.js code within the callback using the OfflineAudioContext.
      * The OfflineAudioContext is capable of rendering much faster than real time in many cases.
      * The callback function also passes in an offline instance of {@link Context} which can be used
      * to schedule events along the Transport.
      * @param  callback  All Tone.js nodes which are created and scheduled within this callback are recorded into the output Buffer.
      * @param  duration     the amount of time to record for.
      * @return  The promise which is invoked with the ToneAudioBuffer of the recorded output.
      * @example
      * // render 2 seconds of the oscillator
      * Tone.Offline(() => {
      * 	// only nodes created in this callback will be recorded
      * 	const oscillator = new Tone.Oscillator().toDestination().start(0);
      * }, 2).then((buffer) => {
      * 	// do something with the output buffer
      * 	console.log(buffer);
      * });
      * @example
      * // can also schedule events along the Transport
      * // using the passed in Offline Transport
      * Tone.Offline(({ transport }) => {
      * 	const osc = new Tone.Oscillator().toDestination();
      * 	transport.schedule(time => {
      * 		osc.start(time).stop(time + 0.1);
      * 	}, 1);
      * 	// make sure to start the transport
      * 	transport.start(0.2);
      * }, 4).then((buffer) => {
      * 	// do something with the output buffer
      * 	console.log(buffer);
      * });
      * @category Core
      */
    export function Offline(callback: (context: OfflineContext) => Promise<void> | void, duration: Seconds, channels?: number, sampleRate?: number): Promise<ToneAudioBuffer>;
}

declare module 'tone/core/context/OfflineContext' {
    import { Context } from "tone/core/context/Context";
    import { Seconds } from "tone/core/type/Units";
    import { ToneAudioBuffer } from "tone/core/context/ToneAudioBuffer";
    /**
        * Wrapper around the OfflineAudioContext
        * @category Core
        * @example
        * // generate a single channel, 0.5 second buffer
        * const context = new Tone.OfflineContext(1, 0.5, 44100);
        * const osc = new Tone.Oscillator({ context });
        * context.render().then(buffer => {
        * 	console.log(buffer.numberOfChannels, buffer.duration);
        * });
        */
    export class OfflineContext extends Context {
            readonly name: string;
            /**
                * Private reference to the OfflineAudioContext.
                */
            protected _context: OfflineAudioContext;
            readonly isOffline: boolean;
            /**
                * @param  channels  The number of channels to render
                * @param  duration  The duration to render in seconds
                * @param sampleRate the sample rate to render at
                */
            constructor(channels: number, duration: Seconds, sampleRate: number);
            constructor(context: OfflineAudioContext);
            /**
                * Override the now method to point to the internal clock time
                */
            now(): Seconds;
            /**
                * Same as this.now()
                */
            get currentTime(): Seconds;
            /**
                * Render the output of the OfflineContext
                * @param asynchronous If the clock should be rendered asynchronously, which will not block the main thread, but be slightly slower.
                */
            render(asynchronous?: boolean): Promise<ToneAudioBuffer>;
            /**
                * Close the context
                */
            close(): Promise<void>;
    }
}

declare module 'tone/core/type/Frequency' {
    import { TimeClass } from "tone/core/type/Time";
    import { TimeBaseUnit, TimeExpression, TimeValue } from "tone/core/type/TimeBase";
    import { Frequency, Hertz, Interval, MidiNote, Note, Seconds, Ticks } from "tone/core/type/Units";
    export type FrequencyUnit = TimeBaseUnit | "midi";
    /**
        * Frequency is a primitive type for encoding Frequency values.
        * Eventually all time values are evaluated to hertz using the `valueOf` method.
        * @example
        * Tone.Frequency("C3"); // 261
        * Tone.Frequency(38, "midi");
        * Tone.Frequency("C3").transpose(4);
        * @category Unit
        */
    export class FrequencyClass<Type extends number = Hertz> extends TimeClass<Type, FrequencyUnit> {
            readonly name: string;
            readonly defaultUnits: FrequencyUnit;
            /**
                * The [concert tuning pitch](https://en.wikipedia.org/wiki/Concert_pitch) which is used
                * to generate all the other pitch values from notes. A4's values in Hertz.
                */
            static get A4(): Hertz;
            static set A4(freq: Hertz);
            protected _getExpressions(): TimeExpression<Type>;
            /**
                * Transposes the frequency by the given number of semitones.
                * @return  A new transposed frequency
                * @example
                * Tone.Frequency("A4").transpose(3); // "C5"
                */
            transpose(interval: Interval): FrequencyClass;
            /**
                * Takes an array of semitone intervals and returns
                * an array of frequencies transposed by those intervals.
                * @return  Returns an array of Frequencies
                * @example
                * Tone.Frequency("A4").harmonize([0, 3, 7]); // ["A4", "C5", "E5"]
                */
            harmonize(intervals: Interval[]): FrequencyClass[];
            /**
                * Return the value of the frequency as a MIDI note
                * @example
                * Tone.Frequency("C4").toMidi(); // 60
                */
            toMidi(): MidiNote;
            /**
                * Return the value of the frequency in Scientific Pitch Notation
                * @example
                * Tone.Frequency(69, "midi").toNote(); // "A4"
                */
            toNote(): Note;
            /**
                * Return the duration of one cycle in seconds.
                */
            toSeconds(): Seconds;
            /**
                * Return the duration of one cycle in ticks
                */
            toTicks(): Ticks;
            /**
                * With no arguments, return 0
                */
            protected _noArg(): Type;
            /**
                * Returns the value of a frequency in the current units
                */
            protected _frequencyToUnits(freq: Hertz): Type;
            /**
                * Returns the value of a tick in the current time units
                */
            protected _ticksToUnits(ticks: Ticks): Type;
            /**
                * Return the value of the beats in the current units
                */
            protected _beatsToUnits(beats: number): Type;
            /**
                * Returns the value of a second in the current units
                */
            protected _secondsToUnits(seconds: Seconds): Type;
            /**
                * Convert a MIDI note to frequency value.
                * @param  midi The midi number to convert.
                * @return The corresponding frequency value
                */
            static mtof(midi: MidiNote): Hertz;
            /**
                * Convert a frequency value to a MIDI note.
                * @param frequency The value to frequency value to convert.
                */
            static ftom(frequency: Hertz): MidiNote;
    }
    /**
        * Convert a value into a FrequencyClass object.
        * @category Unit
        * @example
        * const midi = Tone.Frequency("C3").toMidi();
        * console.log(midi);
        * @example
        * const hertz = Tone.Frequency(38, "midi").toFrequency();
        * console.log(hertz);
        */
    export function Frequency(value?: TimeValue | Frequency, units?: FrequencyUnit): FrequencyClass;
}

declare module 'tone/core/type/Midi' {
    import { FrequencyClass, FrequencyUnit } from "tone/core/type/Frequency";
    import { TimeValue } from "tone/core/type/TimeBase";
    import { Hertz, Interval, MidiNote, Seconds, Ticks } from "tone/core/type/Units";
    /**
        * Midi is a primitive type for encoding Time values.
        * Midi can be constructed with or without the `new` keyword. Midi can be passed
        * into the parameter of any method which takes time as an argument.
        * @category Unit
        */
    export class MidiClass extends FrequencyClass<MidiNote> {
            readonly name: string;
            readonly defaultUnits = "midi";
            /**
                * Returns the value of a frequency in the current units
                */
            protected _frequencyToUnits(freq: Hertz): MidiNote;
            /**
                * Returns the value of a tick in the current time units
                */
            protected _ticksToUnits(ticks: Ticks): MidiNote;
            /**
                * Return the value of the beats in the current units
                */
            protected _beatsToUnits(beats: number): MidiNote;
            /**
                * Returns the value of a second in the current units
                */
            protected _secondsToUnits(seconds: Seconds): MidiNote;
            /**
                * Return the value of the frequency as a MIDI note
                * @example
                * Tone.Midi(60).toMidi(); // 60
                */
            toMidi(): MidiNote;
            /**
                * Return the value of the frequency as a MIDI note
                * @example
                * Tone.Midi(60).toFrequency(); // 261.6255653005986
                */
            toFrequency(): Hertz;
            /**
                * Transposes the frequency by the given number of semitones.
                * @return A new transposed MidiClass
                * @example
                * Tone.Midi("A4").transpose(3); // "C5"
                */
            transpose(interval: Interval): MidiClass;
    }
    /**
        * Convert a value into a FrequencyClass object.
        * @category Unit
        */
    export function Midi(value?: TimeValue, units?: FrequencyUnit): MidiClass;
}

declare module 'tone/core/type/Ticks' {
    import { TimeBaseUnit, TimeValue } from "tone/core/type/TimeBase";
    import { TransportTimeClass } from "tone/core/type/TransportTime";
    import { Seconds, Ticks } from "tone/core/type/Units";
    /**
        * Ticks is a primitive type for encoding Time values.
        * Ticks can be constructed with or without the `new` keyword. Ticks can be passed
        * into the parameter of any method which takes time as an argument.
        * @example
        * const t = Tone.Ticks("4n"); // a quarter note as ticks
        * @category Unit
        */
    export class TicksClass extends TransportTimeClass<Ticks> {
            readonly name: string;
            readonly defaultUnits: TimeBaseUnit;
            /**
                * Get the current time in the given units
                */
            protected _now(): Ticks;
            /**
                * Return the value of the beats in the current units
                */
            protected _beatsToUnits(beats: number): Ticks;
            /**
                * Returns the value of a second in the current units
                */
            protected _secondsToUnits(seconds: Seconds): Ticks;
            /**
                * Returns the value of a tick in the current time units
                */
            protected _ticksToUnits(ticks: Ticks): Ticks;
            /**
                * Return the time in ticks
                */
            toTicks(): Ticks;
            /**
                * Return the time in seconds
                */
            toSeconds(): Seconds;
    }
    /**
        * Convert a time representation to ticks
        * @category Unit
        */
    export function Ticks(value?: TimeValue, units?: TimeBaseUnit): TicksClass;
}

declare module 'tone/core/util/IntervalTimeline' {
    import { Tone } from "tone/core/Tone";
    /**
        * An IntervalTimeline event must have a time and duration
        */
    export interface IntervalTimelineEvent {
            time: number;
            duration: number;
            [propName: string]: any;
    }
    type IteratorCallback = (event: IntervalTimelineEvent) => void;
    /**
        * Similar to Tone.Timeline, but all events represent
        * intervals with both "time" and "duration" times. The
        * events are placed in a tree structure optimized
        * for querying an intersection point with the timeline
        * events. Internally uses an [Interval Tree](https://en.wikipedia.org/wiki/Interval_tree)
        * to represent the data.
        * @internal
        */
    export class IntervalTimeline extends Tone {
            readonly name: string;
            /**
                * The event to add to the timeline. All events must
                * have a time and duration value
                * @param  event  The event to add to the timeline
                */
            add(event: IntervalTimelineEvent): this;
            /**
                * Remove an event from the timeline.
                * @param  event  The event to remove from the timeline
                */
            remove(event: IntervalTimelineEvent): this;
            /**
                * The number of items in the timeline.
                * @readOnly
                */
            get length(): number;
            /**
                * Remove events whose time time is after the given time
                * @param  after  The time to query.
                */
            cancel(after: number): this;
            /**
                * Get an event whose time and duration span the give time. Will
                * return the match whose "time" value is closest to the given time.
                * @return  The event which spans the desired time
                */
            get(time: number): IntervalTimelineEvent | null;
            /**
                * Iterate over everything in the timeline.
                * @param  callback The callback to invoke with every item
                */
            forEach(callback: IteratorCallback): this;
            /**
                * Iterate over everything in the array in which the given time
                * overlaps with the time and duration time of the event.
                * @param  time The time to check if items are overlapping
                * @param  callback The callback to invoke with every item
                */
            forEachAtTime(time: number, callback: IteratorCallback): this;
            /**
                * Iterate over everything in the array in which the time is greater
                * than or equal to the given time.
                * @param  time The time to check if items are before
                * @param  callback The callback to invoke with every item
                */
            forEachFrom(time: number, callback: IteratorCallback): this;
            /**
                * Clean up
                */
            dispose(): this;
    }
    export {};
}

declare module 'tone/core/util/Timeline' {
    import { Tone } from "tone/core/Tone";
    import { Seconds } from "tone/core/type/Units";
    type TimelineSearchParam = "ticks" | "time";
    /**
        * The options object for Timeline
        */
    interface TimelineOptions {
            memory: number;
            increasing: boolean;
    }
    /**
        * An event must have a time number
        */
    export interface TimelineEvent {
            time: number;
    }
    /**
        * A Timeline class for scheduling and maintaining state
        * along a timeline. All events must have a "time" property.
        * Internally, events are stored in time order for fast
        * retrieval.
        * @internal
        */
    export class Timeline<GenericEvent extends TimelineEvent> extends Tone {
            readonly name: string;
            /**
                * The memory of the timeline, i.e.
                * how many events in the past it will retain
                */
            memory: number;
            /**
                * The array of scheduled timeline events
                */
            protected _timeline: GenericEvent[];
            /**
                * If the time value must always be greater than or equal to the last
                * element on the list.
                */
            increasing: boolean;
            /**
                * @param memory The number of previous events that are retained.
                */
            constructor(memory?: number);
            constructor(options?: Partial<TimelineOptions>);
            static getDefaults(): TimelineOptions;
            /**
                * The number of items in the timeline.
                */
            get length(): number;
            /**
                * Insert an event object onto the timeline. Events must have a "time" attribute.
                * @param event  The event object to insert into the timeline.
                */
            add(event: GenericEvent): this;
            /**
                * Remove an event from the timeline.
                * @param  {Object}  event  The event object to remove from the list.
                * @returns {Timeline} this
                */
            remove(event: GenericEvent): this;
            /**
                * Get the nearest event whose time is less than or equal to the given time.
                * @param  time  The time to query.
                */
            get(time: number, param?: TimelineSearchParam): GenericEvent | null;
            /**
                * Return the first event in the timeline without removing it
                * @returns {Object} The first event object
                */
            peek(): GenericEvent | undefined;
            /**
                * Return the first event in the timeline and remove it
                */
            shift(): GenericEvent | undefined;
            /**
                * Get the event which is scheduled after the given time.
                * @param  time  The time to query.
                */
            getAfter(time: number, param?: TimelineSearchParam): GenericEvent | null;
            /**
                * Get the event before the event at the given time.
                * @param  time  The time to query.
                */
            getBefore(time: number): GenericEvent | null;
            /**
                * Cancel events at and after the given time
                * @param  after  The time to query.
                */
            cancel(after: number): this;
            /**
                * Cancel events before or equal to the given time.
                * @param  time  The time to cancel before.
                */
            cancelBefore(time: number): this;
            /**
                * Returns the previous event if there is one. null otherwise
                * @param  event The event to find the previous one of
                * @return The event right before the given event
                */
            previousEvent(event: GenericEvent): GenericEvent | null;
            /**
                * Does a binary search on the timeline array and returns the
                * nearest event index whose time is after or equal to the given time.
                * If a time is searched before the first index in the timeline, -1 is returned.
                * If the time is after the end, the index of the last item is returned.
                */
            protected _search(time: number, param?: TimelineSearchParam): number;
            /**
                * Iterate over everything in the array
                * @param  callback The callback to invoke with every item
                */
            forEach(callback: (event: GenericEvent) => void): this;
            /**
                * Iterate over everything in the array at or before the given time.
                * @param  time The time to check if items are before
                * @param  callback The callback to invoke with every item
                */
            forEachBefore(time: Seconds, callback: (event: GenericEvent) => void): this;
            /**
                * Iterate over everything in the array after the given time.
                * @param  time The time to check if items are before
                * @param  callback The callback to invoke with every item
                */
            forEachAfter(time: Seconds, callback: (event: GenericEvent) => void): this;
            /**
                * Iterate over everything in the array between the startTime and endTime.
                * The timerange is inclusive of the startTime, but exclusive of the endTime.
                * range = [startTime, endTime).
                * @param  startTime The time to check if items are before
                * @param  endTime The end of the test interval.
                * @param  callback The callback to invoke with every item
                */
            forEachBetween(startTime: number, endTime: number, callback: (event: GenericEvent) => void): this;
            /**
                * Iterate over everything in the array at or after the given time. Similar to
                * forEachAfter, but includes the item(s) at the given time.
                * @param  time The time to check if items are before
                * @param  callback The callback to invoke with every item
                */
            forEachFrom(time: number, callback: (event: GenericEvent) => void): this;
            /**
                * Iterate over everything in the array at the given time
                * @param  time The time to check if items are before
                * @param  callback The callback to invoke with every item
                */
            forEachAtTime(time: number, callback: (event: GenericEvent) => void): this;
            /**
                * Clean up.
                */
            dispose(): this;
    }
    export {};
}

declare module 'tone/core/util/TypeCheck' {
    import { Note } from "tone/core/type/Units";
    /**
        * Test if the arg is undefined
        */
    export function isUndef(arg: any): arg is undefined;
    /**
        * Test if the arg is not undefined
        */
    export function isDefined<T>(arg: T | undefined): arg is T;
    /**
        * Test if the arg is a function
        */
    export function isFunction(arg: any): arg is (a: any) => any;
    /**
        * Test if the argument is a number.
        */
    export function isNumber(arg: any): arg is number;
    /**
        * Test if the given argument is an object literal (i.e. `{}`);
        */
    export function isObject(arg: any): arg is object;
    /**
        * Test if the argument is a boolean.
        */
    export function isBoolean(arg: any): arg is boolean;
    /**
        * Test if the argument is an Array
        */
    export function isArray(arg: any): arg is any[];
    /**
        * Test if the argument is a string.
        */
    export function isString(arg: any): arg is string;
    /**
        * Test if the argument is in the form of a note in scientific pitch notation.
        * e.g. "C4"
        */
    export function isNote(arg: any): arg is Note;
}

declare module 'tone/core/type/Conversions' {
    import { Decibels, GainFactor, Hertz, Interval, MidiNote, NormalRange } from "tone/core/type/Units";
    /**
        * Equal power gain scale. Good for cross-fading.
        * @param  percent (0-1)
        */
    export function equalPowerScale(percent: NormalRange): number;
    /**
        * Convert decibels into gain.
        */
    export function dbToGain(db: Decibels): GainFactor;
    /**
        * Convert gain to decibels.
        */
    export function gainToDb(gain: GainFactor): Decibels;
    /**
        * Convert an interval (in semitones) to a frequency ratio.
        * @param interval the number of semitones above the base note
        * @example
        * Tone.intervalToFrequencyRatio(0); // 1
        * Tone.intervalToFrequencyRatio(12); // 2
        * Tone.intervalToFrequencyRatio(-12); // 0.5
        */
    export function intervalToFrequencyRatio(interval: Interval): number;
    export function getA4(): Hertz;
    export function setA4(freq: Hertz): void;
    /**
        * Convert a frequency value to a MIDI note.
        * @param frequency The value to frequency value to convert.
        * @example
        * Tone.ftom(440); // returns 69
        */
    export function ftom(frequency: Hertz): MidiNote;
    /**
        * Convert a frequency to a floating point midi value
        */
    export function ftomf(frequency: Hertz): number;
    /**
        * Convert a MIDI note to frequency value.
        * @param  midi The midi number to convert.
        * @return The corresponding frequency value
        * @example
        * Tone.mtof(69); // 440
        */
    export function mtof(midi: MidiNote): Hertz;
}

declare module 'tone/core/util/Defaults' {
    type BaseToneOptions = import("../Tone").BaseToneOptions;
    /**
        * Recursively merge an object
        * @param target the object to merge into
        * @param sources the source objects to merge
        */
    export function deepMerge<T>(target: T): T;
    export function deepMerge<T, U>(target: T, source1: U): T & U;
    export function deepMerge<T, U, V>(target: T, source1: U, source2: V): T & U & V;
    export function deepMerge<T, U, V, W>(target: T, source1: U, source2: V, source3: W): T & U & V & W;
    /**
        * Returns true if the two arrays have the same value for each of the elements
        */
    export function deepEquals<T>(arrayA: T[], arrayB: T[]): boolean;
    /**
        * Convert an args array into an object.
        * @internal
        */
    export function optionsFromArguments<T extends object>(defaults: T, argsArray: IArguments, keys?: Array<keyof T>, objKey?: keyof T): T;
    /**
        * Return this instances default values by calling Constructor.getDefaults()
        */
    export function getDefaultsFromInstance<T>(instance: T): BaseToneOptions;
    /**
        * Returns the fallback if the given object is undefined.
        * Take an array of arguments and return a formatted options object.
        * @internal
        */
    export function defaultArg<T>(given: T, fallback: T): T;
    /**
        * Remove all of the properties belonging to omit from obj.
        */
    export function omitFromObject<T extends object, O extends string[]>(obj: T, omit: O): Omit<T, keyof O>;
    export {};
}

declare module 'tone/core/util/Debug' {
    /**
        * Assert that the statement is true, otherwise invoke the error.
        * @param statement
        * @param error The message which is passed into an Error
        */
    export function assert(statement: boolean, error: string): asserts statement;
    /**
        * Make sure that the given value is within the range
        */
    export function assertRange(value: number, gte: number, lte?: number): void;
    /**
        * Warn if the context is not running.
        */
    export function assertContextRunning(context: import("../context/BaseContext").BaseContext): void;
    /**
        * Notify that the following block of code is occurring inside a Transport callback.
        */
    export function enterScheduledCallback(insideCallback: boolean): void;
    /**
        * Make sure that a time was passed into
        */
    export function assertUsedScheduleTime(time?: import("../type/Units").Time): void;
    /**
        * A basic logging interface
        */
    interface Logger {
            log: (args?: any[]) => void;
            warn: (args?: any[]) => void;
    }
    /**
        * Set the logging interface
        */
    export function setLogger(logger: Logger): void;
    /**
        * Log anything
        */
    export function log(...args: any[]): void;
    /**
        * Warn anything
        */
    export function warn(...args: any[]): void;
    export {};
}

declare module 'tone/source/Noise' {
    import { Positive, Time } from "tone/core/type/Units";
    import { Source, SourceOptions } from "tone/source/Source";
    export type NoiseType = "white" | "brown" | "pink";
    export interface NoiseOptions extends SourceOptions {
            type: NoiseType;
            playbackRate: Positive;
            fadeIn: Time;
            fadeOut: Time;
    }
    /**
        * Noise is a noise generator. It uses looped noise buffers to save on performance.
        * Noise supports the noise types: "pink", "white", and "brown". Read more about
        * colors of noise on [Wikipedia](https://en.wikipedia.org/wiki/Colors_of_noise).
        *
        * @example
        * // initialize the noise and start
        * const noise = new Tone.Noise("pink").start();
        * // make an autofilter to shape the noise
        * const autoFilter = new Tone.AutoFilter({
        * 	frequency: "8n",
        * 	baseFrequency: 200,
        * 	octaves: 8
        * }).toDestination().start();
        * // connect the noise
        * noise.connect(autoFilter);
        * // start the autofilter LFO
        * autoFilter.start();
        * @category Source
        */
    export class Noise extends Source<NoiseOptions> {
            readonly name: string;
            /**
                * The fadeIn time of the amplitude envelope.
                */
            protected _fadeIn: Time;
            /**
                * The fadeOut time of the amplitude envelope.
                */
            protected _fadeOut: Time;
            /**
                * @param type the noise type (white|pink|brown)
                */
            constructor(type?: NoiseType);
            constructor(options?: Partial<NoiseOptions>);
            static getDefaults(): NoiseOptions;
            /**
                * The type of the noise. Can be "white", "brown", or "pink".
                * @example
                * const noise = new Tone.Noise().toDestination().start();
                * noise.type = "brown";
                */
            get type(): NoiseType;
            set type(type: NoiseType);
            /**
                * The playback rate of the noise. Affects
                * the "frequency" of the noise.
                */
            get playbackRate(): Positive;
            set playbackRate(rate: Positive);
            /**
                * internal start method
                */
            protected _start(time?: Time): void;
            /**
                * internal stop method
                */
            protected _stop(time?: Time): void;
            /**
                * The fadeIn time of the amplitude envelope.
                */
            get fadeIn(): Time;
            set fadeIn(time: Time);
            /**
                * The fadeOut time of the amplitude envelope.
                */
            get fadeOut(): Time;
            set fadeOut(time: Time);
            protected _restart(time?: Time): void;
            /**
                * Clean up.
                */
            dispose(): this;
    }
}

declare module 'tone/source/UserMedia' {
    import { OutputNode, ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { Decibels } from "tone/core/type/Units";
    import { Param } from "tone/core/context/Param";
    export interface UserMediaOptions extends ToneAudioNodeOptions {
            volume: Decibels;
            mute: boolean;
    }
    /**
        * UserMedia uses MediaDevices.getUserMedia to open up and external microphone or audio input.
        * Check [MediaDevices API Support](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia)
        * to see which browsers are supported. Access to an external input
        * is limited to secure (HTTPS) connections.
        * @example
        * const meter = new Tone.Meter();
        * const mic = new Tone.UserMedia().connect(meter);
        * mic.open().then(() => {
        * 	// promise resolves when input is available
        * 	console.log("mic open");
        * 	// print the incoming mic levels in decibels
        * 	setInterval(() => console.log(meter.getValue()), 100);
        * }).catch(e => {
        * 	// promise is rejected when the user doesn't have or allow mic access
        * 	console.log("mic not open");
        * });
        * @category Source
        */
    export class UserMedia extends ToneAudioNode<UserMediaOptions> {
            readonly name: string;
            readonly input: undefined;
            readonly output: OutputNode;
            /**
                * The volume of the output in decibels.
                */
            readonly volume: Param<"decibels">;
            /**
                * @param volume The level of the input in decibels
                */
            constructor(volume?: Decibels);
            constructor(options?: Partial<UserMediaOptions>);
            static getDefaults(): UserMediaOptions;
            /**
                * Open the media stream. If a string is passed in, it is assumed
                * to be the label or id of the stream, if a number is passed in,
                * it is the input number of the stream.
                * @param  labelOrId The label or id of the audio input media device.
                *                   With no argument, the default stream is opened.
                * @return The promise is resolved when the stream is open.
                */
            open(labelOrId?: string | number): Promise<this>;
            /**
                * Close the media stream
                */
            close(): this;
            /**
                * Returns a promise which resolves with the list of audio input devices available.
                * @return The promise that is resolved with the devices
                * @example
                * Tone.UserMedia.enumerateDevices().then((devices) => {
                * 	// print the device labels
                * 	console.log(devices.map(device => device.label));
                * });
                */
            static enumerateDevices(): Promise<MediaDeviceInfo[]>;
            /**
                * Returns the playback state of the source, "started" when the microphone is open
                * and "stopped" when the mic is closed.
                */
            get state(): "started" | "stopped";
            /**
                * Returns an identifier for the represented device that is
                * persisted across sessions. It is un-guessable by other applications and
                * unique to the origin of the calling application. It is reset when the
                * user clears cookies (for Private Browsing, a different identifier is
                * used that is not persisted across sessions). Returns undefined when the
                * device is not open.
                */
            get deviceId(): string | undefined;
            /**
                * Returns a group identifier. Two devices have the
                * same group identifier if they belong to the same physical device.
                * Returns null  when the device is not open.
                */
            get groupId(): string | undefined;
            /**
                * Returns a label describing this device (for example "Built-in Microphone").
                * Returns undefined when the device is not open or label is not available
                * because of permissions.
                */
            get label(): string | undefined;
            /**
                * Mute the output.
                * @example
                * const mic = new Tone.UserMedia();
                * mic.open().then(() => {
                * 	// promise resolves when input is available
                * });
                * // mute the output
                * mic.mute = true;
                */
            get mute(): boolean;
            set mute(mute: boolean);
            dispose(): this;
            /**
                * If getUserMedia is supported by the browser.
                */
            static get supported(): boolean;
    }
}

declare module 'tone/source/oscillator/Oscillator' {
    import { AudioRange, Degrees, Frequency, Time } from "tone/core/type/Units";
    import { Signal } from "tone/signal/Signal";
    import { Source } from "tone/source/Source";
    import { ToneOscillatorConstructorOptions, ToneOscillatorInterface, ToneOscillatorOptions, ToneOscillatorType } from "tone/source/oscillator/OscillatorInterface";
    export { ToneOscillatorOptions, ToneOscillatorType } from "tone/source/oscillator/OscillatorInterface";
    /**
        * Oscillator supports a number of features including
        * phase rotation, multiple oscillator types (see Oscillator.type),
        * and Transport syncing (see Oscillator.syncFrequency).
        *
        * @example
        * // make and start a 440hz sine tone
        * const osc = new Tone.Oscillator(440, "sine").toDestination().start();
        * @category Source
        */
    export class Oscillator extends Source<ToneOscillatorOptions> implements ToneOscillatorInterface {
            readonly name: string;
            /**
                * The frequency control.
                */
            frequency: Signal<"frequency">;
            /**
                * The detune control signal.
                */
            detune: Signal<"cents">;
            /**
                * @param frequency Starting frequency
                * @param type The oscillator type. Read more about type below.
                */
            constructor(frequency?: Frequency, type?: ToneOscillatorType);
            constructor(options?: Partial<ToneOscillatorConstructorOptions>);
            static getDefaults(): ToneOscillatorOptions;
            /**
                * start the oscillator
                */
            protected _start(time?: Time): void;
            /**
                * stop the oscillator
                */
            protected _stop(time?: Time): void;
            /**
                * Restart the oscillator. Does not stop the oscillator, but instead
                * just cancels any scheduled 'stop' from being invoked.
                */
            protected _restart(time?: Time): this;
            /**
                * Sync the signal to the Transport's bpm. Any changes to the transports bpm,
                * will also affect the oscillators frequency.
                * @example
                * const osc = new Tone.Oscillator().toDestination().start();
                * osc.frequency.value = 440;
                * // the ratio between the bpm and the frequency will be maintained
                * osc.syncFrequency();
                * // double the tempo
                * Tone.Transport.bpm.value *= 2;
                * // the frequency of the oscillator is doubled to 880
                */
            syncFrequency(): this;
            /**
                * Unsync the oscillator's frequency from the Transport.
                * @see {@link syncFrequency}
                */
            unsyncFrequency(): this;
            get type(): ToneOscillatorType;
            set type(type: ToneOscillatorType);
            get baseType(): OscillatorType;
            set baseType(baseType: OscillatorType);
            get partialCount(): number;
            set partialCount(p: number);
            /**
                * Returns the initial value of the oscillator when stopped.
                * E.g. a "sine" oscillator with phase = 90 would return an initial value of -1.
                */
            getInitialValue(): AudioRange;
            get partials(): number[];
            set partials(partials: number[]);
            get phase(): Degrees;
            set phase(phase: Degrees);
            asArray(length?: number): Promise<Float32Array>;
            dispose(): this;
    }
}

declare module 'tone/source/oscillator/AMOscillator' {
    import { Degrees, Frequency, Seconds } from "tone/core/type/Units";
    import { Signal } from "tone/signal/Signal";
    import { Source } from "tone/source/Source";
    import { AMConstructorOptions, AMOscillatorOptions, ToneOscillatorInterface, ToneOscillatorType } from "tone/source/oscillator/OscillatorInterface";
    export { AMOscillatorOptions } from "tone/source/oscillator/OscillatorInterface";
    /**
        * An amplitude modulated oscillator node. It is implemented with
        * two oscillators, one which modulators the other's amplitude
        * through a gain node.
        * ```
        *    +-------------+       +----------+
        *    | Carrier Osc +>------> GainNode |
        *    +-------------+       |          +--->Output
        *                      +---> gain     |
        * +---------------+    |   +----------+
        * | Modulator Osc +>---+
        * +---------------+
        * ```
        * @example
        * return Tone.Offline(() => {
        * 	const amOsc = new Tone.AMOscillator(30, "sine", "square").toDestination().start();
        * }, 0.2, 1);
        * @category Source
        */
    export class AMOscillator extends Source<AMOscillatorOptions> implements ToneOscillatorInterface {
            readonly name: string;
            readonly frequency: Signal<"frequency">;
            readonly detune: Signal<"cents">;
            /**
                * Harmonicity is the frequency ratio between the carrier and the modulator oscillators.
                * A harmonicity of 1 gives both oscillators the same frequency.
                * Harmonicity = 2 means a change of an octave.
                * @example
                * const amOsc = new Tone.AMOscillator("D2").toDestination().start();
                * Tone.Transport.scheduleRepeat(time => {
                * 	amOsc.harmonicity.setValueAtTime(1, time);
                * 	amOsc.harmonicity.setValueAtTime(0.5, time + 0.5);
                * 	amOsc.harmonicity.setValueAtTime(1.5, time + 1);
                * 	amOsc.harmonicity.setValueAtTime(1, time + 2);
                * 	amOsc.harmonicity.linearRampToValueAtTime(2, time + 4);
                * }, 4);
                * Tone.Transport.start();
                */
            readonly harmonicity: Signal<"positive">;
            /**
                * @param frequency The starting frequency of the oscillator.
                * @param type The type of the carrier oscillator.
                * @param modulationType The type of the modulator oscillator.
                */
            constructor(frequency?: Frequency, type?: ToneOscillatorType, modulationType?: ToneOscillatorType);
            constructor(options?: Partial<AMConstructorOptions>);
            static getDefaults(): AMOscillatorOptions;
            /**
                * start the oscillator
                */
            protected _start(time: Seconds): void;
            /**
                * stop the oscillator
                */
            protected _stop(time: Seconds): void;
            protected _restart(time: Seconds): void;
            /**
                * The type of the carrier oscillator
                */
            get type(): ToneOscillatorType;
            set type(type: ToneOscillatorType);
            get baseType(): OscillatorType;
            set baseType(baseType: OscillatorType);
            get partialCount(): number;
            set partialCount(partialCount: number);
            /**
                * The type of the modulator oscillator
                */
            get modulationType(): ToneOscillatorType;
            set modulationType(type: ToneOscillatorType);
            get phase(): Degrees;
            set phase(phase: Degrees);
            get partials(): number[];
            set partials(partials: number[]);
            asArray(length?: number): Promise<Float32Array>;
            /**
                * Clean up.
                */
            dispose(): this;
    }
}

declare module 'tone/source/oscillator/FMOscillator' {
    import { Degrees, Frequency, Seconds, Time } from "tone/core/type/Units";
    import { Signal } from "tone/signal/Signal";
    import { Source } from "tone/source/Source";
    import { FMConstructorOptions, FMOscillatorOptions, ToneOscillatorInterface, ToneOscillatorType } from "tone/source/oscillator/OscillatorInterface";
    export { FMOscillatorOptions } from "tone/source/oscillator/OscillatorInterface";
    /**
        * FMOscillator implements a frequency modulation synthesis
        * ```
        *                                              +-------------+
        * +---------------+        +-------------+     | Carrier Osc |
        * | Modulator Osc +>-------> GainNode    |     |             +--->Output
        * +---------------+        |             +>----> frequency   |
        *                       +--> gain        |     +-------------+
        *                       |  +-------------+
        * +-----------------+   |
        * | modulationIndex +>--+
        * +-----------------+
        * ```
        *
        * @example
        * return Tone.Offline(() => {
        * 	const fmOsc = new Tone.FMOscillator({
        * 		frequency: 200,
        * 		type: "square",
        * 		modulationType: "triangle",
        * 		harmonicity: 0.2,
        * 		modulationIndex: 3
        * 	}).toDestination().start();
        * }, 0.1, 1);
        * @category Source
        */
    export class FMOscillator extends Source<FMOscillatorOptions> implements ToneOscillatorInterface {
            readonly name: string;
            readonly frequency: Signal<"frequency">;
            readonly detune: Signal<"cents">;
            /**
                * Harmonicity is the frequency ratio between the carrier and the modulator oscillators.
                * A harmonicity of 1 gives both oscillators the same frequency.
                * Harmonicity = 2 means a change of an octave.
                * @example
                * const fmOsc = new Tone.FMOscillator("D2").toDestination().start();
                * // pitch the modulator an octave below carrier
                * fmOsc.harmonicity.value = 0.5;
                */
            readonly harmonicity: Signal<"positive">;
            /**
                * The modulation index which is in essence the depth or amount of the modulation. In other terms it is the
                * ratio of the frequency of the modulating signal (mf) to the amplitude of the
                * modulating signal (ma) -- as in ma/mf.
                */
            readonly modulationIndex: Signal<"positive">;
            /**
                * @param frequency The starting frequency of the oscillator.
                * @param type The type of the carrier oscillator.
                * @param modulationType The type of the modulator oscillator.
                */
            constructor(frequency?: Frequency, type?: ToneOscillatorType, modulationType?: ToneOscillatorType);
            constructor(options?: Partial<FMConstructorOptions>);
            static getDefaults(): FMOscillatorOptions;
            /**
                * start the oscillator
                */
            protected _start(time: Time): void;
            /**
                * stop the oscillator
                */
            protected _stop(time: Time): void;
            protected _restart(time: Seconds): this;
            get type(): ToneOscillatorType;
            set type(type: ToneOscillatorType);
            get baseType(): OscillatorType;
            set baseType(baseType: OscillatorType);
            get partialCount(): number;
            set partialCount(partialCount: number);
            /**
                * The type of the modulator oscillator
                */
            get modulationType(): ToneOscillatorType;
            set modulationType(type: ToneOscillatorType);
            get phase(): Degrees;
            set phase(phase: Degrees);
            get partials(): number[];
            set partials(partials: number[]);
            asArray(length?: number): Promise<Float32Array>;
            /**
                * Clean up.
                */
            dispose(): this;
    }
}

declare module 'tone/source/oscillator/PulseOscillator' {
    import { AudioRange, Degrees, Frequency, Seconds, Time } from "tone/core/type/Units";
    import { Signal } from "tone/signal/Signal";
    import { Source } from "tone/source/Source";
    import { PulseOscillatorOptions, ToneOscillatorInterface } from "tone/source/oscillator/OscillatorInterface";
    export { PulseOscillatorOptions } from "tone/source/oscillator/OscillatorInterface";
    /**
        * PulseOscillator is an oscillator with control over pulse width,
        * also known as the duty cycle. At 50% duty cycle (width = 0) the wave is
        * a square wave.
        * [Read more](https://wigglewave.wordpress.com/2014/08/16/pulse-waveforms-and-harmonics/).
        * ```
        *    width = -0.25        width = 0.0          width = 0.25
        *
        *   +-----+            +-------+       +    +-------+     +-+
        *   |     |            |       |       |            |     |
        *   |     |            |       |       |            |     |
        * +-+     +-------+    +       +-------+            +-----+
        *
        *
        *    width = -0.5                              width = 0.5
        *
        *     +---+                                 +-------+   +---+
        *     |   |                                         |   |
        *     |   |                                         |   |
        * +---+   +-------+                                 +---+
        *
        *
        *    width = -0.75                             width = 0.75
        *
        *       +-+                                 +-------+ +-----+
        *       | |                                         | |
        *       | |                                         | |
        * +-----+ +-------+                                 +-+
        * ```
        * @example
        * return Tone.Offline(() => {
        * 	const pulse = new Tone.PulseOscillator(50, 0.4).toDestination().start();
        * }, 0.1, 1);
        * @category Source
        */
    export class PulseOscillator extends Source<PulseOscillatorOptions> implements ToneOscillatorInterface {
            readonly name: string;
            /**
                * The width of the pulse.
                * @example
                * return Tone.Offline(() => {
                * 	const pulse = new Tone.PulseOscillator(20, 0.8).toDestination().start();
                * }, 0.1, 1);
                */
            readonly width: Signal<"audioRange">;
            /**
                * The frequency control.
                */
            readonly frequency: Signal<"frequency">;
            /**
                * The detune in cents.
                */
            readonly detune: Signal<"cents">;
            /**
                * @param frequency The frequency of the oscillator
                * @param width The width of the pulse
                */
            constructor(frequency?: Frequency, width?: AudioRange);
            constructor(options?: Partial<PulseOscillatorOptions>);
            static getDefaults(): PulseOscillatorOptions;
            /**
                * start the oscillator
                */
            protected _start(time: Time): void;
            /**
                * stop the oscillator
                */
            protected _stop(time: Time): void;
            protected _restart(time: Seconds): void;
            /**
                * The phase of the oscillator in degrees.
                */
            get phase(): Degrees;
            set phase(phase: Degrees);
            /**
                * The type of the oscillator. Always returns "pulse".
                */
            get type(): "pulse";
            /**
                * The baseType of the oscillator. Always returns "pulse".
                */
            get baseType(): "pulse";
            /**
                * The partials of the waveform. Cannot set partials for this waveform type
                */
            get partials(): number[];
            /**
                * No partials for this waveform type.
                */
            get partialCount(): number;
            /**
                * *Internal use* The carrier oscillator type is fed through the
                * waveshaper node to create the pulse. Using different carrier oscillators
                * changes oscillator's behavior.
                */
            set carrierType(type: "triangle" | "sine");
            asArray(length?: number): Promise<Float32Array>;
            /**
                * Clean up method.
                */
            dispose(): this;
    }
}

declare module 'tone/source/oscillator/FatOscillator' {
    import { Cents, Degrees, Frequency, Seconds, Time } from "tone/core/type/Units";
    import { Signal } from "tone/signal/Signal";
    import { Source } from "tone/source/Source";
    import { FatConstructorOptions, FatOscillatorOptions, ToneOscillatorInterface, ToneOscillatorType } from "tone/source/oscillator/OscillatorInterface";
    export { FatOscillatorOptions } from "tone/source/oscillator/OscillatorInterface";
    /**
        * FatOscillator is an array of oscillators with detune spread between the oscillators
        * @example
        * const fatOsc = new Tone.FatOscillator("Ab3", "sawtooth", 40).toDestination().start();
        * @category Source
        */
    export class FatOscillator extends Source<FatOscillatorOptions> implements ToneOscillatorInterface {
            readonly name: string;
            readonly frequency: Signal<"frequency">;
            readonly detune: Signal<"cents">;
            /**
                * @param frequency The oscillator's frequency.
                * @param type The type of the oscillator.
                * @param spread The detune spread between the oscillators.
                */
            constructor(frequency?: Frequency, type?: ToneOscillatorType, spread?: Cents);
            constructor(options?: Partial<FatConstructorOptions>);
            static getDefaults(): FatOscillatorOptions;
            /**
                * start the oscillator
                */
            protected _start(time: Time): void;
            /**
                * stop the oscillator
                */
            protected _stop(time: Time): void;
            protected _restart(time: Seconds): void;
            /**
                * The type of the oscillator
                */
            get type(): ToneOscillatorType;
            set type(type: ToneOscillatorType);
            /**
                * The detune spread between the oscillators. If "count" is
                * set to 3 oscillators and the "spread" is set to 40,
                * the three oscillators would be detuned like this: [-20, 0, 20]
                * for a total detune spread of 40 cents.
                * @example
                * const fatOsc = new Tone.FatOscillator().toDestination().start();
                * fatOsc.spread = 70;
                */
            get spread(): Cents;
            set spread(spread: Cents);
            /**
                * The number of detuned oscillators. Must be an integer greater than 1.
                * @example
                * const fatOsc = new Tone.FatOscillator("C#3", "sawtooth").toDestination().start();
                * // use 4 sawtooth oscillators
                * fatOsc.count = 4;
                */
            get count(): number;
            set count(count: number);
            get phase(): Degrees;
            set phase(phase: Degrees);
            get baseType(): OscillatorType;
            set baseType(baseType: OscillatorType);
            get partials(): number[];
            set partials(partials: number[]);
            get partialCount(): number;
            set partialCount(partialCount: number);
            asArray(length?: number): Promise<Float32Array>;
            /**
                * Clean up.
                */
            dispose(): this;
    }
}

declare module 'tone/source/oscillator/PWMOscillator' {
    import { Degrees, Frequency, Seconds, Time } from "tone/core/type/Units";
    import { Signal } from "tone/signal/Signal";
    import { Source } from "tone/source/Source";
    import { PWMOscillatorOptions, ToneOscillatorInterface } from "tone/source/oscillator/OscillatorInterface";
    export { PWMOscillatorOptions } from "tone/source/oscillator/OscillatorInterface";
    /**
        * PWMOscillator modulates the width of a Tone.PulseOscillator
        * at the modulationFrequency. This has the effect of continuously
        * changing the timbre of the oscillator by altering the harmonics
        * generated.
        * @example
        * return Tone.Offline(() => {
        * 	const pwm = new Tone.PWMOscillator(60, 0.3).toDestination().start();
        * }, 0.1, 1);
        * @category Source
        */
    export class PWMOscillator extends Source<PWMOscillatorOptions> implements ToneOscillatorInterface {
            readonly name: string;
            readonly sourceType = "pwm";
            /**
                * The frequency control.
                */
            readonly frequency: Signal<"frequency">;
            /**
                * The detune of the oscillator.
                */
            readonly detune: Signal<"cents">;
            /**
                * The width modulation rate of the oscillator.
                * @example
                * return Tone.Offline(() => {
                * 	const osc = new Tone.PWMOscillator(20, 2).toDestination().start();
                * }, 0.1, 1);
                */
            readonly modulationFrequency: Signal<"frequency">;
            /**
                * @param {Frequency} frequency The starting frequency of the oscillator.
                * @param {Frequency} modulationFrequency The modulation frequency of the width of the pulse.
                */
            constructor(frequency?: Frequency, modulationFrequency?: Frequency);
            constructor(options?: Partial<PWMOscillatorOptions>);
            static getDefaults(): PWMOscillatorOptions;
            /**
                * start the oscillator
                */
            protected _start(time: Time): void;
            /**
                * stop the oscillator
                */
            protected _stop(time: Time): void;
            /**
                * restart the oscillator
                */
            protected _restart(time: Seconds): void;
            /**
                * The type of the oscillator. Always returns "pwm".
                */
            get type(): "pwm";
            /**
                * The baseType of the oscillator. Always returns "pwm".
                */
            get baseType(): "pwm";
            /**
                * The partials of the waveform. Cannot set partials for this waveform type
                */
            get partials(): number[];
            /**
                * No partials for this waveform type.
                */
            get partialCount(): number;
            /**
                * The phase of the oscillator in degrees.
                */
            get phase(): Degrees;
            set phase(phase: Degrees);
            asArray(length?: number): Promise<Float32Array>;
            /**
                * Clean up.
                */
            dispose(): this;
    }
}

declare module 'tone/source/oscillator/OmniOscillator' {
    import { Cents, Degrees, Frequency, Seconds, Time } from "tone/core/type/Units";
    import { Signal } from "tone/signal/Signal";
    import { Source } from "tone/source/Source";
    import { AMOscillator } from "tone/source/oscillator/AMOscillator";
    import { FatOscillator } from "tone/source/oscillator/FatOscillator";
    import { FMOscillator } from "tone/source/oscillator/FMOscillator";
    import { Oscillator } from "tone/source/oscillator/Oscillator";
    import { OmniOscillatorOptions, OmniOscillatorType, ToneOscillatorInterface, ToneOscillatorType } from "tone/source/oscillator/OscillatorInterface";
    import { PulseOscillator } from "tone/source/oscillator/PulseOscillator";
    import { PWMOscillator } from "tone/source/oscillator/PWMOscillator";
    export { OmniOscillatorOptions } from "tone/source/oscillator/OscillatorInterface";
    /**
        * All of the oscillator types that OmniOscillator can take on
        */
    type AnyOscillator = Oscillator | PWMOscillator | PulseOscillator | FatOscillator | AMOscillator | FMOscillator;
    /**
        * All of the Oscillator constructor types mapped to their name.
        */
    interface OmniOscillatorSource {
            "fm": FMOscillator;
            "am": AMOscillator;
            "pwm": PWMOscillator;
            "pulse": PulseOscillator;
            "oscillator": Oscillator;
            "fat": FatOscillator;
    }
    /**
        * The available oscillator types.
        */
    export type OmniOscSourceType = keyof OmniOscillatorSource;
    type IsAmOrFmOscillator<Osc, Ret> = Osc extends AMOscillator ? Ret : Osc extends FMOscillator ? Ret : undefined;
    type IsFatOscillator<Osc, Ret> = Osc extends FatOscillator ? Ret : undefined;
    type IsPWMOscillator<Osc, Ret> = Osc extends PWMOscillator ? Ret : undefined;
    type IsPulseOscillator<Osc, Ret> = Osc extends PulseOscillator ? Ret : undefined;
    type IsFMOscillator<Osc, Ret> = Osc extends FMOscillator ? Ret : undefined;
    /**
        * OmniOscillator aggregates all of the oscillator types into one.
        * @example
        * return Tone.Offline(() => {
        * 	const omniOsc = new Tone.OmniOscillator("C#4", "pwm").toDestination().start();
        * }, 0.1, 1);
        * @category Source
        */
    export class OmniOscillator<OscType extends AnyOscillator> extends Source<OmniOscillatorOptions> implements Omit<ToneOscillatorInterface, "type"> {
            readonly name: string;
            readonly frequency: Signal<"frequency">;
            readonly detune: Signal<"cents">;
            /**
                * @param frequency The initial frequency of the oscillator.
                * @param type The type of the oscillator.
                */
            constructor(frequency?: Frequency, type?: OmniOscillatorType);
            constructor(options?: Partial<OmniOscillatorOptions>);
            static getDefaults(): OmniOscillatorOptions;
            /**
                * start the oscillator
                */
            protected _start(time: Time): void;
            /**
                * start the oscillator
                */
            protected _stop(time: Time): void;
            protected _restart(time: Seconds): this;
            /**
                * The type of the oscillator. Can be any of the basic types: sine, square, triangle, sawtooth. Or
                * prefix the basic types with "fm", "am", or "fat" to use the FMOscillator, AMOscillator or FatOscillator
                * types. The oscillator could also be set to "pwm" or "pulse". All of the parameters of the
                * oscillator's class are accessible when the oscillator is set to that type, but throws an error
                * when it's not.
                * @example
                * const omniOsc = new Tone.OmniOscillator().toDestination().start();
                * omniOsc.type = "pwm";
                * // modulationFrequency is parameter which is available
                * // only when the type is "pwm".
                * omniOsc.modulationFrequency.value = 0.5;
                */
            get type(): OmniOscillatorType;
            set type(type: OmniOscillatorType);
            /**
                * The value is an empty array when the type is not "custom".
                * This is not available on "pwm" and "pulse" oscillator types.
                * @see {@link Oscillator.partials}
                */
            get partials(): number[];
            set partials(partials: number[]);
            get partialCount(): number;
            set partialCount(partialCount: number);
            set(props: Partial<OmniOscillatorOptions>): this;
            get phase(): Degrees;
            set phase(phase: Degrees);
            /**
                * The source type of the oscillator.
                * @example
                * const omniOsc = new Tone.OmniOscillator(440, "fmsquare");
                * console.log(omniOsc.sourceType); // 'fm'
                */
            get sourceType(): OmniOscSourceType;
            set sourceType(sType: OmniOscSourceType);
            /**
                * The base type of the oscillator.
                * @see {@link Oscillator.baseType}
                * @example
                * const omniOsc = new Tone.OmniOscillator(440, "fmsquare4");
                * console.log(omniOsc.sourceType, omniOsc.baseType, omniOsc.partialCount);
                */
            get baseType(): OscillatorType | "pwm" | "pulse";
            set baseType(baseType: OscillatorType | "pwm" | "pulse");
            /**
                * The width of the oscillator when sourceType === "pulse".
                * @see {@link PWMOscillator}
                */
            get width(): IsPulseOscillator<OscType, Signal<"audioRange">>;
            /**
                * The number of detuned oscillators when sourceType === "fat".
                * @see {@link FatOscillator.count}
                */
            get count(): IsFatOscillator<OscType, number>;
            set count(count: IsFatOscillator<OscType, number>);
            /**
                * The detune spread between the oscillators when sourceType === "fat".
                * @see {@link FatOscillator.count}
                */
            get spread(): IsFatOscillator<OscType, Cents>;
            set spread(spread: IsFatOscillator<OscType, Cents>);
            /**
                * The type of the modulator oscillator. Only if the oscillator is set to "am" or "fm" types.
                * @see {@link AMOscillator} or {@link FMOscillator}
                */
            get modulationType(): IsAmOrFmOscillator<OscType, ToneOscillatorType>;
            set modulationType(mType: IsAmOrFmOscillator<OscType, ToneOscillatorType>);
            /**
                * The modulation index when the sourceType === "fm"
                * @see {@link FMOscillator}.
                */
            get modulationIndex(): IsFMOscillator<OscType, Signal<"positive">>;
            /**
                * Harmonicity is the frequency ratio between the carrier and the modulator oscillators.
                * @see {@link AMOscillator} or {@link FMOscillator}
                */
            get harmonicity(): IsAmOrFmOscillator<OscType, Signal<"positive">>;
            /**
                * The modulationFrequency Signal of the oscillator when sourceType === "pwm"
                * see {@link PWMOscillator}
                * @min 0.1
                * @max 5
                */
            get modulationFrequency(): IsPWMOscillator<OscType, Signal<"frequency">>;
            asArray(length?: number): Promise<Float32Array>;
            dispose(): this;
    }
}

declare module 'tone/source/oscillator/ToneOscillatorNode' {
    import { Param } from "tone/core/context/Param";
    import { Cents, Frequency, Seconds, Time } from "tone/core/type/Units";
    import { OneShotSource, OneShotSourceOptions } from "tone/source/OneShotSource";
    export interface ToneOscillatorNodeOptions extends OneShotSourceOptions {
            frequency: Frequency;
            detune: Cents;
            type: OscillatorType;
    }
    /**
        * Wrapper around the native fire-and-forget OscillatorNode.
        * Adds the ability to reschedule the stop method.
        * ***{@link Oscillator} is better for most use-cases***
        * @category Source
        */
    export class ToneOscillatorNode extends OneShotSource<ToneOscillatorNodeOptions> {
            readonly name: string;
            protected _internalChannels: OscillatorNode[];
            /**
                * The frequency of the oscillator
                */
            readonly frequency: Param<"frequency">;
            /**
                * The detune of the oscillator
                */
            readonly detune: Param<"cents">;
            /**
                * @param  frequency   The frequency value
                * @param  type  The basic oscillator type
                */
            constructor(frequency: Frequency, type: OscillatorType);
            constructor(options?: Partial<ToneOscillatorNodeOptions>);
            static getDefaults(): ToneOscillatorNodeOptions;
            /**
                * Start the oscillator node at the given time
                * @param  time When to start the oscillator
                */
            start(time?: Time): this;
            protected _stopSource(time?: Seconds): void;
            /**
                * Sets an arbitrary custom periodic waveform given a PeriodicWave.
                * @param  periodicWave PeriodicWave should be created with context.createPeriodicWave
                */
            setPeriodicWave(periodicWave: PeriodicWave): this;
            /**
                * The oscillator type. Either 'sine', 'sawtooth', 'square', or 'triangle'
                */
            get type(): OscillatorType;
            set type(type: OscillatorType);
            /**
                * Clean up.
                */
            dispose(): this;
    }
}

declare module 'tone/source/oscillator/LFO' {
    import { Param } from "tone/core/context/Param";
    import { InputNode, OutputNode, ToneAudioNode } from "tone/core/context/ToneAudioNode";
    import { Degrees, Frequency, NormalRange, Time, UnitName } from "tone/core/type/Units";
    import { BasicPlaybackState } from "tone/core/util/StateTimeline";
    import { Signal } from "tone/signal/Signal";
    import { ToneOscillatorType } from "tone/source/oscillator/Oscillator";
    import { ToneOscillatorOptions } from "tone/source/oscillator/OscillatorInterface";
    export type LFOOptions = {
            min: number;
            max: number;
            amplitude: NormalRange;
            units: UnitName;
    } & ToneOscillatorOptions;
    /**
        * LFO stands for low frequency oscillator. LFO produces an output signal
        * which can be attached to an AudioParam or Tone.Signal
        * in order to modulate that parameter with an oscillator. The LFO can
        * also be synced to the transport to start/stop and change when the tempo changes.
        * @example
        * return Tone.Offline(() => {
        * 	const lfo = new Tone.LFO("4n", 400, 4000).start().toDestination();
        * }, 0.5, 1);
        * @category Source
        */
    export class LFO extends ToneAudioNode<LFOOptions> {
            readonly name: string;
            /**
                * The amplitude of the LFO, which controls the output range between
                * the min and max output. For example if the min is -10 and the max
                * is 10, setting the amplitude to 0.5 would make the LFO modulate
                * between -5 and 5.
                */
            readonly amplitude: Param<"normalRange">;
            /**
                * The output of the LFO
                */
            readonly output: OutputNode;
            /**
                * There is no input node
                */
            readonly input: undefined;
            /**
                * If the input value is converted using the {@link units}
                */
            convert: boolean;
            /**
                * The frequency value of the LFO
                */
            readonly frequency: Signal<"frequency">;
            /**
                * @param frequency The frequency of the oscillation.
                * Typically, LFOs will be in the frequency range of 0.1 to 10 hertz.
                * @param min The minimum output value of the LFO.
                * @param max The maximum value of the LFO.
                */
            constructor(frequency?: Frequency, min?: number, max?: number);
            constructor(options?: Partial<LFOOptions>);
            static getDefaults(): LFOOptions;
            /**
                * Start the LFO.
                * @param time The time the LFO will start
                */
            start(time?: Time): this;
            /**
                * Stop the LFO.
                * @param  time The time the LFO will stop
                */
            stop(time?: Time): this;
            /**
                * Sync the start/stop/pause to the transport
                * and the frequency to the bpm of the transport
                * @example
                * const lfo = new Tone.LFO("8n");
                * lfo.sync().start(0);
                * // the rate of the LFO will always be an eighth note, even as the tempo changes
                */
            sync(): this;
            /**
                * unsync the LFO from transport control
                */
            unsync(): this;
            /**
                * The minimum output of the LFO.
                */
            get min(): number;
            set min(min: number);
            /**
                * The maximum output of the LFO.
                */
            get max(): number;
            set max(max: number);
            /**
                * The type of the oscillator.
                * @see {@link Oscillator.type}
                */
            get type(): ToneOscillatorType;
            set type(type: ToneOscillatorType);
            /**
                * The oscillator's partials array.
                * @see {@link Oscillator.partials}
                */
            get partials(): number[];
            set partials(partials: number[]);
            /**
                * The phase of the LFO.
                */
            get phase(): Degrees;
            set phase(phase: Degrees);
            /**
                * The output units of the LFO.
                */
            get units(): UnitName;
            set units(val: UnitName);
            /**
                * Returns the playback state of the source, either "started" or "stopped".
                */
            get state(): BasicPlaybackState;
            /**
                * @param node the destination to connect to
                * @param outputNum the optional output number
                * @param inputNum the input number
                */
            connect(node: InputNode, outputNum?: number, inputNum?: number): this;
            dispose(): this;
    }
}

declare module 'tone/source/buffer/Player' {
    import { ToneAudioBuffer } from "tone/core/context/ToneAudioBuffer";
    import { Positive, Seconds, Time } from "tone/core/type/Units";
    import { Source, SourceOptions } from "tone/source/Source";
    export interface PlayerOptions extends SourceOptions {
            onload: () => void;
            onerror: (error: Error) => void;
            playbackRate: Positive;
            loop: boolean;
            autostart: boolean;
            loopStart: Time;
            loopEnd: Time;
            reverse: boolean;
            fadeIn: Time;
            fadeOut: Time;
            url?: ToneAudioBuffer | string | AudioBuffer;
    }
    /**
        * Player is an audio file player with start, loop, and stop functions.
        * @example
        * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/gong_1.mp3").toDestination();
        * // play as soon as the buffer is loaded
        * player.autostart = true;
        * @category Source
        */
    export class Player extends Source<PlayerOptions> {
            readonly name: string;
            /**
                * If the file should play as soon
                * as the buffer is loaded.
                */
            autostart: boolean;
            /**
                * The fadeIn time of the amplitude envelope.
                */
            fadeIn: Time;
            /**
                * The fadeOut time of the amplitude envelope.
                */
            fadeOut: Time;
            /**
                * @param url Either the AudioBuffer or the url from which to load the AudioBuffer
                * @param onload The function to invoke when the buffer is loaded.
                */
            constructor(url?: string | AudioBuffer | ToneAudioBuffer, onload?: () => void);
            constructor(options?: Partial<PlayerOptions>);
            static getDefaults(): PlayerOptions;
            /**
                * Load the audio file as an audio buffer.
                * Decodes the audio asynchronously and invokes
                * the callback once the audio buffer loads.
                * Note: this does not need to be called if a url
                * was passed in to the constructor. Only use this
                * if you want to manually load a new url.
                * @param url The url of the buffer to load. Filetype support depends on the browser.
                */
            load(url: string): Promise<this>;
            /**
                * Play the buffer at the given startTime. Optionally add an offset
                * and/or duration which will play the buffer from a position
                * within the buffer for the given duration.
                *
                * @param  time When the player should start.
                * @param  offset The offset from the beginning of the sample to start at.
                * @param  duration How long the sample should play. If no duration is given, it will default to the full length of the sample (minus any offset)
                */
            start(time?: Time, offset?: Time, duration?: Time): this;
            /**
                * Internal start method
                */
            protected _start(startTime?: Time, offset?: Time, duration?: Time): void;
            /**
                * Stop playback.
                */
            protected _stop(time?: Time): void;
            /**
                * Stop and then restart the player from the beginning (or offset)
                * @param  time When the player should start.
                * @param  offset The offset from the beginning of the sample to start at.
                * @param  duration How long the sample should play. If no duration is given,
                * 					it will default to the full length of the sample (minus any offset)
                */
            restart(time?: Seconds, offset?: Time, duration?: Time): this;
            protected _restart(time?: Seconds, offset?: Time, duration?: Time): void;
            /**
                * Seek to a specific time in the player's buffer. If the
                * source is no longer playing at that time, it will stop.
                * @param offset The time to seek to.
                * @param when The time for the seek event to occur.
                * @example
                * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/gurgling_theremin_1.mp3", () => {
                * 	player.start();
                * 	// seek to the offset in 1 second from now
                * 	player.seek(0.4, "+1");
                * }).toDestination();
                */
            seek(offset: Time, when?: Time): this;
            /**
                * Set the loop start and end. Will only loop if loop is set to true.
                * @param loopStart The loop start time
                * @param loopEnd The loop end time
                * @example
                * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/malevoices_aa2_F3.mp3").toDestination();
                * // loop between the given points
                * player.setLoopPoints(0.2, 0.3);
                * player.loop = true;
                * player.autostart = true;
                */
            setLoopPoints(loopStart: Time, loopEnd: Time): this;
            /**
                * If loop is true, the loop will start at this position.
                */
            get loopStart(): Time;
            set loopStart(loopStart: Time);
            /**
                * If loop is true, the loop will end at this position.
                */
            get loopEnd(): Time;
            set loopEnd(loopEnd: Time);
            /**
                * The audio buffer belonging to the player.
                */
            get buffer(): ToneAudioBuffer;
            set buffer(buffer: ToneAudioBuffer);
            /**
                * If the buffer should loop once it's over.
                * @example
                * const player = new Tone.Player("https://tonejs.github.io/audio/drum-samples/breakbeat.mp3").toDestination();
                * player.loop = true;
                * player.autostart = true;
                */
            get loop(): boolean;
            set loop(loop: boolean);
            /**
                * Normal speed is 1. The pitch will change with the playback rate.
                * @example
                * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/femalevoices_aa2_A5.mp3").toDestination();
                * // play at 1/4 speed
                * player.playbackRate = 0.25;
                * // play as soon as the buffer is loaded
                * player.autostart = true;
                */
            get playbackRate(): Positive;
            set playbackRate(rate: Positive);
            /**
                * If the buffer should be reversed. Note that this sets the underlying {@link ToneAudioBuffer.reverse}, so
                * if multiple players are pointing at the same ToneAudioBuffer, they will all be reversed.
                * @example
                * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/chime_1.mp3").toDestination();
                * player.autostart = true;
                * player.reverse = true;
                */
            get reverse(): boolean;
            set reverse(rev: boolean);
            /**
                * If the buffer is loaded
                */
            get loaded(): boolean;
            dispose(): this;
    }
}

declare module 'tone/source/buffer/Players' {
    import { Param } from "tone/core/context/Param";
    import { ToneAudioBuffer } from "tone/core/context/ToneAudioBuffer";
    import { ToneAudioBuffersUrlMap } from "tone/core/context/ToneAudioBuffers";
    import { OutputNode, ToneAudioNode } from "tone/core/context/ToneAudioNode";
    import { Decibels, Time } from "tone/core/type/Units";
    import { BasicPlaybackState } from "tone/core/util/StateTimeline";
    import { SourceOptions } from "tone/source/Source";
    import { Player } from "tone/source/buffer/Player";
    export interface PlayersOptions extends SourceOptions {
            urls: ToneAudioBuffersUrlMap;
            volume: Decibels;
            mute: boolean;
            onload: () => void;
            onerror: (error: Error) => void;
            baseUrl: string;
            fadeIn: Time;
            fadeOut: Time;
    }
    /**
        * Players combines multiple {@link Player} objects.
        * @category Source
        */
    export class Players extends ToneAudioNode<PlayersOptions> {
            readonly name: string;
            /**
                * The volume of the output in decibels.
                */
            readonly volume: Param<"decibels">;
            /**
                * The combined output of all of the players
                */
            readonly output: OutputNode;
            /**
                * Players has no input.
                */
            readonly input: undefined;
            /**
                * @param urls An object mapping a name to a url.
                * @param onload The function to invoke when all buffers are loaded.
                */
            constructor(urls?: ToneAudioBuffersUrlMap, onload?: () => void);
            /**
                * @param urls An object mapping a name to a url.
                * @param options The remaining options associated with the players
                */
            constructor(urls?: ToneAudioBuffersUrlMap, options?: Partial<Omit<PlayersOptions, "urls">>);
            constructor(options?: Partial<PlayersOptions>);
            static getDefaults(): PlayersOptions;
            /**
                * Mute the output.
                */
            get mute(): boolean;
            set mute(mute: boolean);
            /**
                * The fadeIn time of the envelope applied to the source.
                */
            get fadeIn(): Time;
            set fadeIn(fadeIn: Time);
            /**
                * The fadeOut time of the each of the sources.
                */
            get fadeOut(): Time;
            set fadeOut(fadeOut: Time);
            /**
                * The state of the players object. Returns "started" if any of the players are playing.
                */
            get state(): BasicPlaybackState;
            /**
                * True if the buffers object has a buffer by that name.
                * @param name  The key or index of the buffer.
                */
            has(name: string): boolean;
            /**
                * Get a player by name.
                * @param  name  The players name as defined in the constructor object or `add` method.
                */
            player(name: string): Player;
            /**
                * If all the buffers are loaded or not
                */
            get loaded(): boolean;
            /**
                * Add a player by name and url to the Players
                * @param  name A unique name to give the player
                * @param  url  Either the url of the bufer or a buffer which will be added with the given name.
                * @param callback  The callback to invoke when the url is loaded.
                * @example
                * const players = new Tone.Players();
                * players.add("gong", "https://tonejs.github.io/audio/berklee/gong_1.mp3", () => {
                * 	console.log("gong loaded");
                * 	players.player("gong").start();
                * });
                */
            add(name: string, url: string | ToneAudioBuffer | AudioBuffer, callback?: () => void): this;
            /**
                * Stop all of the players at the given time
                * @param time The time to stop all of the players.
                */
            stopAll(time?: Time): this;
            dispose(): this;
    }
}

declare module 'tone/source/buffer/GrainPlayer' {
    import { Source, SourceOptions } from "tone/source/Source";
    import { ToneAudioBuffer } from "tone/core/context/ToneAudioBuffer";
    import { Cents, Positive, Seconds, Time } from "tone/core/type/Units";
    interface GrainPlayerOptions extends SourceOptions {
            onload: () => void;
            onerror: (error: Error) => void;
            reverse: boolean;
            url?: ToneAudioBuffer | string | AudioBuffer;
            overlap: Seconds;
            grainSize: Seconds;
            playbackRate: Positive;
            detune: Cents;
            loop: boolean;
            loopStart: Time;
            loopEnd: Time;
    }
    /**
        * GrainPlayer implements [granular synthesis](https://en.wikipedia.org/wiki/Granular_synthesis).
        * Granular Synthesis enables you to adjust pitch and playback rate independently. The grainSize is the
        * amount of time each small chunk of audio is played for and the overlap is the
        * amount of crossfading transition time between successive grains.
        * @category Source
        */
    export class GrainPlayer extends Source<GrainPlayerOptions> {
            readonly name: string;
            /**
                * The audio buffer belonging to the player.
                */
            buffer: ToneAudioBuffer;
            /**
                * Adjust the pitch independently of the playbackRate.
                */
            detune: Cents;
            /**
                * If the buffer should loop back to the loopStart when completed
                */
            loop: boolean;
            /**
                * @param url Either the AudioBuffer or the url from which to load the AudioBuffer
                * @param onload The function to invoke when the buffer is loaded.
                */
            constructor(url?: string | AudioBuffer | ToneAudioBuffer, onload?: () => void);
            constructor(options?: Partial<GrainPlayerOptions>);
            static getDefaults(): GrainPlayerOptions;
            /**
                * Internal start method
                */
            protected _start(time?: Time, offset?: Time, duration?: Time): void;
            /**
                * Stop and then restart the player from the beginning (or offset)
                * @param  time When the player should start.
                * @param  offset The offset from the beginning of the sample to start at.
                * @param  duration How long the sample should play. If no duration is given,
                * 					it will default to the full length of the sample (minus any offset)
                */
            restart(time?: Seconds, offset?: Time, duration?: Time): this;
            protected _restart(time?: Seconds, offset?: Time, duration?: Time): void;
            /**
                * Internal stop method
                */
            protected _stop(time?: Time): void;
            /**
                * The playback rate of the sample
                */
            get playbackRate(): Positive;
            set playbackRate(rate: Positive);
            /**
                * The loop start time.
                */
            get loopStart(): Time;
            set loopStart(time: Time);
            /**
                * The loop end time.
                */
            get loopEnd(): Time;
            set loopEnd(time: Time);
            /**
                * The direction the buffer should play in
                */
            get reverse(): boolean;
            set reverse(rev: boolean);
            /**
                * The size of each chunk of audio that the
                * buffer is chopped into and played back at.
                */
            get grainSize(): Time;
            set grainSize(size: Time);
            /**
                * The duration of the cross-fade between successive grains.
                */
            get overlap(): Time;
            set overlap(time: Time);
            /**
                * If all the buffer is loaded
                */
            get loaded(): boolean;
            dispose(): this;
    }
    export {};
}

declare module 'tone/signal/Add' {
    import { Gain } from "tone/core/context/Gain";
    import { Param } from "tone/core/context/Param";
    import { Signal, SignalOptions } from "tone/signal/Signal";
    /**
        * Add a signal and a number or two signals. When no value is
        * passed into the constructor, Tone.Add will sum input and `addend`
        * If a value is passed into the constructor, the it will be added to the input.
        *
        * @example
        * return Tone.Offline(() => {
        * 	const add = new Tone.Add(2).toDestination();
        * 	add.addend.setValueAtTime(1, 0.2);
        * 	const signal = new Tone.Signal(2);
        * 	// add a signal and a scalar
        * 	signal.connect(add);
        * 	signal.setValueAtTime(1, 0.1);
        * }, 0.5, 1);
        * @category Signal
        */
    export class Add extends Signal {
            override: boolean;
            readonly name: string;
            readonly input: Gain<"gain">;
            readonly output: Gain<"gain">;
            /**
                * The value which is added to the input signal
                */
            readonly addend: Param<"number">;
            /**
                * @param value If no value is provided, will sum the input and {@link addend}.
                */
            constructor(value?: number);
            constructor(options?: Partial<SignalOptions<"number">>);
            static getDefaults(): SignalOptions<"number">;
            dispose(): this;
    }
}

declare module 'tone/signal/Abs' {
    import { ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { SignalOperator } from "tone/signal/SignalOperator";
    import { WaveShaper } from "tone/signal/WaveShaper";
    /**
        * Return the absolute value of an incoming signal.
        *
        * @example
        * return Tone.Offline(() => {
        * 	const abs = new Tone.Abs().toDestination();
        * 	const signal = new Tone.Signal(1);
        * 	signal.rampTo(-1, 0.5);
        * 	signal.connect(abs);
        * }, 0.5, 1);
        * @category Signal
        */
    export class Abs extends SignalOperator<ToneAudioNodeOptions> {
            readonly name: string;
            /**
                * The AudioRange input [-1, 1]
                */
            input: WaveShaper;
            /**
                * The output range [0, 1]
                */
            output: WaveShaper;
            /**
                * clean up
                */
            dispose(): this;
    }
}

declare module 'tone/signal/AudioToGain' {
    import { ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { SignalOperator } from "tone/signal/SignalOperator";
    import { WaveShaper } from "tone/signal/WaveShaper";
    /**
        * AudioToGain converts an input in AudioRange [-1,1] to NormalRange [0,1].
        * @see {@link GainToAudio}.
        * @category Signal
        */
    export class AudioToGain extends SignalOperator<ToneAudioNodeOptions> {
            readonly name: string;
            /**
                * The AudioRange input [-1, 1]
                */
            input: WaveShaper;
            /**
                * The GainRange output [0, 1]
                */
            output: WaveShaper;
            /**
                * clean up
                */
            dispose(): this;
    }
}

declare module 'tone/signal/GainToAudio' {
    import { ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { SignalOperator } from "tone/signal/SignalOperator";
    import { WaveShaper } from "tone/signal/WaveShaper";
    /**
        * GainToAudio converts an input in NormalRange [0,1] to AudioRange [-1,1].
        * @see {@link AudioToGain}.
        * @category Signal
        */
    export class GainToAudio extends SignalOperator<ToneAudioNodeOptions> {
            readonly name: string;
            /**
                * The NormalRange input [0, 1]
                */
            input: WaveShaper;
            /**
                * The AudioRange output [-1, 1]
                */
            output: WaveShaper;
            /**
                * clean up
                */
            dispose(): this;
    }
}

declare module 'tone/signal/GreaterThan' {
    import { ToneAudioNode } from "tone/core/context/ToneAudioNode";
    import { Signal, SignalOptions } from "tone/signal/Signal";
    import { Param } from "tone/core/context/Param";
    export type GreaterThanOptions = SignalOptions<"number">;
    /**
        * Output 1 if the signal is greater than the value, otherwise outputs 0.
        * can compare two signals or a signal and a number.
        *
        * @example
        * return Tone.Offline(() => {
        * 	const gt = new Tone.GreaterThan(2).toDestination();
        * 	const sig = new Tone.Signal(4).connect(gt);
        * }, 0.1, 1);
        * @category Signal
        */
    export class GreaterThan extends Signal<"number"> {
            readonly name: string;
            readonly override: boolean;
            readonly input: ToneAudioNode;
            readonly output: ToneAudioNode;
            /**
                * The signal to compare to the incoming signal against.
                * @example
                * return Tone.Offline(() => {
                * 	// change the comparison value
                * 	const gt = new Tone.GreaterThan(1.5).toDestination();
                * 	const signal = new Tone.Signal(1).connect(gt);
                * 	gt.comparator.setValueAtTime(0.5, 0.1);
                * }, 0.5, 1);
                */
            readonly comparator: Param<"number">;
            /**
                * @param value The value to compare to
                */
            constructor(value?: number);
            constructor(options?: Partial<GreaterThanOptions>);
            static getDefaults(): GreaterThanOptions;
            dispose(): this;
    }
}

declare module 'tone/signal/GreaterThanZero' {
    import { SignalOperator, SignalOperatorOptions } from "tone/signal/SignalOperator";
    import { ToneAudioNode } from "tone/core/context/ToneAudioNode";
    export type GreaterThanZeroOptions = SignalOperatorOptions;
    /**
        * GreaterThanZero outputs 1 when the input is strictly greater than zero
        * @example
        * return Tone.Offline(() => {
        * 	const gt0 = new Tone.GreaterThanZero().toDestination();
        * 	const sig = new Tone.Signal(0.5).connect(gt0);
        * 	sig.setValueAtTime(-1, 0.05);
        * }, 0.1, 1);
        * @category Signal
        */
    export class GreaterThanZero extends SignalOperator<GreaterThanZeroOptions> {
            readonly name: string;
            readonly output: ToneAudioNode;
            readonly input: ToneAudioNode;
            constructor(options?: Partial<GreaterThanZeroOptions>);
            dispose(): this;
    }
}

declare module 'tone/signal/Multiply' {
    import { Param } from "tone/core/context/Param";
    import { Signal, SignalOptions } from "tone/signal/Signal";
    import { InputNode, OutputNode } from "tone/core/context/ToneAudioNode";
    /**
        * Multiply two incoming signals. Or, if a number is given in the constructor,
        * multiplies the incoming signal by that value.
        *
        * @example
        * // multiply two signals
        * const mult = new Tone.Multiply();
        * const sigA = new Tone.Signal(3);
        * const sigB = new Tone.Signal(4);
        * sigA.connect(mult);
        * sigB.connect(mult.factor);
        * // output of mult is 12.
        * @example
        * // multiply a signal and a number
        * const mult = new Tone.Multiply(10);
        * const sig = new Tone.Signal(2).connect(mult);
        * // the output of mult is 20.
        * @category Signal
        */
    export class Multiply<TypeName extends "number" | "positive" = "number"> extends Signal<TypeName> {
            readonly name: string;
            /**
                * Indicates if the value should be overridden on connection
                */
            readonly override = false;
            /**
                * The multiplicand input.
                */
            input: InputNode;
            /**
                * The product of the input and {@link factor}
                */
            output: OutputNode;
            /**
                * The multiplication factor. Can be set directly or a signal can be connected to it.
                */
            factor: Param<TypeName>;
            /**
                * @param value Constant value to multiple
                */
            constructor(value?: number);
            constructor(options?: Partial<SignalOptions<TypeName>>);
            static getDefaults(): SignalOptions<any>;
            dispose(): this;
    }
}

declare module 'tone/signal/Negate' {
    import { ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { Multiply } from "tone/signal/Multiply";
    import { SignalOperator } from "tone/signal/SignalOperator";
    /**
        * Negate the incoming signal. i.e. an input signal of 10 will output -10
        *
        * @example
        * const neg = new Tone.Negate();
        * const sig = new Tone.Signal(-2).connect(neg);
        * // output of neg is positive 2.
        * @category Signal
        */
    export class Negate extends SignalOperator<ToneAudioNodeOptions> {
            readonly name: string;
            /**
                * The input and output are equal to the multiply node
                */
            input: Multiply<"number">;
            output: Multiply<"number">;
            /**
                * clean up
                * @returns {Negate} this
                */
            dispose(): this;
    }
}

declare module 'tone/signal/Pow' {
    import { WaveShaper } from "tone/signal/WaveShaper";
    import { SignalOperator } from "tone/signal/SignalOperator";
    import { ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    export interface PowOptions extends ToneAudioNodeOptions {
            value: number;
    }
    /**
        * Pow applies an exponent to the incoming signal. The incoming signal must be AudioRange [-1, 1]
        *
        * @example
        * const pow = new Tone.Pow(2);
        * const sig = new Tone.Signal(0.5).connect(pow);
        * // output of pow is 0.25.
        * @category Signal
        */
    export class Pow extends SignalOperator<PowOptions> {
            readonly name: string;
            input: WaveShaper;
            output: WaveShaper;
            /**
                * @param value Constant exponent value to use
                */
            constructor(value?: number);
            constructor(options?: Partial<PowOptions>);
            static getDefaults(): PowOptions;
            /**
                * The value of the exponent.
                */
            get value(): number;
            set value(exponent: number);
            /**
                * Clean up.
                */
            dispose(): this;
    }
}

declare module 'tone/signal/Scale' {
    import { InputNode, OutputNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { Add } from "tone/signal/Add";
    import { Multiply } from "tone/signal/Multiply";
    import { SignalOperator } from "tone/signal/SignalOperator";
    export interface ScaleOptions extends ToneAudioNodeOptions {
            min: number;
            max: number;
    }
    /**
        * Performs a linear scaling on an input signal.
        * Scales a NormalRange input to between
        * outputMin and outputMax.
        *
        * @example
        * const scale = new Tone.Scale(50, 100);
        * const signal = new Tone.Signal(0.5).connect(scale);
        * // the output of scale equals 75
        * @category Signal
        */
    export class Scale<Options extends ScaleOptions = ScaleOptions> extends SignalOperator<Options> {
            readonly name: string;
            input: InputNode;
            output: OutputNode;
            /**
                * Hold the multiple
                */
            protected _mult: Multiply;
            /**
                * Hold the adder
                */
            protected _add: Add;
            /**
                * @param min The output value when the input is 0.
                * @param max The output value when the input is 1.
                */
            constructor(min?: number, max?: number);
            constructor(options?: Partial<ScaleOptions>);
            static getDefaults(): ScaleOptions;
            /**
                * The minimum output value. This number is output when the value input value is 0.
                */
            get min(): number;
            set min(min: number);
            /**
                * The maximum output value. This number is output when the value input value is 1.
                */
            get max(): number;
            set max(max: number);
            dispose(): this;
    }
}

declare module 'tone/signal/ScaleExp' {
    import { Scale, ScaleOptions } from "tone/signal/Scale";
    import { Positive } from "tone/core/type/Units";
    export interface ScaleExpOptions extends ScaleOptions {
            exponent: Positive;
    }
    /**
        * Performs an exponential scaling on an input signal.
        * Scales a NormalRange value [0,1] exponentially
        * to the output range of outputMin to outputMax.
        * @example
        * const scaleExp = new Tone.ScaleExp(0, 100, 2);
        * const signal = new Tone.Signal(0.5).connect(scaleExp);
        * @category Signal
        */
    export class ScaleExp extends Scale<ScaleExpOptions> {
            readonly name: string;
            /**
                * @param min The output value when the input is 0.
                * @param max The output value when the input is 1.
                * @param exponent The exponent which scales the incoming signal.
                */
            constructor(min?: number, max?: number, exponent?: number);
            constructor(options?: Partial<ScaleExpOptions>);
            static getDefaults(): ScaleExpOptions;
            /**
                * Instead of interpolating linearly between the {@link min} and
                * {@link max} values, setting the exponent will interpolate between
                * the two values with an exponential curve.
                */
            get exponent(): Positive;
            set exponent(exp: Positive);
            dispose(): this;
    }
}

declare module 'tone/signal/Subtract' {
    import { Gain } from "tone/core/context/Gain";
    import { Param } from "tone/core/context/Param";
    import { Signal, SignalOptions } from "tone/signal/Signal";
    /**
        * Subtract the signal connected to the input is subtracted from the signal connected
        * The subtrahend.
        *
        * @example
        * // subtract a scalar from a signal
        * const sub = new Tone.Subtract(1);
        * const sig = new Tone.Signal(4).connect(sub);
        * // the output of sub is 3.
        * @example
        * // subtract two signals
        * const sub = new Tone.Subtract();
        * const sigA = new Tone.Signal(10);
        * const sigB = new Tone.Signal(2.5);
        * sigA.connect(sub);
        * sigB.connect(sub.subtrahend);
        * // output of sub is 7.5
        * @category Signal
        */
    export class Subtract extends Signal {
            override: boolean;
            readonly name: string;
            readonly input: Gain;
            readonly output: Gain;
            /**
                * The value which is subtracted from the main signal
                */
            subtrahend: Param<"number">;
            /**
                * @param value The value to subtract from the incoming signal. If the value
                *             is omitted, it will subtract the second signal from the first.
                */
            constructor(value?: number);
            constructor(options?: Partial<SignalOptions<"number">>);
            static getDefaults(): SignalOptions<"number">;
            dispose(): this;
    }
}

declare module 'tone/signal/SyncedSignal' {
    import { Signal, SignalOptions } from "tone/signal/Signal";
    import { NormalRange, Time, TransportTime, UnitMap, UnitName } from "tone/core/type/Units";
    import { OutputNode } from "tone/core/context/ToneAudioNode";
    /**
        * Adds the ability to synchronize the signal to the {@link TransportClass}
        * @category Signal
        */
    export class SyncedSignal<TypeName extends UnitName = "number"> extends Signal<TypeName> {
            readonly name: string;
            /**
                * Don't override when something is connected to the input
                */
            readonly override = false;
            readonly output: OutputNode;
            /**
                * @param value Initial value of the signal
                * @param units The unit name, e.g. "frequency"
                */
            constructor(value?: UnitMap[TypeName], units?: TypeName);
            constructor(options?: Partial<SignalOptions<TypeName>>);
            getValueAtTime(time: TransportTime): UnitMap[TypeName];
            setValueAtTime(value: UnitMap[TypeName], time: TransportTime): this;
            linearRampToValueAtTime(value: UnitMap[TypeName], time: TransportTime): this;
            exponentialRampToValueAtTime(value: UnitMap[TypeName], time: TransportTime): this;
            setTargetAtTime(value: any, startTime: TransportTime, timeConstant: number): this;
            cancelScheduledValues(startTime: TransportTime): this;
            setValueCurveAtTime(values: UnitMap[TypeName][], startTime: TransportTime, duration: Time, scaling: NormalRange): this;
            cancelAndHoldAtTime(time: TransportTime): this;
            setRampPoint(time: TransportTime): this;
            exponentialRampTo(value: UnitMap[TypeName], rampTime: Time, startTime?: TransportTime): this;
            linearRampTo(value: UnitMap[TypeName], rampTime: Time, startTime?: TransportTime): this;
            targetRampTo(value: UnitMap[TypeName], rampTime: Time, startTime?: TransportTime): this;
            dispose(): this;
    }
}

declare module 'tone/signal/WaveShaper' {
    import { ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { SignalOperator } from "tone/signal/SignalOperator";
    export type WaveShaperMappingFn = (value: number, index?: number) => number;
    type WaveShaperMapping = WaveShaperMappingFn | number[] | Float32Array;
    interface WaveShaperOptions extends ToneAudioNodeOptions {
            mapping?: WaveShaperMapping;
            length: number;
            curve?: number[] | Float32Array;
    }
    /**
        * Wraps the native Web Audio API
        * [WaveShaperNode](http://webaudio.github.io/web-audio-api/#the-waveshapernode-interface).
        *
        * @example
        * const osc = new Tone.Oscillator().toDestination().start();
        * // multiply the output of the signal by 2 using the waveshaper's function
        * const timesTwo = new Tone.WaveShaper((val) => val * 2, 2048).connect(osc.frequency);
        * const signal = new Tone.Signal(440).connect(timesTwo);
        * @category Signal
        */
    export class WaveShaper extends SignalOperator<WaveShaperOptions> {
            readonly name: string;
            /**
                * The input to the waveshaper node.
                */
            input: WaveShaperNode;
            /**
                * The output from the waveshaper node
                */
            output: WaveShaperNode;
            /**
                * @param mapping The function used to define the values.
                *                The mapping function should take two arguments:
                *                the first is the value at the current position
                *                and the second is the array position.
                *                If the argument is an array, that array will be
                *                set as the wave shaping function. The input
                *                signal is an AudioRange [-1, 1] value and the output
                *                signal can take on any numerical values.
                *
                * @param length The length of the WaveShaperNode buffer.
                */
            constructor(mapping?: WaveShaperMapping, length?: number);
            constructor(options?: Partial<WaveShaperOptions>);
            static getDefaults(): WaveShaperOptions;
            /**
                * Uses a mapping function to set the value of the curve.
                * @param mapping The function used to define the values.
                *                The mapping function take two arguments:
                *                the first is the value at the current position
                *                which goes from -1 to 1 over the number of elements
                *                in the curve array. The second argument is the array position.
                * @example
                * const shaper = new Tone.WaveShaper();
                * // map the input signal from [-1, 1] to [0, 10]
                * shaper.setMap((val, index) => (val + 1) * 5);
                */
            setMap(mapping: WaveShaperMappingFn, length?: number): this;
            /**
                * The array to set as the waveshaper curve. For linear curves
                * array length does not make much difference, but for complex curves
                * longer arrays will provide smoother interpolation.
                */
            get curve(): Float32Array | null;
            set curve(mapping: Float32Array | null);
            /**
                * Specifies what type of oversampling (if any) should be used when
                * applying the shaping curve. Can either be "none", "2x" or "4x".
                */
            get oversample(): OverSampleType;
            set oversample(oversampling: OverSampleType);
            /**
                * Clean up.
                */
            dispose(): this;
    }
    export {};
}

declare module 'tone/signal/Zero' {
    import { Gain } from "tone/core/context/Gain";
    import { ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { SignalOperator } from "tone/signal/SignalOperator";
    /**
        * Tone.Zero outputs 0's at audio-rate. The reason this has to be
        * it's own class is that many browsers optimize out Tone.Signal
        * with a value of 0 and will not process nodes further down the graph.
        * @category Signal
        */
    export class Zero extends SignalOperator<ToneAudioNodeOptions> {
            readonly name: string;
            /**
                * Only outputs 0
                */
            output: Gain<"gain">;
            /**
                * no input node
                */
            input: undefined;
            constructor(options?: Partial<ToneAudioNodeOptions>);
            /**
                * clean up
                */
            dispose(): this;
    }
}

declare module 'tone/instrument/AMSynth' {
    import { RecursivePartial } from "tone/core/util/Interface";
    import { ModulationSynth, ModulationSynthOptions } from "tone/instrument/ModulationSynth";
    export type AMSynthOptions = ModulationSynthOptions;
    /**
        * AMSynth uses the output of one Tone.Synth to modulate the
        * amplitude of another Tone.Synth. The harmonicity (the ratio between
        * the two signals) affects the timbre of the output signal greatly.
        * Read more about Amplitude Modulation Synthesis on
        * [SoundOnSound](https://web.archive.org/web/20160404103653/http://www.soundonsound.com:80/sos/mar00/articles/synthsecrets.htm).
        *
        * @example
        * const synth = new Tone.AMSynth().toDestination();
        * synth.triggerAttackRelease("C4", "4n");
        *
        * @category Instrument
        */
    export class AMSynth extends ModulationSynth<AMSynthOptions> {
            readonly name: string;
            constructor(options?: RecursivePartial<AMSynthOptions>);
            dispose(): this;
    }
}

declare module 'tone/instrument/DuoSynth' {
    import { Monophonic, MonophonicOptions } from "tone/instrument/Monophonic";
    import { MonoSynth, MonoSynthOptions } from "tone/instrument/MonoSynth";
    import { Signal } from "tone/signal/Signal";
    import { RecursivePartial } from "tone/core/util/Interface";
    import { Frequency, NormalRange, Positive, Seconds, Time } from "tone/core/type/Units";
    import { Param } from "tone/core/context/Param";
    export interface DuoSynthOptions extends MonophonicOptions {
            voice0: Omit<MonoSynthOptions, keyof MonophonicOptions>;
            voice1: Omit<MonoSynthOptions, keyof MonophonicOptions>;
            harmonicity: Positive;
            vibratoRate: Frequency;
            vibratoAmount: Positive;
    }
    /**
        * DuoSynth is a monophonic synth composed of two {@link MonoSynth}s run in parallel with control over the
        * frequency ratio between the two voices and vibrato effect.
        * @example
        * const duoSynth = new Tone.DuoSynth().toDestination();
        * duoSynth.triggerAttackRelease("C4", "2n");
        * @category Instrument
        */
    export class DuoSynth extends Monophonic<DuoSynthOptions> {
            readonly name: string;
            readonly frequency: Signal<"frequency">;
            readonly detune: Signal<"cents">;
            /**
                * the first voice
                */
            readonly voice0: MonoSynth;
            /**
                * the second voice
                */
            readonly voice1: MonoSynth;
            /**
                * The amount of vibrato
                */
            vibratoAmount: Param<"normalRange">;
            /**
                * the vibrato frequency
                */
            vibratoRate: Signal<"frequency">;
            /**
                * Harmonicity is the ratio between the two voices. A harmonicity of
                * 1 is no change. Harmonicity = 2 means a change of an octave.
                * @example
                * const duoSynth = new Tone.DuoSynth().toDestination();
                * duoSynth.triggerAttackRelease("C4", "2n");
                * // pitch voice1 an octave below voice0
                * duoSynth.harmonicity.value = 0.5;
                */
            harmonicity: Signal<"positive">;
            constructor(options?: RecursivePartial<DuoSynthOptions>);
            getLevelAtTime(time: Time): NormalRange;
            static getDefaults(): DuoSynthOptions;
            /**
                * Trigger the attack portion of the note
                */
            protected _triggerEnvelopeAttack(time: Seconds, velocity: number): void;
            /**
                * Trigger the release portion of the note
                */
            protected _triggerEnvelopeRelease(time: Seconds): this;
            dispose(): this;
    }
}

declare module 'tone/instrument/FMSynth' {
    import { Positive } from "tone/core/type/Units";
    import { RecursivePartial } from "tone/core/util/Interface";
    import { Multiply } from "tone/signal/Multiply";
    import { ModulationSynth, ModulationSynthOptions } from "tone/instrument/ModulationSynth";
    export interface FMSynthOptions extends ModulationSynthOptions {
            modulationIndex: Positive;
    }
    /**
        * FMSynth is composed of two Tone.Synths where one Tone.Synth modulates
        * the frequency of a second Tone.Synth. A lot of spectral content
        * can be explored using the modulationIndex parameter. Read more about
        * frequency modulation synthesis on Sound On Sound: [Part 1](https://web.archive.org/web/20160403123704/http://www.soundonsound.com/sos/apr00/articles/synthsecrets.htm), [Part 2](https://web.archive.org/web/20160403115835/http://www.soundonsound.com/sos/may00/articles/synth.htm).
        *
        * @example
        * const fmSynth = new Tone.FMSynth().toDestination();
        * fmSynth.triggerAttackRelease("C5", "4n");
        *
        * @category Instrument
        */
    export class FMSynth extends ModulationSynth<FMSynthOptions> {
            readonly name: string;
            /**
                * The modulation index which essentially the depth or amount of the modulation. It is the
                * ratio of the frequency of the modulating signal (mf) to the amplitude of the
                * modulating signal (ma) -- as in ma/mf.
                */
            readonly modulationIndex: Multiply;
            constructor(options?: RecursivePartial<FMSynthOptions>);
            static getDefaults(): FMSynthOptions;
            dispose(): this;
    }
}

declare module 'tone/instrument/MetalSynth' {
    import { Envelope, EnvelopeOptions } from "tone/component/envelope/Envelope";
    import { ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { Frequency, NormalRange, Positive, Seconds, Time } from "tone/core/type/Units";
    import { RecursivePartial } from "tone/core/util/Interface";
    import { Signal } from "tone/signal/Signal";
    import { Monophonic, MonophonicOptions } from "tone/instrument/Monophonic";
    export interface MetalSynthOptions extends MonophonicOptions {
            harmonicity: Positive;
            modulationIndex: Positive;
            octaves: number;
            resonance: Frequency;
            envelope: Omit<EnvelopeOptions, keyof ToneAudioNodeOptions>;
    }
    /**
        * A highly inharmonic and spectrally complex source with a highpass filter
        * and amplitude envelope which is good for making metallophone sounds.
        * Based on CymbalSynth by [@polyrhythmatic](https://github.com/polyrhythmatic).
        * @category Instrument
        */
    export class MetalSynth extends Monophonic<MetalSynthOptions> {
            readonly name: string;
            /**
                * The frequency of the cymbal
                */
            readonly frequency: Signal<"frequency">;
            /**
                * The detune applied to the oscillators
                */
            readonly detune: Signal<"cents">;
            /**
                * The envelope which is connected both to the
                * amplitude and a highpass filter's cutoff frequency.
                * The lower-limit of the filter is controlled by the {@link resonance}
                */
            readonly envelope: Envelope;
            constructor(options?: RecursivePartial<MetalSynthOptions>);
            static getDefaults(): MetalSynthOptions;
            /**
                * Trigger the attack.
                * @param time When the attack should be triggered.
                * @param velocity The velocity that the envelope should be triggered at.
                */
            protected _triggerEnvelopeAttack(time: Seconds, velocity?: NormalRange): this;
            /**
                * Trigger the release of the envelope.
                * @param time When the release should be triggered.
                */
            protected _triggerEnvelopeRelease(time: Seconds): this;
            getLevelAtTime(time: Time): NormalRange;
            /**
                * The modulationIndex of the oscillators which make up the source.
                * see {@link FMOscillator.modulationIndex}
                * @min 1
                * @max 100
                */
            get modulationIndex(): number;
            set modulationIndex(val: number);
            /**
                * The harmonicity of the oscillators which make up the source.
                * see Tone.FMOscillator.harmonicity
                * @min 0.1
                * @max 10
                */
            get harmonicity(): number;
            set harmonicity(val: number);
            /**
                * The lower level of the highpass filter which is attached to the envelope.
                * This value should be between [0, 7000]
                * @min 0
                * @max 7000
                */
            get resonance(): Frequency;
            set resonance(val: Frequency);
            /**
                * The number of octaves above the "resonance" frequency
                * that the filter ramps during the attack/decay envelope
                * @min 0
                * @max 8
                */
            get octaves(): number;
            set octaves(val: number);
            dispose(): this;
    }
}

declare module 'tone/instrument/MembraneSynth' {
    import { FrequencyClass } from "tone/core/type/Frequency";
    import { Frequency, Positive, Time } from "tone/core/type/Units";
    import { RecursivePartial } from "tone/core/util/Interface";
    import { Synth, SynthOptions } from "tone/instrument/Synth";
    export interface MembraneSynthOptions extends SynthOptions {
            pitchDecay: Time;
            octaves: Positive;
    }
    /**
        * MembraneSynth makes kick and tom sounds using a single oscillator
        * with an amplitude envelope and frequency ramp. A Tone.OmniOscillator
        * is routed through a Tone.AmplitudeEnvelope to the output. The drum
        * quality of the sound comes from the frequency envelope applied
        * during MembraneSynth.triggerAttack(note). The frequency envelope
        * starts at <code>note * .octaves</code> and ramps to <code>note</code>
        * over the duration of <code>.pitchDecay</code>.
        * @example
        * const synth = new Tone.MembraneSynth().toDestination();
        * synth.triggerAttackRelease("C2", "8n");
        * @category Instrument
        */
    export class MembraneSynth extends Synth<MembraneSynthOptions> {
            readonly name: string;
            /**
                * The number of octaves the pitch envelope ramps.
                * @min 0.5
                * @max 8
                */
            octaves: Positive;
            /**
                * The amount of time the frequency envelope takes.
                * @min 0
                * @max 0.5
                */
            pitchDecay: Time;
            /**
                * Portamento is ignored in this synth. use pitch decay instead.
                */
            readonly portamento = 0;
            /**
                * @param options the options available for the synth see defaults
                */
            constructor(options?: RecursivePartial<MembraneSynthOptions>);
            static getDefaults(): MembraneSynthOptions;
            setNote(note: Frequency | FrequencyClass, time?: Time): this;
            dispose(): this;
    }
}

declare module 'tone/instrument/MonoSynth' {
    import { AmplitudeEnvelope } from "tone/component/envelope/AmplitudeEnvelope";
    import { EnvelopeOptions } from "tone/component/envelope/Envelope";
    import { Filter, FilterOptions } from "tone/component/filter/Filter";
    import { RecursivePartial } from "tone/core/util/Interface";
    import { Monophonic, MonophonicOptions } from "tone/instrument/Monophonic";
    import { OmniOscillator } from "tone/source/oscillator/OmniOscillator";
    import { FrequencyEnvelope, FrequencyEnvelopeOptions } from "tone/component/envelope/FrequencyEnvelope";
    import { NormalRange, Seconds, Time } from "tone/core/type/Units";
    import { Signal } from "tone/signal/Signal";
    import { ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { OmniOscillatorSynthOptions } from "tone/source/oscillator/OscillatorInterface";
    export interface MonoSynthOptions extends MonophonicOptions {
            oscillator: OmniOscillatorSynthOptions;
            envelope: Omit<EnvelopeOptions, keyof ToneAudioNodeOptions>;
            filterEnvelope: Omit<FrequencyEnvelopeOptions, keyof ToneAudioNodeOptions>;
            filter: Omit<FilterOptions, keyof ToneAudioNodeOptions>;
    }
    /**
        * MonoSynth is composed of one `oscillator`, one `filter`, and two `envelopes`.
        * The amplitude of the Oscillator and the cutoff frequency of the
        * Filter are controlled by Envelopes.
        * <img src="https://docs.google.com/drawings/d/1gaY1DF9_Hzkodqf8JI1Cg2VZfwSElpFQfI94IQwad38/pub?w=924&h=240">
        * @example
        * const synth = new Tone.MonoSynth({
        * 	oscillator: {
        * 		type: "square"
        * 	},
        * 	envelope: {
        * 		attack: 0.1
        * 	}
        * }).toDestination();
        * synth.triggerAttackRelease("C4", "8n");
        * @category Instrument
        */
    export class MonoSynth extends Monophonic<MonoSynthOptions> {
            readonly name = "MonoSynth";
            /**
                * The oscillator.
                */
            readonly oscillator: OmniOscillator<any>;
            /**
                * The frequency control.
                */
            readonly frequency: Signal<"frequency">;
            /**
                * The detune control.
                */
            readonly detune: Signal<"cents">;
            /**
                * The filter.
                */
            readonly filter: Filter;
            /**
                * The filter envelope.
                */
            readonly filterEnvelope: FrequencyEnvelope;
            /**
                * The amplitude envelope.
                */
            readonly envelope: AmplitudeEnvelope;
            constructor(options?: RecursivePartial<MonoSynthOptions>);
            static getDefaults(): MonoSynthOptions;
            /**
                * start the attack portion of the envelope
                * @param time the time the attack should start
                * @param velocity the velocity of the note (0-1)
                */
            protected _triggerEnvelopeAttack(time: Seconds, velocity?: number): void;
            /**
                * start the release portion of the envelope
                * @param time the time the release should start
                */
            protected _triggerEnvelopeRelease(time: Seconds): void;
            getLevelAtTime(time: Time): NormalRange;
            dispose(): this;
    }
}

declare module 'tone/instrument/NoiseSynth' {
    import { AmplitudeEnvelope } from "tone/component/envelope/AmplitudeEnvelope";
    import { NormalRange, Time } from "tone/core/type/Units";
    import { RecursivePartial } from "tone/core/util/Interface";
    import { Noise, NoiseOptions } from "tone/source/Noise";
    import { Instrument, InstrumentOptions } from "tone/instrument/Instrument";
    import { ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { EnvelopeOptions } from "tone/component/envelope/Envelope";
    export interface NoiseSynthOptions extends InstrumentOptions {
            envelope: Omit<EnvelopeOptions, keyof ToneAudioNodeOptions>;
            noise: Omit<NoiseOptions, keyof ToneAudioNodeOptions>;
    }
    /**
        * Tone.NoiseSynth is composed of {@link Noise} through an {@link AmplitudeEnvelope}.
        * ```
        * +-------+   +-------------------+
        * | Noise +>--> AmplitudeEnvelope +>--> Output
        * +-------+   +-------------------+
        * ```
        * @example
        * const noiseSynth = new Tone.NoiseSynth().toDestination();
        * noiseSynth.triggerAttackRelease("8n", 0.05);
        * @category Instrument
        */
    export class NoiseSynth extends Instrument<NoiseSynthOptions> {
            readonly name = "NoiseSynth";
            /**
                * The noise source.
                */
            readonly noise: Noise;
            /**
                * The amplitude envelope.
                */
            readonly envelope: AmplitudeEnvelope;
            constructor(options?: RecursivePartial<NoiseSynthOptions>);
            static getDefaults(): NoiseSynthOptions;
            /**
                * Start the attack portion of the envelopes. Unlike other
                * instruments, Tone.NoiseSynth doesn't have a note.
                * @example
                * const noiseSynth = new Tone.NoiseSynth().toDestination();
                * noiseSynth.triggerAttack();
                */
            triggerAttack(time?: Time, velocity?: NormalRange): this;
            /**
                * Start the release portion of the envelopes.
                */
            triggerRelease(time?: Time): this;
            sync(): this;
            /**
                * Trigger the attack and then the release after the duration.
                * @param duration The amount of time to hold the note for
                * @param time The time the note should start
                * @param velocity The volume of the note (0-1)
                * @example
                * const noiseSynth = new Tone.NoiseSynth().toDestination();
                * // hold the note for 0.5 seconds
                * noiseSynth.triggerAttackRelease(0.5);
                */
            triggerAttackRelease(duration: Time, time?: Time, velocity?: NormalRange): this;
            dispose(): this;
    }
}

declare module 'tone/instrument/PluckSynth' {
    import { Frequency, NormalRange, Time } from "tone/core/type/Units";
    import { RecursivePartial } from "tone/core/util/Interface";
    import { Instrument, InstrumentOptions } from "tone/instrument/Instrument";
    export interface PluckSynthOptions extends InstrumentOptions {
            attackNoise: number;
            dampening: Frequency;
            resonance: NormalRange;
            release: Time;
    }
    /**
        * Karplus-Strong string synthesis.
        * @example
        * const plucky = new Tone.PluckSynth().toDestination();
        * plucky.triggerAttack("C4", "+0.5");
        * plucky.triggerAttack("C3", "+1");
        * plucky.triggerAttack("C2", "+1.5");
        * plucky.triggerAttack("C1", "+2");
        * @category Instrument
        */
    export class PluckSynth extends Instrument<PluckSynthOptions> {
            readonly name = "PluckSynth";
            /**
                * The amount of noise at the attack.
                * Nominal range of [0.1, 20]
                * @min 0.1
                * @max 20
                */
            attackNoise: number;
            /**
                * The amount of resonance of the pluck. Also correlates to the sustain duration.
                */
            resonance: NormalRange;
            /**
                * The release time which corresponds to a resonance ramp down to 0
                */
            release: Time;
            constructor(options?: RecursivePartial<PluckSynthOptions>);
            static getDefaults(): PluckSynthOptions;
            /**
                * The dampening control. i.e. the lowpass filter frequency of the comb filter
                * @min 0
                * @max 7000
                */
            get dampening(): Frequency;
            set dampening(fq: Frequency);
            triggerAttack(note: Frequency, time?: Time): this;
            /**
                * Ramp down the {@link resonance} to 0 over the duration of the release time.
                */
            triggerRelease(time?: Time): this;
            dispose(): this;
    }
}

declare module 'tone/instrument/PolySynth' {
    import { Frequency, NormalRange, Time } from "tone/core/type/Units";
    import { RecursivePartial } from "tone/core/util/Interface";
    import { Instrument, InstrumentOptions } from "tone/instrument/Instrument";
    import { MembraneSynth, MembraneSynthOptions } from "tone/instrument/MembraneSynth";
    import { FMSynth, FMSynthOptions } from "tone/instrument/FMSynth";
    import { AMSynth, AMSynthOptions } from "tone/instrument/AMSynth";
    import { MonoSynth, MonoSynthOptions } from "tone/instrument/MonoSynth";
    import { MetalSynth, MetalSynthOptions } from "tone/instrument/MetalSynth";
    import { Monophonic } from "tone/instrument/Monophonic";
    import { Synth, SynthOptions } from "tone/instrument/Synth";
    type VoiceConstructor<V> = {
            getDefaults: () => VoiceOptions<V>;
    } & (new (...args: any[]) => V);
    type OmitMonophonicOptions<T> = Omit<T, "context" | "onsilence">;
    type VoiceOptions<T> = T extends MembraneSynth ? MembraneSynthOptions : T extends MetalSynth ? MetalSynthOptions : T extends FMSynth ? FMSynthOptions : T extends MonoSynth ? MonoSynthOptions : T extends AMSynth ? AMSynthOptions : T extends Synth ? SynthOptions : T extends Monophonic<infer U> ? U : never;
    /**
        * The settable synth options. excludes monophonic options.
        */
    type PartialVoiceOptions<T> = RecursivePartial<OmitMonophonicOptions<VoiceOptions<T>>>;
    export interface PolySynthOptions<Voice> extends InstrumentOptions {
            maxPolyphony: number;
            voice: VoiceConstructor<Voice>;
            options: PartialVoiceOptions<Voice>;
    }
    /**
        * PolySynth handles voice creation and allocation for any
        * instruments passed in as the second parameter. PolySynth is
        * not a synthesizer by itself, it merely manages voices of
        * one of the other types of synths, allowing any of the
        * monophonic synthesizers to be polyphonic.
        *
        * @example
        * const synth = new Tone.PolySynth().toDestination();
        * // set the attributes across all the voices using 'set'
        * synth.set({ detune: -1200 });
        * // play a chord
        * synth.triggerAttackRelease(["C4", "E4", "A4"], 1);
        * @category Instrument
        */
    export class PolySynth<Voice extends Monophonic<any> = Synth> extends Instrument<VoiceOptions<Voice>> {
            readonly name: string;
            /**
                * The polyphony limit.
                */
            maxPolyphony: number;
            /**
                * @param voice The constructor of the voices
                * @param options	The options object to set the synth voice
                */
            constructor(voice?: VoiceConstructor<Voice>, options?: PartialVoiceOptions<Voice>);
            constructor(options?: Partial<PolySynthOptions<Voice>>);
            static getDefaults(): PolySynthOptions<Synth>;
            /**
                * The number of active voices.
                */
            get activeVoices(): number;
            /**
                * Trigger the attack portion of the note
                * @param  notes The notes to play. Accepts a single Frequency or an array of frequencies.
                * @param  time  The start time of the note.
                * @param velocity The velocity of the note.
                * @example
                * const synth = new Tone.PolySynth(Tone.FMSynth).toDestination();
                * // trigger a chord immediately with a velocity of 0.2
                * synth.triggerAttack(["Ab3", "C4", "F5"], Tone.now(), 0.2);
                */
            triggerAttack(notes: Frequency | Frequency[], time?: Time, velocity?: NormalRange): this;
            /**
                * Trigger the release of the note. Unlike monophonic instruments,
                * a note (or array of notes) needs to be passed in as the first argument.
                * @param  notes The notes to play. Accepts a single Frequency or an array of frequencies.
                * @param  time  When the release will be triggered.
                * @example
                * const poly = new Tone.PolySynth(Tone.AMSynth).toDestination();
                * poly.triggerAttack(["Ab3", "C4", "F5"]);
                * // trigger the release of the given notes.
                * poly.triggerRelease(["Ab3", "C4"], "+1");
                * poly.triggerRelease("F5", "+3");
                */
            triggerRelease(notes: Frequency | Frequency[], time?: Time): this;
            /**
                * Trigger the attack and release after the specified duration
                * @param  notes The notes to play. Accepts a single  Frequency or an array of frequencies.
                * @param  duration the duration of the note
                * @param  time  if no time is given, defaults to now
                * @param  velocity the velocity of the attack (0-1)
                * @example
                * const poly = new Tone.PolySynth(Tone.AMSynth).toDestination();
                * // can pass in an array of durations as well
                * poly.triggerAttackRelease(["Eb3", "G4", "Bb4", "D5"], [4, 3, 2, 1]);
                */
            triggerAttackRelease(notes: Frequency | Frequency[], duration: Time | Time[], time?: Time, velocity?: NormalRange): this;
            sync(): this;
            /**
                * The release which is scheduled to the timeline.
                */
            protected _syncedRelease: (time: number) => this;
            /**
                * Set a member/attribute of the voices
                * @example
                * const poly = new Tone.PolySynth().toDestination();
                * // set all of the voices using an options object for the synth type
                * poly.set({
                * 	envelope: {
                * 		attack: 0.25
                * 	}
                * });
                * poly.triggerAttackRelease("Bb3", 0.2);
                */
            set(options: RecursivePartial<VoiceOptions<Voice>>): this;
            get(): VoiceOptions<Voice>;
            /**
                * Trigger the release portion of all the currently active voices immediately.
                * Useful for silencing the synth.
                */
            releaseAll(time?: Time): this;
            dispose(): this;
    }
    export {};
}

declare module 'tone/instrument/Sampler' {
    import { ToneAudioBuffer } from "tone/core/context/ToneAudioBuffer";
    import { Frequency, MidiNote, NormalRange, Note, Time } from "tone/core/type/Units";
    import { Instrument, InstrumentOptions } from "tone/instrument/Instrument";
    import { ToneBufferSourceCurve } from "tone/source/buffer/ToneBufferSource";
    interface SamplesMap {
            [note: string]: ToneAudioBuffer | AudioBuffer | string;
            [midi: number]: ToneAudioBuffer | AudioBuffer | string;
    }
    export interface SamplerOptions extends InstrumentOptions {
            attack: Time;
            release: Time;
            onload: () => void;
            onerror: (error: Error) => void;
            baseUrl: string;
            curve: ToneBufferSourceCurve;
            urls: SamplesMap;
    }
    /**
        * Pass in an object which maps the note's pitch or midi value to the url,
        * then you can trigger the attack and release of that note like other instruments.
        * By automatically repitching the samples, it is possible to play pitches which
        * were not explicitly included which can save loading time.
        *
        * For sample or buffer playback where repitching is not necessary,
        * use {@link Player}.
        * @example
        * const sampler = new Tone.Sampler({
        * 	urls: {
        * 		A1: "A1.mp3",
        * 		A2: "A2.mp3",
        * 	},
        * 	baseUrl: "https://tonejs.github.io/audio/casio/",
        * 	onload: () => {
        * 		sampler.triggerAttackRelease(["C1", "E1", "G1", "B1"], 0.5);
        * 	}
        * }).toDestination();
        * @category Instrument
        */
    export class Sampler extends Instrument<SamplerOptions> {
            readonly name: string;
            /**
                * The envelope applied to the beginning of the sample.
                * @min 0
                * @max 1
                */
            attack: Time;
            /**
                * The envelope applied to the end of the envelope.
                * @min 0
                * @max 1
                */
            release: Time;
            /**
                * The shape of the attack/release curve.
                * Either "linear" or "exponential"
                */
            curve: ToneBufferSourceCurve;
            /**
                * @param samples An object of samples mapping either Midi Note Numbers or
                * 			Scientific Pitch Notation to the url of that sample.
                * @param onload The callback to invoke when all of the samples are loaded.
                * @param baseUrl The root URL of all of the samples, which is prepended to all the URLs.
                */
            constructor(samples?: SamplesMap, onload?: () => void, baseUrl?: string);
            /**
                * @param samples An object of samples mapping either Midi Note Numbers or
                * 			Scientific Pitch Notation to the url of that sample.
                * @param options The remaining options associated with the sampler
                */
            constructor(samples?: SamplesMap, options?: Partial<Omit<SamplerOptions, "urls">>);
            constructor(options?: Partial<SamplerOptions>);
            static getDefaults(): SamplerOptions;
            /**
                * @param  notes	The note to play, or an array of notes.
                * @param  time     When to play the note
                * @param  velocity The velocity to play the sample back.
                */
            triggerAttack(notes: Frequency | Frequency[], time?: Time, velocity?: NormalRange): this;
            /**
                * @param  notes	The note to release, or an array of notes.
                * @param  time     	When to release the note.
                */
            triggerRelease(notes: Frequency | Frequency[], time?: Time): this;
            /**
                * Release all currently active notes.
                * @param  time     	When to release the notes.
                */
            releaseAll(time?: Time): this;
            sync(): this;
            /**
                * Invoke the attack phase, then after the duration, invoke the release.
                * @param  notes	The note to play and release, or an array of notes.
                * @param  duration The time the note should be held
                * @param  time     When to start the attack
                * @param  velocity The velocity of the attack
                */
            triggerAttackRelease(notes: Frequency[] | Frequency, duration: Time | Time[], time?: Time, velocity?: NormalRange): this;
            /**
                * Add a note to the sampler.
                * @param  note      The buffer's pitch.
                * @param  url  Either the url of the buffer, or a buffer which will be added with the given name.
                * @param  callback  The callback to invoke when the url is loaded.
                */
            add(note: Note | MidiNote, url: string | ToneAudioBuffer | AudioBuffer, callback?: () => void): this;
            /**
                * If the buffers are loaded or not
                */
            get loaded(): boolean;
            /**
                * Clean up
                */
            dispose(): this;
    }
    export {};
}

declare module 'tone/instrument/Synth' {
    import { AmplitudeEnvelope } from "tone/component/envelope/AmplitudeEnvelope";
    import { EnvelopeOptions } from "tone/component/envelope/Envelope";
    import { ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { NormalRange, Seconds, Time } from "tone/core/type/Units";
    import { RecursivePartial } from "tone/core/util/Interface";
    import { Signal } from "tone/signal/Signal";
    import { OmniOscillator } from "tone/source/oscillator/OmniOscillator";
    import { OmniOscillatorSynthOptions } from "tone/source/oscillator/OscillatorInterface";
    import { Monophonic, MonophonicOptions } from "tone/instrument/Monophonic";
    export interface SynthOptions extends MonophonicOptions {
            oscillator: OmniOscillatorSynthOptions;
            envelope: Omit<EnvelopeOptions, keyof ToneAudioNodeOptions>;
    }
    /**
        * Synth is composed simply of a {@link OmniOscillator} routed through an {@link AmplitudeEnvelope}.
        * ```
        * +----------------+   +-------------------+
        * | OmniOscillator +>--> AmplitudeEnvelope +>--> Output
        * +----------------+   +-------------------+
        * ```
        * @example
        * const synth = new Tone.Synth().toDestination();
        * synth.triggerAttackRelease("C4", "8n");
        * @category Instrument
        */
    export class Synth<Options extends SynthOptions = SynthOptions> extends Monophonic<Options> {
            readonly name: string;
            /**
                * The oscillator.
                */
            readonly oscillator: OmniOscillator<any>;
            /**
                * The frequency signal
                */
            readonly frequency: Signal<"frequency">;
            /**
                * The detune signal
                */
            readonly detune: Signal<"cents">;
            /**
                * The envelope
                */
            readonly envelope: AmplitudeEnvelope;
            /**
                * @param options the options available for the synth.
                */
            constructor(options?: RecursivePartial<SynthOptions>);
            static getDefaults(): SynthOptions;
            /**
                * start the attack portion of the envelope
                * @param time the time the attack should start
                * @param velocity the velocity of the note (0-1)
                */
            protected _triggerEnvelopeAttack(time: Seconds, velocity: number): void;
            /**
                * start the release portion of the envelope
                * @param time the time the release should start
                */
            protected _triggerEnvelopeRelease(time: Seconds): void;
            getLevelAtTime(time: Time): NormalRange;
            /**
                * clean up
                */
            dispose(): this;
    }
}

declare module 'tone/event/Loop' {
    import { NormalRange, Positive, Seconds, Time, TransportTime } from "tone/core/type/Units";
    import { ToneWithContext, ToneWithContextOptions } from "tone/core/context/ToneWithContext";
    import { BasicPlaybackState } from "tone/core/util/StateTimeline";
    export interface LoopOptions extends ToneWithContextOptions {
            callback: (time: Seconds) => void;
            interval: Time;
            playbackRate: Positive;
            iterations: number;
            probability: NormalRange;
            mute: boolean;
            humanize: boolean | Time;
    }
    /**
        * Loop creates a looped callback at the
        * specified interval. The callback can be
        * started, stopped and scheduled along
        * the Transport's timeline.
        * @example
        * const loop = new Tone.Loop((time) => {
        * 	// triggered every eighth note.
        * 	console.log(time);
        * }, "8n").start(0);
        * Tone.Transport.start();
        * @category Event
        */
    export class Loop<Options extends LoopOptions = LoopOptions> extends ToneWithContext<Options> {
            readonly name: string;
            /**
                * The callback to invoke with the next event in the pattern
                */
            callback: (time: Seconds) => void;
            /**
                * @param callback The callback to invoke at the time.
                * @param interval The time between successive callback calls.
                */
            constructor(callback?: (time: Seconds) => void, interval?: Time);
            constructor(options?: Partial<LoopOptions>);
            static getDefaults(): LoopOptions;
            /**
                * Start the loop at the specified time along the Transport's timeline.
                * @param  time  When to start the Loop.
                */
            start(time?: TransportTime): this;
            /**
                * Stop the loop at the given time.
                * @param  time  When to stop the Loop.
                */
            stop(time?: TransportTime): this;
            /**
                * Cancel all scheduled events greater than or equal to the given time
                * @param  time  The time after which events will be cancel.
                */
            cancel(time?: TransportTime): this;
            /**
                * Internal function called when the notes should be called
                * @param time  The time the event occurs
                */
            protected _tick(time: Seconds): void;
            /**
                * The state of the Loop, either started or stopped.
                */
            get state(): BasicPlaybackState;
            /**
                * The progress of the loop as a value between 0-1. 0, when the loop is stopped or done iterating.
                */
            get progress(): NormalRange;
            /**
                * The time between successive callbacks.
                * @example
                * const loop = new Tone.Loop();
                * loop.interval = "8n"; // loop every 8n
                */
            get interval(): Time;
            set interval(interval: Time);
            /**
                * The playback rate of the loop. The normal playback rate is 1 (no change).
                * A `playbackRate` of 2 would be twice as fast.
                */
            get playbackRate(): Positive;
            set playbackRate(rate: Positive);
            /**
                * Random variation +/-0.01s to the scheduled time.
                * Or give it a time value which it will randomize by.
                */
            get humanize(): boolean | Time;
            set humanize(variation: boolean | Time);
            /**
                * The probably of the callback being invoked.
                */
            get probability(): NormalRange;
            set probability(prob: NormalRange);
            /**
                * Muting the Loop means that no callbacks are invoked.
                */
            get mute(): boolean;
            set mute(mute: boolean);
            /**
                * The number of iterations of the loop. The default value is `Infinity` (loop forever).
                */
            get iterations(): number;
            set iterations(iters: number);
            dispose(): this;
    }
}

declare module 'tone/event/Part' {
    import { TransportTimeClass } from "tone/core/type/TransportTime";
    import { NormalRange, Positive, Seconds, Ticks, Time, TransportTime } from "tone/core/type/Units";
    import { StateTimeline } from "tone/core/util/StateTimeline";
    import { ToneEvent, ToneEventCallback, ToneEventOptions } from "tone/event/ToneEvent";
    type CallbackType<T> = T extends {
            time: Time;
            [key: string]: any;
    } ? T : T extends ArrayLike<any> ? T[1] : T extends Time ? null : never;
    interface PartOptions<T> extends Omit<ToneEventOptions<CallbackType<T>>, "value"> {
            events: T[];
    }
    /**
        * Part is a collection ToneEvents which can be started/stopped and looped as a single unit.
        *
        * @example
        * const synth = new Tone.Synth().toDestination();
        * const part = new Tone.Part(((time, note) => {
        * 	// the notes given as the second element in the array
        * 	// will be passed in as the second argument
        * 	synth.triggerAttackRelease(note, "8n", time);
        * }), [[0, "C2"], ["0:2", "C3"], ["0:3:2", "G2"]]).start(0);
        * Tone.Transport.start();
        * @example
        * const synth = new Tone.Synth().toDestination();
        * // use an array of objects as long as the object has a "time" attribute
        * const part = new Tone.Part(((time, value) => {
        * 	// the value is an object which contains both the note and the velocity
        * 	synth.triggerAttackRelease(value.note, "8n", time, value.velocity);
        * }), [{ time: 0, note: "C3", velocity: 0.9 },
        * 	{ time: "0:2", note: "C4", velocity: 0.5 }
        * ]).start(0);
        * Tone.Transport.start();
        * @category Event
        */
    export class Part<ValueType = any> extends ToneEvent<ValueType> {
            readonly name: string;
            /**
                * Tracks the scheduled events
                */
            protected _state: StateTimeline<{
                    id: number;
                    offset: number;
            }>;
            /**
                * @param callback The callback to invoke on each event
                * @param value the array of events
                */
            constructor(callback?: ToneEventCallback<CallbackType<ValueType>>, value?: ValueType[]);
            constructor(options?: Partial<PartOptions<ValueType>>);
            static getDefaults(): PartOptions<any>;
            /**
                * Start the part at the given time.
                * @param  time    When to start the part.
                * @param  offset  The offset from the start of the part to begin playing at.
                */
            start(time?: TransportTime, offset?: Time): this;
            get startOffset(): Ticks;
            set startOffset(offset: Ticks);
            /**
                * Stop the part at the given time.
                * @param  time  When to stop the part.
                */
            stop(time?: TransportTime): this;
            /**
                * Get/Set an Event's value at the given time.
                * If a value is passed in and no event exists at
                * the given time, one will be created with that value.
                * If two events are at the same time, the first one will
                * be returned.
                * @example
                * const part = new Tone.Part();
                * part.at("1m"); // returns the part at the first measure
                * part.at("2m", "C2"); // set the value at "2m" to C2.
                * // if an event didn't exist at that time, it will be created.
                * @param time The time of the event to get or set.
                * @param value If a value is passed in, the value of the event at the given time will be set to it.
                */
            at(time: Time, value?: any): ToneEvent | null;
            /**
                * Add a an event to the part.
                * @param time The time the note should start. If an object is passed in, it should
                * 		have a 'time' attribute and the rest of the object will be used as the 'value'.
                * @param  value Any value to add to the timeline
                * @example
                * const part = new Tone.Part();
                * part.add("1m", "C#+11");
                */
            add(obj: {
                    time: Time;
                    [key: string]: any;
            }): this;
            add(time: Time, value?: any): this;
            /**
                * Remove an event from the part. If the event at that time is a Part,
                * it will remove the entire part.
                * @param time The time of the event
                * @param value Optionally select only a specific event value
                */
            remove(obj: {
                    time: Time;
                    [key: string]: any;
            }): this;
            remove(time: Time, value?: any): this;
            /**
                * Remove all of the notes from the group.
                */
            clear(): this;
            /**
                * Cancel scheduled state change events: i.e. "start" and "stop".
                * @param after The time after which to cancel the scheduled events.
                */
            cancel(after?: TransportTime | TransportTimeClass): this;
            /**
                * Internal tick method
                * @param  time  The time of the event in seconds
                */
            protected _tick(time: Seconds, value?: any): void;
            get probability(): NormalRange;
            set probability(prob: NormalRange);
            get humanize(): boolean | Time;
            set humanize(variation: boolean | Time);
            /**
                * If the part should loop or not
                * between Part.loopStart and
                * Part.loopEnd. If set to true,
                * the part will loop indefinitely,
                * if set to a number greater than 1
                * it will play a specific number of
                * times, if set to false, 0 or 1, the
                * part will only play once.
                * @example
                * const part = new Tone.Part();
                * // loop the part 8 times
                * part.loop = 8;
                */
            get loop(): boolean | number;
            set loop(loop: boolean | number);
            /**
                * The loopEnd point determines when it will
                * loop if Part.loop is true.
                */
            get loopEnd(): Time;
            set loopEnd(loopEnd: Time);
            /**
                * The loopStart point determines when it will
                * loop if Part.loop is true.
                */
            get loopStart(): Time;
            set loopStart(loopStart: Time);
            /**
                * The playback rate of the part
                */
            get playbackRate(): Positive;
            set playbackRate(rate: Positive);
            /**
                * The number of scheduled notes in the part.
                */
            get length(): number;
            dispose(): this;
    }
    export {};
}

declare module 'tone/event/Pattern' {
    import { Loop, LoopOptions } from "tone/event/Loop";
    import { PatternName } from "tone/event/PatternGenerator";
    import { ToneEventCallback } from "tone/event/ToneEvent";
    import { Seconds } from "tone/core/type/Units";
    export interface PatternOptions<ValueType> extends LoopOptions {
            pattern: PatternName;
            values: ValueType[];
            callback: (time: Seconds, value?: ValueType) => void;
    }
    /**
        * Pattern arpeggiates between the given notes
        * in a number of patterns.
        * @example
        * const pattern = new Tone.Pattern((time, note) => {
        * 	// the order of the notes passed in depends on the pattern
        * }, ["C2", "D4", "E5", "A6"], "upDown");
        * @category Event
        */
    export class Pattern<ValueType> extends Loop<PatternOptions<ValueType>> {
            readonly name: string;
            /**
                * The callback to be invoked at a regular interval
                */
            callback: (time: Seconds, value?: ValueType) => void;
            /**
                * @param  callback The callback to invoke with the event.
                * @param  values The values to arpeggiate over.
                * @param  pattern  The name of the pattern
                */
            constructor(callback?: ToneEventCallback<ValueType>, values?: ValueType[], pattern?: PatternName);
            constructor(options?: Partial<PatternOptions<ValueType>>);
            static getDefaults(): PatternOptions<any>;
            /**
                * Internal function called when the notes should be called
                */
            protected _tick(time: Seconds): void;
            /**
                * The array of events.
                */
            get values(): ValueType[];
            set values(val: ValueType[]);
            /**
                * The current value of the pattern.
                */
            get value(): ValueType | undefined;
            /**
                * The current index of the pattern.
                */
            get index(): number | undefined;
            /**
                * The pattern type.
                */
            get pattern(): PatternName;
            set pattern(pattern: PatternName);
    }
}

declare module 'tone/event/Sequence' {
    import { NormalRange, Positive, Seconds, Ticks, Time, TransportTime } from "tone/core/type/Units";
    import { ToneEvent, ToneEventCallback, ToneEventOptions } from "tone/event/ToneEvent";
    type SequenceEventDescription<T> = Array<T | SequenceEventDescription<T>>;
    interface SequenceOptions<T> extends Omit<ToneEventOptions<T>, "value"> {
            loopStart: number;
            loopEnd: number;
            subdivision: Time;
            events: SequenceEventDescription<T>;
    }
    /**
        * A sequence is an alternate notation of a part. Instead
        * of passing in an array of [time, event] pairs, pass
        * in an array of events which will be spaced at the
        * given subdivision. Sub-arrays will subdivide that beat
        * by the number of items are in the array.
        * Sequence notation inspiration from [Tidal Cycles](http://tidalcycles.org/)
        * @example
        * const synth = new Tone.Synth().toDestination();
        * const seq = new Tone.Sequence((time, note) => {
        * 	synth.triggerAttackRelease(note, 0.1, time);
        * 	// subdivisions are given as subarrays
        * }, ["C4", ["E4", "D4", "E4"], "G4", ["A4", "G4"]]).start(0);
        * Tone.Transport.start();
        * @category Event
        */
    export class Sequence<ValueType = any> extends ToneEvent<ValueType> {
            readonly name: string;
            /**
                * @param  callback  The callback to invoke with every note
                * @param  events  The sequence of events
                * @param  subdivision  The subdivision between which events are placed.
                */
            constructor(callback?: ToneEventCallback<ValueType>, events?: SequenceEventDescription<ValueType>, subdivision?: Time);
            constructor(options?: Partial<SequenceOptions<ValueType>>);
            static getDefaults(): SequenceOptions<any>;
            /**
                * The sequence
                */
            get events(): any[];
            set events(s: any[]);
            /**
                * Start the part at the given time.
                * @param  time    When to start the part.
                * @param  offset  The offset index to start at
                */
            start(time?: TransportTime, offset?: number): this;
            /**
                * Stop the part at the given time.
                * @param  time  When to stop the part.
                */
            stop(time?: TransportTime): this;
            /**
                * The subdivision of the sequence. This can only be
                * set in the constructor. The subdivision is the
                * interval between successive steps.
                */
            get subdivision(): Seconds;
            /**
                * Clear all of the events
                */
            clear(): this;
            dispose(): this;
            get loop(): boolean | number;
            set loop(l: boolean | number);
            /**
                * The index at which the sequence should start looping
                */
            get loopStart(): number;
            set loopStart(index: number);
            /**
                * The index at which the sequence should end looping
                */
            get loopEnd(): number;
            set loopEnd(index: number);
            get startOffset(): Ticks;
            set startOffset(start: Ticks);
            get playbackRate(): Positive;
            set playbackRate(rate: Positive);
            get probability(): NormalRange;
            set probability(prob: NormalRange);
            get progress(): NormalRange;
            get humanize(): boolean | Time;
            set humanize(variation: boolean | Time);
            /**
                * The number of scheduled events
                */
            get length(): number;
    }
    export {};
}

declare module 'tone/event/ToneEvent' {
    import "../core/clock/Transport";
    import { ToneWithContext, ToneWithContextOptions } from "tone/core/context/ToneWithContext";
    import { TransportTimeClass } from "tone/core/type/TransportTime";
    import { NormalRange, Positive, Seconds, Ticks, Time, TransportTime } from "tone/core/type/Units";
    import { BasicPlaybackState, StateTimeline } from "tone/core/util/StateTimeline";
    export type ToneEventCallback<T> = (time: Seconds, value: T) => void;
    export interface ToneEventOptions<T> extends ToneWithContextOptions {
            callback: ToneEventCallback<T>;
            loop: boolean | number;
            loopEnd: Time;
            loopStart: Time;
            playbackRate: Positive;
            value?: T;
            probability: NormalRange;
            mute: boolean;
            humanize: boolean | Time;
    }
    /**
        * ToneEvent abstracts away this.context.transport.schedule and provides a schedulable
        * callback for a single or repeatable events along the timeline.
        *
        * @example
        * const synth = new Tone.PolySynth().toDestination();
        * const chordEvent = new Tone.ToneEvent(((time, chord) => {
        * 	// the chord as well as the exact time of the event
        * 	// are passed in as arguments to the callback function
        * 	synth.triggerAttackRelease(chord, 0.5, time);
        * }), ["D4", "E4", "F4"]);
        * // start the chord at the beginning of the transport timeline
        * chordEvent.start();
        * // loop it every measure for 8 measures
        * chordEvent.loop = 8;
        * chordEvent.loopEnd = "1m";
        * @category Event
        */
    export class ToneEvent<ValueType = any> extends ToneWithContext<ToneEventOptions<ValueType>> {
            readonly name: string;
            /**
                * Loop value
                */
            protected _loop: boolean | number;
            /**
                * The callback to invoke.
                */
            callback: ToneEventCallback<ValueType>;
            /**
                * The value which is passed to the
                * callback function.
                */
            value: ValueType;
            /**
                * When the note is scheduled to start.
                */
            protected _loopStart: Ticks;
            /**
                * When the note is scheduled to start.
                */
            protected _loopEnd: Ticks;
            /**
                * Tracks the scheduled events
                */
            protected _state: StateTimeline<{
                    id: number;
            }>;
            /**
                * The playback speed of the note. A speed of 1
                * is no change.
                */
            protected _playbackRate: Positive;
            /**
                * A delay time from when the event is scheduled to start
                */
            protected _startOffset: Ticks;
            /**
                * private holder of probability value
                */
            protected _probability: NormalRange;
            /**
                * the amount of variation from the given time.
                */
            protected _humanize: boolean | Time;
            /**
                * If mute is true, the callback won't be invoked.
                */
            mute: boolean;
            /**
                * @param callback The callback to invoke at the time.
                * @param value The value or values which should be passed to the callback function on invocation.
                */
            constructor(callback?: ToneEventCallback<ValueType>, value?: ValueType);
            constructor(options?: Partial<ToneEventOptions<ValueType>>);
            static getDefaults(): ToneEventOptions<any>;
            /**
                * Returns the playback state of the note, either "started" or "stopped".
                */
            get state(): BasicPlaybackState;
            /**
                * The start from the scheduled start time.
                */
            get startOffset(): Ticks;
            set startOffset(offset: Ticks);
            /**
                * The probability of the notes being triggered.
                */
            get probability(): NormalRange;
            set probability(prob: NormalRange);
            /**
                * If set to true, will apply small random variation
                * to the callback time. If the value is given as a time, it will randomize
                * by that amount.
                * @example
                * const event = new Tone.ToneEvent();
                * event.humanize = true;
                */
            get humanize(): Time | boolean;
            set humanize(variation: Time | boolean);
            /**
                * Start the note at the given time.
                * @param  time  When the event should start.
                */
            start(time?: TransportTime | TransportTimeClass): this;
            /**
                * Stop the Event at the given time.
                * @param  time  When the event should stop.
                */
            stop(time?: TransportTime | TransportTimeClass): this;
            /**
                * Cancel all scheduled events greater than or equal to the given time
                * @param  time  The time after which events will be cancel.
                */
            cancel(time?: TransportTime | TransportTimeClass): this;
            /**
                * The callback function invoker. Also
                * checks if the Event is done playing
                * @param  time  The time of the event in seconds
                */
            protected _tick(time: Seconds): void;
            /**
                * Get the duration of the loop.
                */
            protected _getLoopDuration(): Ticks;
            /**
                * If the note should loop or not
                * between ToneEvent.loopStart and
                * ToneEvent.loopEnd. If set to true,
                * the event will loop indefinitely,
                * if set to a number greater than 1
                * it will play a specific number of
                * times, if set to false, 0 or 1, the
                * part will only play once.
                */
            get loop(): boolean | number;
            set loop(loop: boolean | number);
            /**
                * The playback rate of the event. Defaults to 1.
                * @example
                * const note = new Tone.ToneEvent();
                * note.loop = true;
                * // repeat the note twice as fast
                * note.playbackRate = 2;
                */
            get playbackRate(): Positive;
            set playbackRate(rate: Positive);
            /**
                * The loopEnd point is the time the event will loop
                * if ToneEvent.loop is true.
                */
            get loopEnd(): Time;
            set loopEnd(loopEnd: Time);
            /**
                * The time when the loop should start.
                */
            get loopStart(): Time;
            set loopStart(loopStart: Time);
            /**
                * The current progress of the loop interval.
                * Returns 0 if the event is not started yet or
                * it is not set to loop.
                */
            get progress(): NormalRange;
            dispose(): this;
    }
}

declare module 'tone/effect/AutoFilter' {
    import { Frequency, Positive } from "tone/core/type/Units";
    import { Filter, FilterOptions } from "tone/component/filter/Filter";
    import { SourceOptions } from "tone/source/Source";
    import { LFOEffect, LFOEffectOptions } from "tone/effect/LFOEffect";
    export interface AutoFilterOptions extends LFOEffectOptions {
            baseFrequency: Frequency;
            octaves: Positive;
            filter: Omit<FilterOptions, keyof SourceOptions | "frequency" | "detune" | "gain">;
    }
    /**
        * AutoFilter is a Tone.Filter with a Tone.LFO connected to the filter cutoff frequency.
        * Setting the LFO rate and depth allows for control over the filter modulation rate
        * and depth.
        *
        * @example
        * // create an autofilter and start it's LFO
        * const autoFilter = new Tone.AutoFilter("4n").toDestination().start();
        * // route an oscillator through the filter and start it
        * const oscillator = new Tone.Oscillator().connect(autoFilter).start();
        * @category Effect
        */
    export class AutoFilter extends LFOEffect<AutoFilterOptions> {
            readonly name: string;
            /**
                * The filter node
                */
            readonly filter: Filter;
            /**
                * @param frequency The rate of the LFO.
                * @param baseFrequency The lower value of the LFOs oscillation
                * @param octaves The number of octaves above the baseFrequency
                */
            constructor(frequency?: Frequency, baseFrequency?: Frequency, octaves?: Positive);
            constructor(options?: Partial<AutoFilterOptions>);
            static getDefaults(): AutoFilterOptions;
            /**
                * The minimum value of the filter's cutoff frequency.
                */
            get baseFrequency(): Frequency;
            set baseFrequency(freq: Frequency);
            /**
                * The maximum value of the filter's cutoff frequency.
                */
            get octaves(): Positive;
            set octaves(oct: Positive);
            dispose(): this;
    }
}

declare module 'tone/effect/AutoPanner' {
    import { Panner } from "tone/component/channel/Panner";
    import { LFOEffect, LFOEffectOptions } from "tone/effect/LFOEffect";
    import { Frequency } from "tone/core/type/Units";
    export interface AutoPannerOptions extends LFOEffectOptions {
            channelCount: number;
    }
    /**
        * AutoPanner is a {@link Panner} with an {@link LFO} connected to the pan amount.
        * [Related Reading](https://www.ableton.com/en/blog/autopan-chopper-effect-and-more-liveschool/).
        *
        * @example
        * // create an autopanner and start it
        * const autoPanner = new Tone.AutoPanner("4n").toDestination().start();
        * // route an oscillator through the panner and start it
        * const oscillator = new Tone.Oscillator().connect(autoPanner).start();
        * @category Effect
        */
    export class AutoPanner extends LFOEffect<AutoPannerOptions> {
            readonly name: string;
            /**
                * The filter node
                */
            readonly _panner: Panner;
            /**
                * @param frequency Rate of left-right oscillation.
                */
            constructor(frequency?: Frequency);
            constructor(options?: Partial<AutoPannerOptions>);
            static getDefaults(): AutoPannerOptions;
            dispose(): this;
    }
}

declare module 'tone/effect/AutoWah' {
    import { Effect, EffectOptions } from "tone/effect/Effect";
    import { Decibels, Frequency, GainFactor, Positive, Time } from "tone/core/type/Units";
    import { Signal } from "tone/signal/Signal";
    export interface AutoWahOptions extends EffectOptions {
            baseFrequency: Frequency;
            octaves: Positive;
            sensitivity: Decibels;
            Q: Positive;
            gain: GainFactor;
            follower: Time;
    }
    /**
        * AutoWah connects a {@link Follower} to a {@link Filter}.
        * The frequency of the filter, follows the input amplitude curve.
        * Inspiration from [Tuna.js](https://github.com/Dinahmoe/tuna).
        *
        * @example
        * const autoWah = new Tone.AutoWah(50, 6, -30).toDestination();
        * // initialize the synth and connect to autowah
        * const synth = new Tone.Synth().connect(autoWah);
        * // Q value influences the effect of the wah - default is 2
        * autoWah.Q.value = 6;
        * // more audible on higher notes
        * synth.triggerAttackRelease("C4", "8n");
        * @category Effect
        */
    export class AutoWah extends Effect<AutoWahOptions> {
            readonly name: string;
            /**
                * The gain of the filter.
                */
            readonly gain: Signal<"decibels">;
            /**
                * The quality of the filter.
                */
            readonly Q: Signal<"positive">;
            /**
                * @param baseFrequency The frequency the filter is set to at the low point of the wah
                * @param octaves The number of octaves above the baseFrequency the filter will sweep to when fully open.
                * @param sensitivity The decibel threshold sensitivity for the incoming signal. Normal range of -40 to 0.
                */
            constructor(baseFrequency?: Frequency, octaves?: Positive, sensitivity?: Decibels);
            constructor(options?: Partial<AutoWahOptions>);
            static getDefaults(): AutoWahOptions;
            /**
                * The number of octaves that the filter will sweep above the baseFrequency.
                */
            get octaves(): number;
            set octaves(octaves: number);
            /**
                * The follower's smoothing time
                */
            get follower(): Time;
            set follower(follower: Time);
            /**
                * The base frequency from which the sweep will start from.
                */
            get baseFrequency(): Frequency;
            set baseFrequency(baseFreq: Frequency);
            /**
                * The sensitivity to control how responsive to the input signal the filter is.
                */
            get sensitivity(): Decibels;
            set sensitivity(sensitivity: Decibels);
            dispose(): this;
    }
}

declare module 'tone/effect/BitCrusher' {
    import { ToneAudioWorkletOptions } from "tone/core/worklet/ToneAudioWorklet";
    import { Effect, EffectOptions } from "tone/effect/Effect";
    import { Positive } from "tone/core/type/Units";
    import { Param } from "tone/core/context/Param";
    export interface BitCrusherOptions extends EffectOptions {
            bits: Positive;
    }
    /**
        * BitCrusher down-samples the incoming signal to a different bit depth.
        * Lowering the bit depth of the signal creates distortion. Read more about BitCrushing
        * on [Wikipedia](https://en.wikipedia.org/wiki/Bitcrusher).
        * @example
        * // initialize crusher and route a synth through it
        * const crusher = new Tone.BitCrusher(4).toDestination();
        * const synth = new Tone.Synth().connect(crusher);
        * synth.triggerAttackRelease("C2", 2);
        *
        * @category Effect
        */
    export class BitCrusher extends Effect<BitCrusherOptions> {
            readonly name: string;
            /**
                * The bit depth of the effect
                * @min 1
                * @max 16
                */
            readonly bits: Param<"positive">;
            constructor(bits?: Positive);
            constructor(options?: Partial<BitCrusherWorkletOptions>);
            static getDefaults(): BitCrusherOptions;
            dispose(): this;
    }
    interface BitCrusherWorkletOptions extends ToneAudioWorkletOptions {
            bits: number;
    }
    export {};
}

declare module 'tone/effect/Chebyshev' {
    import { Effect, EffectOptions } from "tone/effect/Effect";
    import { Positive } from "tone/core/type/Units";
    export interface ChebyshevOptions extends EffectOptions {
            order: Positive;
            oversample: OverSampleType;
    }
    /**
        * Chebyshev is a waveshaper which is good
        * for making different types of distortion sounds.
        * Note that odd orders sound very different from even ones,
        * and order = 1 is no change.
        * Read more at [music.columbia.edu](http://music.columbia.edu/cmc/musicandcomputers/chapter4/04_06.php).
        * @example
        * // create a new cheby
        * const cheby = new Tone.Chebyshev(50).toDestination();
        * // create a monosynth connected to our cheby
        * const synth = new Tone.MonoSynth().connect(cheby);
        * synth.triggerAttackRelease("C2", 0.4);
        * @category Effect
        */
    export class Chebyshev extends Effect<ChebyshevOptions> {
            readonly name: string;
            /**
                * @param order The order of the chebyshev polynomial. Normal range between 1-100.
                */
            constructor(order?: Positive);
            constructor(options?: Partial<ChebyshevOptions>);
            static getDefaults(): ChebyshevOptions;
            /**
                * The order of the Chebyshev polynomial which creates the equation which is applied to the incoming
                * signal through a Tone.WaveShaper. Must be an integer. The equations are in the form:
                * ```
                * order 2: 2x^2 + 1
                * order 3: 4x^3 + 3x
                * ```
                * @min 1
                * @max 100
                */
            get order(): Positive;
            set order(order: Positive);
            /**
                * The oversampling of the effect. Can either be "none", "2x" or "4x".
                */
            get oversample(): OverSampleType;
            set oversample(oversampling: OverSampleType);
            dispose(): this;
    }
}

declare module 'tone/effect/Chorus' {
    import { StereoFeedbackEffect, StereoFeedbackEffectOptions } from "tone/effect/StereoFeedbackEffect";
    import { Degrees, Frequency, Milliseconds, NormalRange, Time } from "tone/core/type/Units";
    import { ToneOscillatorType } from "tone/source/oscillator/OscillatorInterface";
    import { Signal } from "tone/signal/Signal";
    export interface ChorusOptions extends StereoFeedbackEffectOptions {
            frequency: Frequency;
            delayTime: Milliseconds;
            depth: NormalRange;
            type: ToneOscillatorType;
            spread: Degrees;
    }
    /**
        * Chorus is a stereo chorus effect composed of a left and right delay with an {@link LFO} applied to the delayTime of each channel.
        * When {@link feedback} is set to a value larger than 0, you also get Flanger-type effects.
        * Inspiration from [Tuna.js](https://github.com/Dinahmoe/tuna/blob/master/tuna.js).
        * Read more on the chorus effect on [Sound On Sound](http://www.soundonsound.com/sos/jun04/articles/synthsecrets.htm).
        *
        * @example
        * const chorus = new Tone.Chorus(4, 2.5, 0.5).toDestination().start();
        * const synth = new Tone.PolySynth().connect(chorus);
        * synth.triggerAttackRelease(["C3", "E3", "G3"], "8n");
        *
        * @category Effect
        */
    export class Chorus extends StereoFeedbackEffect<ChorusOptions> {
            readonly name: string;
            /**
                * The frequency of the LFO which modulates the delayTime.
                */
            readonly frequency: Signal<"frequency">;
            /**
                * @param frequency The frequency of the LFO.
                * @param delayTime The delay of the chorus effect in ms.
                * @param depth The depth of the chorus.
                */
            constructor(frequency?: Frequency, delayTime?: Milliseconds, depth?: NormalRange);
            constructor(options?: Partial<ChorusOptions>);
            static getDefaults(): ChorusOptions;
            /**
                * The depth of the effect. A depth of 1 makes the delayTime
                * modulate between 0 and 2*delayTime (centered around the delayTime).
                */
            get depth(): NormalRange;
            set depth(depth: NormalRange);
            /**
                * The delayTime in milliseconds of the chorus. A larger delayTime
                * will give a more pronounced effect. Nominal range a delayTime
                * is between 2 and 20ms.
                */
            get delayTime(): Milliseconds;
            set delayTime(delayTime: Milliseconds);
            /**
                * The oscillator type of the LFO.
                */
            get type(): ToneOscillatorType;
            set type(type: ToneOscillatorType);
            /**
                * Amount of stereo spread. When set to 0, both LFO's will be panned centrally.
                * When set to 180, LFO's will be panned hard left and right respectively.
                */
            get spread(): Degrees;
            set spread(spread: Degrees);
            /**
                * Start the effect.
                */
            start(time?: Time): this;
            /**
                * Stop the lfo
                */
            stop(time?: Time): this;
            /**
                * Sync the filter to the transport.
                * @see {@link LFO.sync}
                */
            sync(): this;
            /**
                * Unsync the filter from the transport.
                */
            unsync(): this;
            dispose(): this;
    }
}

declare module 'tone/effect/Distortion' {
    import { Effect, EffectOptions } from "tone/effect/Effect";
    export interface DistortionOptions extends EffectOptions {
            distortion: number;
            oversample: OverSampleType;
    }
    /**
        * A simple distortion effect using Tone.WaveShaper.
        * Algorithm from [this stackoverflow answer](http://stackoverflow.com/a/22313408).
        * Read more about distortion on [Wikipedia] (https://en.wikipedia.org/wiki/Distortion_(music)).
        * @example
        * const dist = new Tone.Distortion(0.8).toDestination();
        * const fm = new Tone.FMSynth().connect(dist);
        * fm.triggerAttackRelease("A1", "8n");
        * @category Effect
        */
    export class Distortion extends Effect<DistortionOptions> {
            readonly name: string;
            /**
                * @param distortion The amount of distortion (nominal range of 0-1)
                */
            constructor(distortion?: number);
            constructor(options?: Partial<DistortionOptions>);
            static getDefaults(): DistortionOptions;
            /**
                * The amount of distortion. Nominal range is between 0 and 1.
                */
            get distortion(): number;
            set distortion(amount: number);
            /**
                * The oversampling of the effect. Can either be "none", "2x" or "4x".
                */
            get oversample(): OverSampleType;
            set oversample(oversampling: OverSampleType);
            dispose(): this;
    }
}

declare module 'tone/effect/FeedbackDelay' {
    import { Param } from "tone/core/context/Param";
    import { NormalRange, Time } from "tone/core/type/Units";
    import { FeedbackEffect, FeedbackEffectOptions } from "tone/effect/FeedbackEffect";
    interface FeedbackDelayOptions extends FeedbackEffectOptions {
            delayTime: Time;
            maxDelay: Time;
    }
    /**
        * FeedbackDelay is a DelayNode in which part of output signal is fed back into the delay.
        *
        * @param delayTime The delay applied to the incoming signal.
        * @param feedback The amount of the effected signal which is fed back through the delay.
        * @example
        * const feedbackDelay = new Tone.FeedbackDelay("8n", 0.5).toDestination();
        * const tom = new Tone.MembraneSynth({
        * 	octaves: 4,
        * 	pitchDecay: 0.1
        * }).connect(feedbackDelay);
        * tom.triggerAttackRelease("A2", "32n");
        * @category Effect
        */
    export class FeedbackDelay extends FeedbackEffect<FeedbackDelayOptions> {
            readonly name: string;
            /**
                * The delayTime of the FeedbackDelay.
                */
            readonly delayTime: Param<"time">;
            constructor(delayTime?: Time, feedback?: NormalRange);
            constructor(options?: Partial<FeedbackDelayOptions>);
            static getDefaults(): FeedbackDelayOptions;
            dispose(): this;
    }
    export {};
}

declare module 'tone/effect/FrequencyShifter' {
    import { Frequency } from "tone/core/type/Units";
    import { Effect, EffectOptions } from "tone/effect/Effect";
    import { Signal } from "tone/signal/Signal";
    interface FrequencyShifterOptions extends EffectOptions {
            frequency: Frequency;
    }
    /**
        * FrequencyShifter can be used to shift all frequencies of a signal by a fixed amount.
        * The amount can be changed at audio rate and the effect is applied in real time.
        * The frequency shifting is implemented with a technique called single side band modulation using a ring modulator.
        * Note: Contrary to pitch shifting, all frequencies are shifted by the same amount,
        * destroying the harmonic relationship between them. This leads to the classic ring modulator timbre distortion.
        * The algorithm will produces some aliasing towards the high end, especially if your source material
        * contains a lot of high frequencies. Unfortunatelly the webaudio API does not support resampling
        * buffers in real time, so it is not possible to fix it properly. Depending on the use case it might
        * be an option to low pass filter your input before frequency shifting it to get ride of the aliasing.
        * You can find a very detailed description of the algorithm here: https://larzeitlin.github.io/RMFS/
        *
        * @example
        * const input = new Tone.Oscillator(230, "sawtooth").start();
        * const shift = new Tone.FrequencyShifter(42).toDestination();
        * input.connect(shift);
        * @category Effect
        */
    export class FrequencyShifter extends Effect<FrequencyShifterOptions> {
            readonly name: string;
            /**
                * The ring modulators carrier frequency. This frequency determines
                * by how many Hertz the input signal will be shifted up or down. Default is 0.
                */
            readonly frequency: Signal<"frequency">;
            /**
                * @param frequency The incoming signal is shifted by this frequency value.
                */
            constructor(frequency?: Frequency);
            constructor(options?: Partial<FrequencyShifterOptions>);
            static getDefaults(): FrequencyShifterOptions;
            dispose(): this;
    }
    export {};
}

declare module 'tone/effect/Freeverb' {
    import { StereoEffect, StereoEffectOptions } from "tone/effect/StereoEffect";
    import { Frequency, NormalRange } from "tone/core/type/Units";
    import { Signal } from "tone/signal/Signal";
    export interface FreeverbOptions extends StereoEffectOptions {
            dampening: Frequency;
            roomSize: NormalRange;
    }
    /**
        * Freeverb is a reverb based on [Freeverb](https://ccrma.stanford.edu/~jos/pasp/Freeverb.html).
        * Read more on reverb on [Sound On Sound](https://web.archive.org/web/20160404083902/http://www.soundonsound.com:80/sos/feb01/articles/synthsecrets.asp).
        * Freeverb is now implemented with an AudioWorkletNode which may result on performance degradation on some platforms. Consider using {@link Reverb}.
        * @example
        * const freeverb = new Tone.Freeverb().toDestination();
        * freeverb.dampening = 1000;
        * // routing synth through the reverb
        * const synth = new Tone.NoiseSynth().connect(freeverb);
        * synth.triggerAttackRelease(0.05);
        * @category Effect
        */
    export class Freeverb extends StereoEffect<FreeverbOptions> {
            readonly name: string;
            /**
                * The roomSize value between 0 and 1. A larger roomSize will result in a longer decay.
                */
            readonly roomSize: Signal<"normalRange">;
            /**
                * @param roomSize Correlated to the decay time.
                * @param dampening The cutoff frequency of a lowpass filter as part of the reverb.
                */
            constructor(roomSize?: NormalRange, dampening?: Frequency);
            constructor(options?: Partial<FreeverbOptions>);
            static getDefaults(): FreeverbOptions;
            /**
                * The amount of dampening of the reverberant signal.
                */
            get dampening(): Frequency;
            set dampening(d: Frequency);
            dispose(): this;
    }
}

declare module 'tone/effect/JCReverb' {
    import { NormalRange } from "tone/core/type/Units";
    import { StereoEffect, StereoEffectOptions } from "tone/effect/StereoEffect";
    import { Signal } from "tone/signal/Signal";
    export interface JCReverbOptions extends StereoEffectOptions {
            roomSize: NormalRange;
    }
    /**
        * JCReverb is a simple [Schroeder Reverberator](https://ccrma.stanford.edu/~jos/pasp/Schroeder_Reverberators.html)
        * tuned by John Chowning in 1970.
        * It is made up of three allpass filters and four {@link FeedbackCombFilter}.
        * JCReverb is now implemented with an AudioWorkletNode which may result on performance degradation on some platforms. Consider using {@link Reverb}.
        * @example
        * const reverb = new Tone.JCReverb(0.4).toDestination();
        * const delay = new Tone.FeedbackDelay(0.5);
        * // connecting the synth to reverb through delay
        * const synth = new Tone.DuoSynth().chain(delay, reverb);
        * synth.triggerAttackRelease("A4", "8n");
        *
        * @category Effect
        */
    export class JCReverb extends StereoEffect<JCReverbOptions> {
            readonly name: string;
            /**
                * Room size control values.
                */
            readonly roomSize: Signal<"normalRange">;
            /**
                * @param roomSize Correlated to the decay time.
                */
            constructor(roomSize?: NormalRange);
            constructor(options?: Partial<JCReverbOptions>);
            static getDefaults(): JCReverbOptions;
            dispose(): this;
    }
}

declare module 'tone/effect/PingPongDelay' {
    import { StereoXFeedbackEffect, StereoXFeedbackEffectOptions } from "tone/effect/StereoXFeedbackEffect";
    import { NormalRange, Seconds, Time } from "tone/core/type/Units";
    import { Signal } from "tone/signal/Signal";
    export interface PingPongDelayOptions extends StereoXFeedbackEffectOptions {
            delayTime: Time;
            maxDelay: Seconds;
    }
    /**
        * PingPongDelay is a feedback delay effect where the echo is heard
        * first in one channel and next in the opposite channel. In a stereo
        * system these are the right and left channels.
        * PingPongDelay in more simplified terms is two Tone.FeedbackDelays
        * with independent delay values. Each delay is routed to one channel
        * (left or right), and the channel triggered second will always
        * trigger at the same interval after the first.
        * @example
        * const pingPong = new Tone.PingPongDelay("4n", 0.2).toDestination();
        * const drum = new Tone.MembraneSynth().connect(pingPong);
        * drum.triggerAttackRelease("C4", "32n");
        * @category Effect
        */
    export class PingPongDelay extends StereoXFeedbackEffect<PingPongDelayOptions> {
            readonly name: string;
            /**
                * the delay time signal
                */
            readonly delayTime: Signal<"time">;
            /**
                * @param delayTime The delayTime between consecutive echos.
                * @param feedback The amount of the effected signal which is fed back through the delay.
                */
            constructor(delayTime?: Time, feedback?: NormalRange);
            constructor(options?: Partial<PingPongDelayOptions>);
            static getDefaults(): PingPongDelayOptions;
            dispose(): this;
    }
}

declare module 'tone/effect/PitchShift' {
    import { Interval, Seconds, Time } from "tone/core/type/Units";
    import { FeedbackEffect, FeedbackEffectOptions } from "tone/effect/FeedbackEffect";
    import { Param } from "tone/core/context/Param";
    export interface PitchShiftOptions extends FeedbackEffectOptions {
            pitch: Interval;
            windowSize: Seconds;
            delayTime: Time;
    }
    /**
        * PitchShift does near-realtime pitch shifting to the incoming signal.
        * The effect is achieved by speeding up or slowing down the delayTime
        * of a DelayNode using a sawtooth wave.
        * Algorithm found in [this pdf](http://dsp-book.narod.ru/soundproc.pdf).
        * Additional reference by [Miller Pucket](http://msp.ucsd.edu/techniques/v0.11/book-html/node115.html).
        * @category Effect
        */
    export class PitchShift extends FeedbackEffect<PitchShiftOptions> {
            readonly name: string;
            /**
                * The amount of delay on the input signal
                */
            readonly delayTime: Param<"time">;
            /**
                * @param pitch The interval to transpose the incoming signal by.
                */
            constructor(pitch?: Interval);
            constructor(options?: Partial<PitchShiftOptions>);
            static getDefaults(): PitchShiftOptions;
            /**
                * Repitch the incoming signal by some interval (measured in semi-tones).
                * @example
                * const pitchShift = new Tone.PitchShift().toDestination();
                * const osc = new Tone.Oscillator().connect(pitchShift).start().toDestination();
                * pitchShift.pitch = -12; // down one octave
                * pitchShift.pitch = 7; // up a fifth
                */
            get pitch(): number;
            set pitch(interval: number);
            /**
                * The window size corresponds roughly to the sample length in a looping sampler.
                * Smaller values are desirable for a less noticeable delay time of the pitch shifted
                * signal, but larger values will result in smoother pitch shifting for larger intervals.
                * A nominal range of 0.03 to 0.1 is recommended.
                */
            get windowSize(): Seconds;
            set windowSize(size: Seconds);
            dispose(): this;
    }
}

declare module 'tone/effect/Phaser' {
    import { StereoEffect, StereoEffectOptions } from "tone/effect/StereoEffect";
    import { Frequency, Positive } from "tone/core/type/Units";
    import { Signal } from "tone/signal/Signal";
    export interface PhaserOptions extends StereoEffectOptions {
            frequency: Frequency;
            octaves: Positive;
            stages: Positive;
            Q: Positive;
            baseFrequency: Frequency;
    }
    /**
        * Phaser is a phaser effect. Phasers work by changing the phase
        * of different frequency components of an incoming signal. Read more on
        * [Wikipedia](https://en.wikipedia.org/wiki/Phaser_(effect)).
        * Inspiration for this phaser comes from [Tuna.js](https://github.com/Dinahmoe/tuna/).
        * @example
        * const phaser = new Tone.Phaser({
        * 	frequency: 15,
        * 	octaves: 5,
        * 	baseFrequency: 1000
        * }).toDestination();
        * const synth = new Tone.FMSynth().connect(phaser);
        * synth.triggerAttackRelease("E3", "2n");
        * @category Effect
        */
    export class Phaser extends StereoEffect<PhaserOptions> {
            readonly name: string;
            /**
                * The quality factor of the filters
                */
            readonly Q: Signal<"positive">;
            /**
                * the frequency of the effect
                */
            readonly frequency: Signal<"frequency">;
            /**
                * @param frequency The speed of the phasing.
                * @param octaves The octaves of the effect.
                * @param baseFrequency The base frequency of the filters.
                */
            constructor(frequency?: Frequency, octaves?: Positive, baseFrequency?: Frequency);
            constructor(options?: Partial<PhaserOptions>);
            static getDefaults(): PhaserOptions;
            /**
                * The number of octaves the phase goes above the baseFrequency
                */
            get octaves(): number;
            set octaves(octaves: number);
            /**
                * The the base frequency of the filters.
                */
            get baseFrequency(): Frequency;
            set baseFrequency(freq: Frequency);
            dispose(): this;
    }
}

declare module 'tone/effect/Reverb' {
    import { Seconds, Time } from "tone/core/type/Units";
    import { Effect, EffectOptions } from "tone/effect/Effect";
    interface ReverbOptions extends EffectOptions {
            decay: Seconds;
            preDelay: Seconds;
    }
    /**
        * Simple convolution created with decaying noise.
        * Generates an Impulse Response Buffer
        * with Tone.Offline then feeds the IR into ConvolverNode.
        * The impulse response generation is async, so you have
        * to wait until {@link ready} resolves before it will make a sound.
        *
        * Inspiration from [ReverbGen](https://github.com/adelespinasse/reverbGen).
        * Copyright (c) 2014 Alan deLespinasse Apache 2.0 License.
        *
        * @category Effect
        */
    export class Reverb extends Effect<ReverbOptions> {
            readonly name: string;
            /**
                * Resolves when the reverb buffer is generated. Whenever either {@link decay}
                * or {@link preDelay} are set, you have to wait until {@link ready} resolves
                * before the IR is generated with the latest values.
                */
            ready: Promise<void>;
            /**
                * @param decay The amount of time it will reverberate for.
                */
            constructor(decay?: Seconds);
            constructor(options?: Partial<ReverbOptions>);
            static getDefaults(): ReverbOptions;
            /**
                * The duration of the reverb.
                */
            get decay(): Time;
            set decay(time: Time);
            /**
                * The amount of time before the reverb is fully ramped in.
                */
            get preDelay(): Time;
            set preDelay(time: Time);
            /**
                * Generate the Impulse Response. Returns a promise while the IR is being generated.
                * @return Promise which returns this object.
                */
            generate(): Promise<this>;
            dispose(): this;
    }
    export {};
}

declare module 'tone/effect/StereoWidener' {
    import { MidSideEffect, MidSideEffectOptions } from "tone/effect/MidSideEffect";
    import { Signal } from "tone/signal/Signal";
    import { NormalRange } from "tone/core/type/Units";
    export interface StereoWidenerOptions extends MidSideEffectOptions {
            width: NormalRange;
    }
    /**
        * Applies a width factor to the mid/side seperation.
        * 0 is all mid and 1 is all side.
        * Algorithm found in [kvraudio forums](http://www.kvraudio.com/forum/viewtopic.php?t=212587).
        * ```
        * Mid *= 2*(1-width)<br>
        * Side *= 2*width
        * ```
        * @category Effect
        */
    export class StereoWidener extends MidSideEffect<StereoWidenerOptions> {
            readonly name: string;
            /**
                * The width control. 0 = 100% mid. 1 = 100% side. 0.5 = no change.
                */
            readonly width: Signal<"normalRange">;
            /**
                * @param width The stereo width. A width of 0 is mono and 1 is stereo. 0.5 is no change.
                */
            constructor(width?: NormalRange);
            constructor(options?: Partial<StereoWidenerOptions>);
            static getDefaults(): StereoWidenerOptions;
            dispose(): this;
    }
}

declare module 'tone/effect/Tremolo' {
    import { StereoEffect, StereoEffectOptions } from "tone/effect/StereoEffect";
    import { Signal } from "tone/signal/Signal";
    import { Degrees, Frequency, NormalRange, Time } from "tone/core/type/Units";
    import { ToneOscillatorType } from "tone/source/oscillator/OscillatorInterface";
    export interface TremoloOptions extends StereoEffectOptions {
            frequency: Frequency;
            type: ToneOscillatorType;
            depth: NormalRange;
            spread: Degrees;
    }
    /**
        * Tremolo modulates the amplitude of an incoming signal using an {@link LFO}.
        * The effect is a stereo effect where the modulation phase is inverted in each channel.
        *
        * @example
        * // create a tremolo and start it's LFO
        * const tremolo = new Tone.Tremolo(9, 0.75).toDestination().start();
        * // route an oscillator through the tremolo and start it
        * const oscillator = new Tone.Oscillator().connect(tremolo).start();
        *
        * @category Effect
        */
    export class Tremolo extends StereoEffect<TremoloOptions> {
            readonly name: string;
            /**
                * The frequency of the tremolo.
                */
            readonly frequency: Signal<"frequency">;
            /**
                * The depth of the effect. A depth of 0, has no effect
                * on the amplitude, and a depth of 1 makes the amplitude
                * modulate fully between 0 and 1.
                */
            readonly depth: Signal<"normalRange">;
            /**
                * @param frequency The rate of the effect.
                * @param depth The depth of the effect.
                */
            constructor(frequency?: Frequency, depth?: NormalRange);
            constructor(options?: Partial<TremoloOptions>);
            static getDefaults(): TremoloOptions;
            /**
                * Start the tremolo.
                */
            start(time?: Time): this;
            /**
                * Stop the tremolo.
                */
            stop(time?: Time): this;
            /**
                * Sync the effect to the transport.
                */
            sync(): this;
            /**
                * Unsync the filter from the transport
                */
            unsync(): this;
            /**
                * The oscillator type.
                */
            get type(): ToneOscillatorType;
            set type(type: ToneOscillatorType);
            /**
                * Amount of stereo spread. When set to 0, both LFO's will be panned centrally.
                * When set to 180, LFO's will be panned hard left and right respectively.
                */
            get spread(): Degrees;
            set spread(spread: Degrees);
            dispose(): this;
    }
}

declare module 'tone/effect/Vibrato' {
    import { Effect, EffectOptions } from "tone/effect/Effect";
    import { ToneOscillatorType } from "tone/source/oscillator/OscillatorInterface";
    import { Frequency, NormalRange, Seconds } from "tone/core/type/Units";
    import { Signal } from "tone/signal/Signal";
    import { Param } from "tone/core/context/Param";
    export interface VibratoOptions extends EffectOptions {
            maxDelay: Seconds;
            frequency: Frequency;
            depth: NormalRange;
            type: ToneOscillatorType;
    }
    /**
        * A Vibrato effect composed of a Tone.Delay and a Tone.LFO. The LFO
        * modulates the delayTime of the delay, causing the pitch to rise and fall.
        * @category Effect
        */
    export class Vibrato extends Effect<VibratoOptions> {
            readonly name: string;
            /**
                * The frequency of the vibrato
                */
            readonly frequency: Signal<"frequency">;
            /**
                * The depth of the vibrato.
                */
            readonly depth: Param<"normalRange">;
            /**
                * @param frequency The frequency of the vibrato.
                * @param depth The amount the pitch is modulated.
                */
            constructor(frequency?: Frequency, depth?: NormalRange);
            constructor(options?: Partial<VibratoOptions>);
            static getDefaults(): VibratoOptions;
            /**
                * Type of oscillator attached to the Vibrato.
                */
            get type(): ToneOscillatorType;
            set type(type: ToneOscillatorType);
            dispose(): this;
    }
}

declare module 'tone/component/analysis/Analyser' {
    import { InputNode, OutputNode, ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { NormalRange, PowerOfTwo } from "tone/core/type/Units";
    export type AnalyserType = "fft" | "waveform";
    export interface AnalyserOptions extends ToneAudioNodeOptions {
            size: PowerOfTwo;
            type: AnalyserType;
            smoothing: NormalRange;
            channels: number;
    }
    /**
        * Wrapper around the native Web Audio's [AnalyserNode](http://webaudio.github.io/web-audio-api/#idl-def-AnalyserNode).
        * Extracts FFT or Waveform data from the incoming signal.
        * @category Component
        */
    export class Analyser extends ToneAudioNode<AnalyserOptions> {
            readonly name: string;
            readonly input: InputNode;
            readonly output: OutputNode;
            /**
                * @param type The return type of the analysis, either "fft", or "waveform".
                * @param size The size of the FFT. This must be a power of two in the range 16 to 16384.
                */
            constructor(type?: AnalyserType, size?: number);
            constructor(options?: Partial<AnalyserOptions>);
            static getDefaults(): AnalyserOptions;
            /**
                * Run the analysis given the current settings. If {@link channels} = 1,
                * it will return a Float32Array. If {@link channels} > 1, it will
                * return an array of Float32Arrays where each index in the array
                * represents the analysis done on a channel.
                */
            getValue(): Float32Array | Float32Array[];
            /**
                * The size of analysis. This must be a power of two in the range 16 to 16384.
                */
            get size(): PowerOfTwo;
            set size(size: PowerOfTwo);
            /**
                * The number of channels the analyser does the analysis on. Channel
                * separation is done using {@link Split}
                */
            get channels(): number;
            /**
                * The analysis function returned by analyser.getValue(), either "fft" or "waveform".
                */
            get type(): AnalyserType;
            set type(type: AnalyserType);
            /**
                * 0 represents no time averaging with the last analysis frame.
                */
            get smoothing(): NormalRange;
            set smoothing(val: NormalRange);
            /**
                * Clean up.
                */
            dispose(): this;
    }
}

declare module 'tone/component/analysis/Meter' {
    import { NormalRange } from "tone/core/type/Units";
    import { MeterBase, MeterBaseOptions } from "tone/component/analysis/MeterBase";
    export interface MeterOptions extends MeterBaseOptions {
            smoothing: NormalRange;
            normalRange: boolean;
            channelCount: number;
    }
    /**
        * Meter gets the [RMS](https://en.wikipedia.org/wiki/Root_mean_square)
        * of an input signal. It can also get the raw value of the input signal.
        * Setting `normalRange` to `true` will covert the output to a range of
        * 0-1. See an example using a graphical display
        * [here](https://tonejs.github.io/examples/meter).
        * @see {@link DCMeter}.
        *
        * @example
        * const meter = new Tone.Meter();
        * const mic = new Tone.UserMedia();
        * mic.open();
        * // connect mic to the meter
        * mic.connect(meter);
        * // the current level of the mic
        * setInterval(() => console.log(meter.getValue()), 100);
        * @category Component
        */
    export class Meter extends MeterBase<MeterOptions> {
            readonly name: string;
            /**
                * If the output should be in decibels or normal range between 0-1. If `normalRange` is false,
                * the output range will be the measured decibel value, otherwise the decibel value will be converted to
                * the range of 0-1
                */
            normalRange: boolean;
            /**
                * A value from between 0 and 1 where 0 represents no time averaging with the last analysis frame.
                */
            smoothing: number;
            /**
                * @param smoothing The amount of smoothing applied between frames.
                */
            constructor(smoothing?: NormalRange);
            constructor(options?: Partial<MeterOptions>);
            static getDefaults(): MeterOptions;
            /**
                * Use {@link getValue} instead. For the previous getValue behavior, use DCMeter.
                * @deprecated
                */
            getLevel(): number | number[];
            /**
                * Get the current value of the incoming signal.
                * Output is in decibels when {@link normalRange} is `false`.
                * If {@link channels} = 1, then the output is a single number
                * representing the value of the input signal. When {@link channels} > 1,
                * then each channel is returned as a value in a number array.
                */
            getValue(): number | number[];
            /**
                * The number of channels of analysis.
                */
            get channels(): number;
            dispose(): this;
    }
}

declare module 'tone/component/analysis/FFT' {
    import { Hertz, NormalRange, PowerOfTwo } from "tone/core/type/Units";
    import { MeterBase, MeterBaseOptions } from "tone/component/analysis/MeterBase";
    export interface FFTOptions extends MeterBaseOptions {
            size: PowerOfTwo;
            smoothing: NormalRange;
            normalRange: boolean;
    }
    /**
        * Get the current frequency data of the connected audio source using a fast Fourier transform.
        * Read more about FFT algorithms on [Wikipedia] (https://en.wikipedia.org/wiki/Fast_Fourier_transform).
        * @category Component
        */
    export class FFT extends MeterBase<FFTOptions> {
            readonly name: string;
            /**
                * If the output should be in decibels or normal range between 0-1. If `normalRange` is false,
                * the output range will be the measured decibel value, otherwise the decibel value will be converted to
                * the range of 0-1
                */
            normalRange: boolean;
            /**
                * @param size The size of the FFT. Value must be a power of two in the range 16 to 16384.
                */
            constructor(size?: PowerOfTwo);
            constructor(options?: Partial<FFTOptions>);
            static getDefaults(): FFTOptions;
            /**
                * Gets the current frequency data from the connected audio source.
                * Returns the frequency data of length {@link size} as a Float32Array of decibel values.
                */
            getValue(): Float32Array;
            /**
                * The size of analysis. This must be a power of two in the range 16 to 16384.
                * Determines the size of the array returned by {@link getValue} (i.e. the number of
                * frequency bins). Large FFT sizes may be costly to compute.
                */
            get size(): PowerOfTwo;
            set size(size: PowerOfTwo);
            /**
                * 0 represents no time averaging with the last analysis frame.
                */
            get smoothing(): NormalRange;
            set smoothing(val: NormalRange);
            /**
                * Returns the frequency value in hertz of each of the indices of the FFT's {@link getValue} response.
                * @example
                * const fft = new Tone.FFT(32);
                * console.log([0, 1, 2, 3, 4].map(index => fft.getFrequencyOfIndex(index)));
                */
            getFrequencyOfIndex(index: number): Hertz;
    }
}

declare module 'tone/component/analysis/DCMeter' {
    import { MeterBase, MeterBaseOptions } from "tone/component/analysis/MeterBase";
    export type DCMeterOptions = MeterBaseOptions;
    /**
        * DCMeter gets the raw value of the input signal at the current time.
        * @see {@link Meter}.
        *
        * @example
        * const meter = new Tone.DCMeter();
        * const mic = new Tone.UserMedia();
        * mic.open();
        * // connect mic to the meter
        * mic.connect(meter);
        * // the current level of the mic
        * const level = meter.getValue();
        * @category Component
        */
    export class DCMeter extends MeterBase<DCMeterOptions> {
            readonly name: string;
            constructor(options?: Partial<DCMeterOptions>);
            /**
                * Get the signal value of the incoming signal
                */
            getValue(): number;
    }
}

declare module 'tone/component/analysis/Waveform' {
    import { PowerOfTwo } from "tone/core/type/Units";
    import { MeterBase, MeterBaseOptions } from "tone/component/analysis/MeterBase";
    export interface WaveformOptions extends MeterBaseOptions {
            /**
                * The size of the Waveform. Value must be a power of two in the range 16 to 16384.
                */
            size: PowerOfTwo;
    }
    /**
        * Get the current waveform data of the connected audio source.
        * @category Component
        */
    export class Waveform extends MeterBase<WaveformOptions> {
            readonly name: string;
            /**
                * @param size The size of the Waveform. Value must be a power of two in the range 16 to 16384.
                */
            constructor(size?: PowerOfTwo);
            constructor(options?: Partial<WaveformOptions>);
            static getDefaults(): WaveformOptions;
            /**
                * Return the waveform for the current time as a Float32Array where each value in the array
                * represents a sample in the waveform.
                */
            getValue(): Float32Array;
            /**
                * The size of analysis. This must be a power of two in the range 16 to 16384.
                * Determines the size of the array returned by {@link getValue}.
                */
            get size(): PowerOfTwo;
            set size(size: PowerOfTwo);
    }
}

declare module 'tone/component/analysis/Follower' {
    import { Time } from "tone/core/type/Units";
    import { InputNode, OutputNode, ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    export interface FollowerOptions extends ToneAudioNodeOptions {
            smoothing: Time;
    }
    /**
        * Follower is a simple envelope follower.
        * It's implemented by applying a lowpass filter to the absolute value of the incoming signal.
        * ```
        *          +-----+    +---------------+
        * Input +--> Abs +----> OnePoleFilter +--> Output
        *          +-----+    +---------------+
        * ```
        * @category Component
        */
    export class Follower extends ToneAudioNode<FollowerOptions> {
            readonly name: string;
            readonly input: InputNode;
            readonly output: OutputNode;
            /**
                * @param smoothing The rate of change of the follower.
                */
            constructor(smoothing?: Time);
            constructor(options?: Partial<FollowerOptions>);
            static getDefaults(): FollowerOptions;
            /**
                * The amount of time it takes a value change to arrive at the updated value.
                */
            get smoothing(): Time;
            set smoothing(smoothing: Time);
            dispose(): this;
    }
}

declare module 'tone/component/channel/Channel' {
    import { AudioRange, Decibels } from "tone/core/type/Units";
    import { InputNode, OutputNode, ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { Param } from "tone/core/context/Param";
    import { Gain } from "tone/core/context/Gain";
    export interface ChannelOptions extends ToneAudioNodeOptions {
            pan: AudioRange;
            volume: Decibels;
            solo: boolean;
            mute: boolean;
            channelCount: number;
    }
    /**
        * Channel provides a channel strip interface with volume, pan, solo and mute controls.
        * @see {@link PanVol} and {@link Solo}
        * @example
        * // pan the incoming signal left and drop the volume 12db
        * const channel = new Tone.Channel(-0.25, -12);
        * @category Component
        */
    export class Channel extends ToneAudioNode<ChannelOptions> {
            readonly name: string;
            readonly input: InputNode;
            readonly output: OutputNode;
            /**
                * The L/R panning control. -1 = hard left, 1 = hard right.
                * @min -1
                * @max 1
                */
            readonly pan: Param<"audioRange">;
            /**
                * The volume control in decibels.
                */
            readonly volume: Param<"decibels">;
            /**
                * @param volume The output volume.
                * @param pan the initial pan
                */
            constructor(volume?: Decibels, pan?: AudioRange);
            constructor(options?: Partial<ChannelOptions>);
            static getDefaults(): ChannelOptions;
            /**
                * Solo/unsolo the channel. Soloing is only relative to other {@link Channel}s and {@link Solo} instances
                */
            get solo(): boolean;
            set solo(solo: boolean);
            /**
                * If the current instance is muted, i.e. another instance is soloed,
                * or the channel is muted
                */
            get muted(): boolean;
            /**
                * Mute/unmute the volume
                */
            get mute(): boolean;
            set mute(mute: boolean);
            /**
                * Send audio to another channel using a string. `send` is a lot like
                * {@link connect}, except it uses a string instead of an object. This can
                * be useful in large applications to decouple sections since {@link send}
                * and {@link receive} can be invoked separately in order to connect an object
                * @param name The channel name to send the audio
                * @param volume The amount of the signal to send.
                * 	Defaults to 0db, i.e. send the entire signal
                * @returns Returns the gain node of this connection.
                */
            send(name: string, volume?: Decibels): Gain<"decibels">;
            /**
                * Receive audio from a channel which was connected with {@link send}.
                * @param name The channel name to receive audio from.
                */
            receive(name: string): this;
            dispose(): this;
    }
}

declare module 'tone/component/channel/CrossFade' {
    import { Gain } from "tone/core/context/Gain";
    import { ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { NormalRange } from "tone/core/type/Units";
    import { Signal } from "tone/signal/Signal";
    interface CrossFadeOptions extends ToneAudioNodeOptions {
            fade: NormalRange;
    }
    /**
        * Tone.Crossfade provides equal power fading between two inputs.
        * More on crossfading technique [here](https://en.wikipedia.org/wiki/Fade_(audio_engineering)#Crossfading).
        * ```
        *                                             +---------+
        *                                            +> input a +>--+
        * +-----------+   +---------------------+     |         |   |
        * | 1s signal +>--> stereoPannerNode  L +>----> gain    |   |
        * +-----------+   |                     |     +---------+   |
        *               +-> pan               R +>-+                |   +--------+
        *               | +---------------------+  |                +---> output +>
        *  +------+     |                          |  +---------+   |   +--------+
        *  | fade +>----+                          | +> input b +>--+
        *  +------+                                |  |         |
        *                                          +--> gain    |
        *                                             +---------+
        * ```
        * @example
        * const crossFade = new Tone.CrossFade().toDestination();
        * // connect two inputs Tone.to a/b
        * const inputA = new Tone.Oscillator(440, "square").connect(crossFade.a).start();
        * const inputB = new Tone.Oscillator(440, "sine").connect(crossFade.b).start();
        * // use the fade to control the mix between the two
        * crossFade.fade.value = 0.5;
        * @category Component
        */
    export class CrossFade extends ToneAudioNode<CrossFadeOptions> {
            readonly name: string;
            /**
                * The input which is at full level when fade = 0
                */
            readonly a: Gain;
            /**
                * The input which is at full level when fade = 1
                */
            readonly b: Gain;
            /**
                * The output is a mix between `a` and `b` at the ratio of `fade`
                */
            readonly output: Gain;
            /**
                * CrossFade has no input, you must choose either `a` or `b`
                */
            readonly input: undefined;
            /**
                * The mix between the two inputs. A fade value of 0
                * will output 100% crossFade.a and
                * a value of 1 will output 100% crossFade.b.
                */
            readonly fade: Signal<"normalRange">;
            protected _internalChannels: Gain<"gain">[];
            /**
                * @param fade The initial fade value [0, 1].
                */
            constructor(fade?: NormalRange);
            constructor(options?: Partial<CrossFadeOptions>);
            static getDefaults(): CrossFadeOptions;
            dispose(): this;
    }
    export {};
}

declare module 'tone/component/channel/Merge' {
    import { ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { Positive } from "tone/core/type/Units";
    interface MergeOptions extends ToneAudioNodeOptions {
            channels: Positive;
    }
    /**
        * Merge brings multiple mono input channels into a single multichannel output channel.
        *
        * @example
        * const merge = new Tone.Merge().toDestination();
        * // routing a sine tone in the left channel
        * const osc = new Tone.Oscillator().connect(merge, 0, 0).start();
        * // and noise in the right channel
        * const noise = new Tone.Noise().connect(merge, 0, 1).start();;
        * @category Component
        */
    export class Merge extends ToneAudioNode<MergeOptions> {
            readonly name: string;
            /**
                * The output is the input channels combined into a single (multichannel) output
                */
            readonly output: ChannelMergerNode;
            /**
                * Multiple input connections combine into a single output.
                */
            readonly input: ChannelMergerNode;
            /**
                * @param channels The number of channels to merge.
                */
            constructor(channels?: Positive);
            constructor(options?: Partial<MergeOptions>);
            static getDefaults(): MergeOptions;
            dispose(): this;
    }
    export {};
}

declare module 'tone/component/channel/MidSideMerge' {
    import { ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { Merge } from "tone/component/channel/Merge";
    export type MidSideMergeOptions = ToneAudioNodeOptions;
    /**
        * MidSideMerge merges the mid and side signal after they've been separated by {@link MidSideSplit}
        * ```
        * Mid = (Left+Right)/sqrt(2);   // obtain mid-signal from left and right
        * Side = (Left-Right)/sqrt(2);   // obtain side-signal from left and right
        * ```
        * @category Component
        */
    export class MidSideMerge extends ToneAudioNode<MidSideMergeOptions> {
            readonly name: string;
            /**
                * There is no input, connect sources to either {@link mid} or {@link side} inputs.
                */
            readonly input: undefined;
            /**
                * The merged signal
                */
            readonly output: Merge;
            /**
                * The "mid" input.
                */
            readonly mid: ToneAudioNode;
            /**
                * The "side" input.
                */
            readonly side: ToneAudioNode;
            constructor(options?: Partial<MidSideMergeOptions>);
            dispose(): this;
    }
}

declare module 'tone/component/channel/MidSideSplit' {
    import { ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { Split } from "tone/component/channel/Split";
    export type MidSideSplitOptions = ToneAudioNodeOptions;
    /**
        * Mid/Side processing separates the the 'mid' signal (which comes out of both the left and the right channel)
        * and the 'side' (which only comes out of the the side channels).
        * ```
        * Mid = (Left+Right)/sqrt(2);   // obtain mid-signal from left and right
        * Side = (Left-Right)/sqrt(2);   // obtain side-signal from left and right
        * ```
        * @category Component
        */
    export class MidSideSplit extends ToneAudioNode<MidSideSplitOptions> {
            readonly name: string;
            readonly input: Split;
            /**
                * There is no output node, use either {@link mid} or {@link side} outputs.
                */
            readonly output: undefined;
            /**
                * The "mid" output. `(Left+Right)/sqrt(2)`
                */
            readonly mid: ToneAudioNode;
            /**
                * The "side" output. `(Left-Right)/sqrt(2)`
                */
            readonly side: ToneAudioNode;
            constructor(options?: Partial<MidSideSplitOptions>);
            dispose(): this;
    }
}

declare module 'tone/component/channel/Mono' {
    import { Gain } from "tone/core/context/Gain";
    import { OutputNode, ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    export type MonoOptions = ToneAudioNodeOptions;
    /**
        * Mono coerces the incoming mono or stereo signal into a mono signal
        * where both left and right channels have the same value. This can be useful
        * for [stereo imaging](https://en.wikipedia.org/wiki/Stereo_imaging).
        * @category Component
        */
    export class Mono extends ToneAudioNode<MonoOptions> {
            readonly name: string;
            /**
                * The summed output of the multiple inputs
                */
            readonly output: OutputNode;
            /**
                * The stereo signal to sum to mono
                */
            readonly input: Gain;
            constructor(options?: Partial<MonoOptions>);
            dispose(): this;
    }
}

declare module 'tone/component/channel/MultibandSplit' {
    import { Gain } from "tone/core/context/Gain";
    import { ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { Frequency, Positive } from "tone/core/type/Units";
    import { Signal } from "tone/signal/Signal";
    import { Filter } from "tone/component/filter/Filter";
    interface MultibandSplitOptions extends ToneAudioNodeOptions {
            Q: Positive;
            lowFrequency: Frequency;
            highFrequency: Frequency;
    }
    /**
        * Split the incoming signal into three bands (low, mid, high)
        * with two crossover frequency controls.
        * ```
        *            +----------------------+
        *          +-> input < lowFrequency +------------------> low
        *          | +----------------------+
        *          |
        *          | +--------------------------------------+
        * input ---+-> lowFrequency < input < highFrequency +--> mid
        *          | +--------------------------------------+
        *          |
        *          | +-----------------------+
        *          +-> highFrequency < input +-----------------> high
        *            +-----------------------+
        * ```
        * @category Component
        */
    export class MultibandSplit extends ToneAudioNode<MultibandSplitOptions> {
            readonly name: string;
            /**
                * the input
                */
            readonly input: Gain<"gain">;
            /**
                * no output node, use either low, mid or high outputs
                */
            readonly output: undefined;
            /**
                * The low band.
                */
            readonly low: Filter;
            /**
                * The mid band output.
                */
            readonly mid: Filter;
            /**
                * The high band output.
                */
            readonly high: Filter;
            /**
                * The low/mid crossover frequency.
                */
            readonly lowFrequency: Signal<"frequency">;
            /**
                * The mid/high crossover frequency.
                */
            readonly highFrequency: Signal<"frequency">;
            protected _internalChannels: Filter[];
            /**
                * The Q or Quality of the filter
                */
            readonly Q: Signal<"positive">;
            /**
                * @param lowFrequency the low/mid crossover frequency
                * @param highFrequency the mid/high crossover frequency
                */
            constructor(lowFrequency?: Frequency, highFrequency?: Frequency);
            constructor(options?: Partial<MultibandSplitOptions>);
            static getDefaults(): MultibandSplitOptions;
            /**
                * Clean up.
                */
            dispose(): this;
    }
    export {};
}

declare module 'tone/component/channel/Panner' {
    import { Param } from "tone/core/context/Param";
    import { ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { AudioRange } from "tone/core/type/Units";
    interface TonePannerOptions extends ToneAudioNodeOptions {
            pan: AudioRange;
            channelCount: number;
    }
    /**
        * Panner is an equal power Left/Right Panner. It is a wrapper around the StereoPannerNode.
        * @example
        * return Tone.Offline(() => {
        * // move the input signal from right to left
        * 	const panner = new Tone.Panner(1).toDestination();
        * 	panner.pan.rampTo(-1, 0.5);
        * 	const osc = new Tone.Oscillator(100).connect(panner).start();
        * }, 0.5, 2);
        * @category Component
        */
    export class Panner extends ToneAudioNode<TonePannerOptions> {
            readonly name: string;
            readonly input: StereoPannerNode;
            readonly output: StereoPannerNode;
            /**
                * The pan control. -1 = hard left, 1 = hard right.
                * @min -1
                * @max 1
                * @example
                * return Tone.Offline(() => {
                * 	// pan hard right
                * 	const panner = new Tone.Panner(1).toDestination();
                * 	// pan hard left
                * 	panner.pan.setValueAtTime(-1, 0.25);
                * 	const osc = new Tone.Oscillator(50, "triangle").connect(panner).start();
                * }, 0.5, 2);
                */
            readonly pan: Param<"audioRange">;
            constructor(options?: Partial<TonePannerOptions>);
            /**
                * @param pan The initial panner value (Defaults to 0 = "center").
                */
            constructor(pan?: AudioRange);
            static getDefaults(): TonePannerOptions;
            dispose(): this;
    }
    export {};
}

declare module 'tone/component/channel/Panner3D' {
    import { Param } from "tone/core/context/Param";
    import { ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { Degrees, GainFactor } from "tone/core/type/Units";
    import "../../core/context/Listener";
    export interface Panner3DOptions extends ToneAudioNodeOptions {
            coneInnerAngle: Degrees;
            coneOuterAngle: Degrees;
            coneOuterGain: GainFactor;
            distanceModel: DistanceModelType;
            maxDistance: number;
            orientationX: number;
            orientationY: number;
            orientationZ: number;
            panningModel: PanningModelType;
            positionX: number;
            positionY: number;
            positionZ: number;
            refDistance: number;
            rolloffFactor: number;
    }
    /**
        * A spatialized panner node which supports equalpower or HRTF panning.
        * @category Component
        */
    export class Panner3D extends ToneAudioNode<Panner3DOptions> {
            readonly name: string;
            readonly input: PannerNode;
            readonly output: PannerNode;
            readonly positionX: Param<"number">;
            readonly positionY: Param<"number">;
            readonly positionZ: Param<"number">;
            readonly orientationX: Param<"number">;
            readonly orientationY: Param<"number">;
            readonly orientationZ: Param<"number">;
            /**
                * @param positionX The initial x position.
                * @param positionY The initial y position.
                * @param positionZ The initial z position.
                */
            constructor(positionX: number, positionY: number, positionZ: number);
            constructor(options?: Partial<Panner3DOptions>);
            static getDefaults(): Panner3DOptions;
            /**
                * Sets the position of the source in 3d space.
                */
            setPosition(x: number, y: number, z: number): this;
            /**
                * Sets the orientation of the source in 3d space.
                */
            setOrientation(x: number, y: number, z: number): this;
            /**
                * The panning model. Either "equalpower" or "HRTF".
                */
            get panningModel(): PanningModelType;
            set panningModel(val: PanningModelType);
            /**
                * A reference distance for reducing volume as source move further from the listener
                */
            get refDistance(): number;
            set refDistance(val: number);
            /**
                * Describes how quickly the volume is reduced as source moves away from listener.
                */
            get rolloffFactor(): number;
            set rolloffFactor(val: number);
            /**
                * The distance model used by,  "linear", "inverse", or "exponential".
                */
            get distanceModel(): DistanceModelType;
            set distanceModel(val: DistanceModelType);
            /**
                * The angle, in degrees, inside of which there will be no volume reduction
                */
            get coneInnerAngle(): Degrees;
            set coneInnerAngle(val: Degrees);
            /**
                * The angle, in degrees, outside of which the volume will be reduced
                * to a constant value of coneOuterGain
                */
            get coneOuterAngle(): Degrees;
            set coneOuterAngle(val: Degrees);
            /**
                * The gain outside of the coneOuterAngle
                */
            get coneOuterGain(): GainFactor;
            set coneOuterGain(val: GainFactor);
            /**
                * The maximum distance between source and listener,
                * after which the volume will not be reduced any further.
                */
            get maxDistance(): number;
            set maxDistance(val: number);
            dispose(): this;
    }
}

declare module 'tone/component/channel/PanVol' {
    import { Param } from "tone/core/context/Param";
    import { InputNode, OutputNode, ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { AudioRange, Decibels } from "tone/core/type/Units";
    export interface PanVolOptions extends ToneAudioNodeOptions {
            pan: AudioRange;
            volume: Decibels;
            mute: boolean;
            channelCount: number;
    }
    /**
        * PanVol is a Tone.Panner and Tone.Volume in one.
        * @example
        * // pan the incoming signal left and drop the volume
        * const panVol = new Tone.PanVol(-0.25, -12).toDestination();
        * const osc = new Tone.Oscillator().connect(panVol).start();
        * @category Component
        */
    export class PanVol extends ToneAudioNode<PanVolOptions> {
            readonly name: string;
            readonly input: InputNode;
            readonly output: OutputNode;
            /**
                * The L/R panning control. -1 = hard left, 1 = hard right.
                * @min -1
                * @max 1
                */
            readonly pan: Param<"audioRange">;
            /**
                * The volume control in decibels.
                */
            readonly volume: Param<"decibels">;
            /**
                * @param pan the initial pan
                * @param volume The output volume.
                */
            constructor(pan?: AudioRange, volume?: Decibels);
            constructor(options?: Partial<PanVolOptions>);
            static getDefaults(): PanVolOptions;
            /**
                * Mute/unmute the volume
                */
            get mute(): boolean;
            set mute(mute: boolean);
            dispose(): this;
    }
}

declare module 'tone/component/channel/Recorder' {
    import { ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { Gain } from "tone/core/context/Gain";
    import { PlaybackState } from "tone/core/util/StateTimeline";
    export interface RecorderOptions extends ToneAudioNodeOptions {
            mimeType?: string;
    }
    /**
        * A wrapper around the MediaRecorder API. Unlike the rest of Tone.js, this module does not offer
        * any sample-accurate scheduling because it is not a feature of the MediaRecorder API.
        * This is only natively supported in Chrome and Firefox.
        * For a cross-browser shim, install (audio-recorder-polyfill)[https://www.npmjs.com/package/audio-recorder-polyfill].
        * @example
        * const recorder = new Tone.Recorder();
        * const synth = new Tone.Synth().connect(recorder);
        * // start recording
        * recorder.start();
        * // generate a few notes
        * synth.triggerAttackRelease("C3", 0.5);
        * synth.triggerAttackRelease("C4", 0.5, "+1");
        * synth.triggerAttackRelease("C5", 0.5, "+2");
        * // wait for the notes to end and stop the recording
        * setTimeout(async () => {
        * 	// the recorded audio is returned as a blob
        * 	const recording = await recorder.stop();
        * 	// download the recording by creating an anchor element and blob url
        * 	const url = URL.createObjectURL(recording);
        * 	const anchor = document.createElement("a");
        * 	anchor.download = "recording.webm";
        * 	anchor.href = url;
        * 	anchor.click();
        * }, 4000);
        * @category Component
        */
    export class Recorder extends ToneAudioNode<RecorderOptions> {
            readonly name = "Recorder";
            readonly input: Gain;
            readonly output: undefined;
            constructor(options?: Partial<RecorderOptions>);
            static getDefaults(): RecorderOptions;
            /**
                * The mime type is the format that the audio is encoded in. For Chrome
                * that is typically webm encoded as "vorbis".
                */
            get mimeType(): string;
            /**
                * Test if your platform supports the Media Recorder API. If it's not available,
                * try installing this (polyfill)[https://www.npmjs.com/package/audio-recorder-polyfill].
                */
            static get supported(): boolean;
            /**
                * Get the playback state of the Recorder, either "started", "stopped" or "paused"
                */
            get state(): PlaybackState;
            /**
                * Start the Recorder. Returns a promise which resolves
                * when the recorder has started.
                */
            start(): Promise<void>;
            /**
                * Stop the recorder. Returns a promise with the recorded content until this point
                * encoded as {@link mimeType}
                */
            stop(): Promise<Blob>;
            /**
                * Pause the recorder
                */
            pause(): this;
            dispose(): this;
    }
}

declare module 'tone/component/channel/Solo' {
    import { Gain } from "tone/core/context/Gain";
    import { ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    export interface SoloOptions extends ToneAudioNodeOptions {
            solo: boolean;
    }
    /**
        * Solo lets you isolate a specific audio stream. When an instance is set to `solo=true`,
        * it will mute all other instances of Solo.
        * @example
        * const soloA = new Tone.Solo().toDestination();
        * const oscA = new Tone.Oscillator("C4", "sawtooth").connect(soloA);
        * const soloB = new Tone.Solo().toDestination();
        * const oscB = new Tone.Oscillator("E4", "square").connect(soloB);
        * soloA.solo = true;
        * // no audio will pass through soloB
        * @category Component
        */
    export class Solo extends ToneAudioNode<SoloOptions> {
            readonly name: string;
            readonly input: Gain;
            readonly output: Gain;
            /**
                * @param solo If the connection should be initially solo'ed.
                */
            constructor(solo?: boolean);
            constructor(options?: Partial<SoloOptions>);
            static getDefaults(): SoloOptions;
            /**
                * Isolates this instance and mutes all other instances of Solo.
                * Only one instance can be soloed at a time. A soloed
                * instance will report `solo=false` when another instance is soloed.
                */
            get solo(): boolean;
            set solo(solo: boolean);
            /**
                * If the current instance is muted, i.e. another instance is soloed
                */
            get muted(): boolean;
            dispose(): this;
    }
}

declare module 'tone/component/channel/Split' {
    import { ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    interface SplitOptions extends ToneAudioNodeOptions {
            channels: number;
    }
    /**
        * Split splits an incoming signal into the number of given channels.
        *
        * @example
        * const split = new Tone.Split();
        * // stereoSignal.connect(split);
        * @category Component
        */
    export class Split extends ToneAudioNode<SplitOptions> {
            readonly name: string;
            readonly input: ChannelSplitterNode;
            readonly output: ChannelSplitterNode;
            /**
                * @param channels The number of channels to merge.
                */
            constructor(channels?: number);
            constructor(options?: Partial<SplitOptions>);
            static getDefaults(): SplitOptions;
            dispose(): this;
    }
    export {};
}

declare module 'tone/component/dynamics/Compressor' {
    import { Param } from "tone/core/context/Param";
    import { ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { Decibels, Positive, Time } from "tone/core/type/Units";
    export interface CompressorOptions extends ToneAudioNodeOptions {
            attack: Time;
            knee: Decibels;
            ratio: Positive;
            release: Time;
            threshold: Decibels;
    }
    /**
        * Compressor is a thin wrapper around the Web Audio
        * [DynamicsCompressorNode](http://webaudio.github.io/web-audio-api/#the-dynamicscompressornode-interface).
        * Compression reduces the volume of loud sounds or amplifies quiet sounds
        * by narrowing or "compressing" an audio signal's dynamic range.
        * Read more on [Wikipedia](https://en.wikipedia.org/wiki/Dynamic_range_compression).
        * @example
        * const comp = new Tone.Compressor(-30, 3);
        * @category Component
        */
    export class Compressor extends ToneAudioNode<CompressorOptions> {
            readonly name: string;
            readonly input: DynamicsCompressorNode;
            readonly output: DynamicsCompressorNode;
            /**
                * The decibel value above which the compression will start taking effect.
                * @min -100
                * @max 0
                */
            readonly threshold: Param<"decibels">;
            /**
                * The amount of time (in seconds) to reduce the gain by 10dB.
                * @min 0
                * @max 1
                */
            readonly attack: Param<"time">;
            /**
                * The amount of time (in seconds) to increase the gain by 10dB.
                * @min 0
                * @max 1
                */
            readonly release: Param<"time">;
            /**
                * A decibel value representing the range above the threshold where the
                * curve smoothly transitions to the "ratio" portion.
                * @min 0
                * @max 40
                */
            readonly knee: Param<"decibels">;
            /**
                * The amount of dB change in input for a 1 dB change in output.
                * @min 1
                * @max 20
                */
            readonly ratio: Param<"positive">;
            /**
                * @param threshold The value above which the compression starts to be applied.
                * @param ratio The gain reduction ratio.
                */
            constructor(threshold?: Decibels, ratio?: Positive);
            constructor(options?: Partial<CompressorOptions>);
            static getDefaults(): CompressorOptions;
            /**
                * A read-only decibel value for metering purposes, representing the current amount of gain
                * reduction that the compressor is applying to the signal. If fed no signal the value will be 0 (no gain reduction).
                */
            get reduction(): Decibels;
            dispose(): this;
    }
}

declare module 'tone/component/dynamics/Gate' {
    import { ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { Decibels, Time } from "tone/core/type/Units";
    export interface GateOptions extends ToneAudioNodeOptions {
            threshold: Decibels;
            smoothing: Time;
    }
    /**
        * Gate only passes a signal through when the incoming
        * signal exceeds a specified threshold. It uses {@link Follower} to follow the ampltiude
        * of the incoming signal and compares it to the {@link threshold} value using {@link GreaterThan}.
        *
        * @example
        * const gate = new Tone.Gate(-30, 0.2).toDestination();
        * const mic = new Tone.UserMedia().connect(gate);
        * // the gate will only pass through the incoming
        * // signal when it's louder than -30db
        * @category Component
        */
    export class Gate extends ToneAudioNode<GateOptions> {
            readonly name: string;
            readonly input: ToneAudioNode;
            readonly output: ToneAudioNode;
            /**
                * @param threshold The threshold above which the gate will open.
                * @param smoothing The follower's smoothing time
                */
            constructor(threshold?: Decibels, smoothing?: Time);
            constructor(options?: Partial<GateOptions>);
            static getDefaults(): GateOptions;
            /**
                * The threshold of the gate in decibels
                */
            get threshold(): Decibels;
            set threshold(thresh: Decibels);
            /**
                * The attack/decay speed of the gate.
                * @see {@link Follower.smoothing}
                */
            get smoothing(): Time;
            set smoothing(smoothingTime: Time);
            dispose(): this;
    }
}

declare module 'tone/component/dynamics/Limiter' {
    import { InputNode, OutputNode, ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { Decibels } from "tone/core/type/Units";
    import { Param } from "tone/core/context/Param";
    export interface LimiterOptions extends ToneAudioNodeOptions {
            threshold: Decibels;
    }
    /**
        * Limiter will limit the loudness of an incoming signal.
        * Under the hood it's composed of a {@link Compressor} with a fast attack
        * and release and max compression ratio.
        *
        * @example
        * const limiter = new Tone.Limiter(-20).toDestination();
        * const oscillator = new Tone.Oscillator().connect(limiter);
        * oscillator.start();
        * @category Component
        */
    export class Limiter extends ToneAudioNode<LimiterOptions> {
            readonly name: string;
            readonly input: InputNode;
            readonly output: OutputNode;
            readonly threshold: Param<"decibels">;
            /**
                * @param threshold The threshold above which the gain reduction is applied.
                */
            constructor(threshold?: Decibels);
            constructor(options?: Partial<LimiterOptions>);
            static getDefaults(): LimiterOptions;
            /**
                * A read-only decibel value for metering purposes, representing the current amount of gain
                * reduction that the compressor is applying to the signal.
                */
            get reduction(): Decibels;
            dispose(): this;
    }
}

declare module 'tone/component/dynamics/MidSideCompressor' {
    import { InputNode, OutputNode, ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { Compressor, CompressorOptions } from "tone/component/dynamics/Compressor";
    import { RecursivePartial } from "tone/core/util/Interface";
    export interface MidSideCompressorOptions extends ToneAudioNodeOptions {
            mid: Omit<CompressorOptions, keyof ToneAudioNodeOptions>;
            side: Omit<CompressorOptions, keyof ToneAudioNodeOptions>;
    }
    /**
        * MidSideCompressor applies two different compressors to the {@link mid}
        * and {@link side} signal components of the input.
        * @see {@link MidSideSplit} and {@link MidSideMerge}.
        * @category Component
        */
    export class MidSideCompressor extends ToneAudioNode<MidSideCompressorOptions> {
            readonly name: string;
            readonly input: InputNode;
            readonly output: OutputNode;
            /**
                * The compression applied to the mid signal
                */
            readonly mid: Compressor;
            /**
                * The compression applied to the side signal
                */
            readonly side: Compressor;
            constructor(options?: RecursivePartial<MidSideCompressorOptions>);
            static getDefaults(): MidSideCompressorOptions;
            dispose(): this;
    }
}

declare module 'tone/component/dynamics/MultibandCompressor' {
    import { InputNode, ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { Compressor, CompressorOptions } from "tone/component/dynamics/Compressor";
    import { RecursivePartial } from "tone/core/util/Interface";
    import { Frequency } from "tone/core/type/Units";
    import { Signal } from "tone/signal/Signal";
    export interface MultibandCompressorOptions extends ToneAudioNodeOptions {
            mid: Omit<CompressorOptions, keyof ToneAudioNodeOptions>;
            low: Omit<CompressorOptions, keyof ToneAudioNodeOptions>;
            high: Omit<CompressorOptions, keyof ToneAudioNodeOptions>;
            lowFrequency: Frequency;
            highFrequency: Frequency;
    }
    /**
        * A compressor with separate controls over low/mid/high dynamics.
        * @see {@link Compressor} and {@link MultibandSplit}
        *
        * @example
        * const multiband = new Tone.MultibandCompressor({
        * 	lowFrequency: 200,
        * 	highFrequency: 1300,
        * 	low: {
        * 		threshold: -12
        * 	}
        * });
        * @category Component
        */
    export class MultibandCompressor extends ToneAudioNode<MultibandCompressorOptions> {
            readonly name: string;
            readonly input: InputNode;
            readonly output: ToneAudioNode;
            /**
                * low/mid crossover frequency.
                */
            readonly lowFrequency: Signal<"frequency">;
            /**
                * mid/high crossover frequency.
                */
            readonly highFrequency: Signal<"frequency">;
            /**
                * The compressor applied to the low frequencies
                */
            readonly low: Compressor;
            /**
                * The compressor applied to the mid frequencies
                */
            readonly mid: Compressor;
            /**
                * The compressor applied to the high frequencies
                */
            readonly high: Compressor;
            constructor(options?: RecursivePartial<MultibandCompressorOptions>);
            static getDefaults(): MultibandCompressorOptions;
            dispose(): this;
    }
}

declare module 'tone/component/envelope/AmplitudeEnvelope' {
    import { Gain } from "tone/core/context/Gain";
    import { NormalRange, Time } from "tone/core/type/Units";
    import { Envelope, EnvelopeOptions } from "tone/component/envelope/Envelope";
    /**
        * AmplitudeEnvelope is a Tone.Envelope connected to a gain node.
        * Unlike Tone.Envelope, which outputs the envelope's value, AmplitudeEnvelope accepts
        * an audio signal as the input and will apply the envelope to the amplitude
        * of the signal.
        * Read more about ADSR Envelopes on [Wikipedia](https://en.wikipedia.org/wiki/Synthesizer#ADSR_envelope).
        *
        * @example
        * return Tone.Offline(() => {
        * 	const ampEnv = new Tone.AmplitudeEnvelope({
        * 		attack: 0.1,
        * 		decay: 0.2,
        * 		sustain: 1.0,
        * 		release: 0.8
        * 	}).toDestination();
        * 	// create an oscillator and connect it
        * 	const osc = new Tone.Oscillator().connect(ampEnv).start();
        * 	// trigger the envelopes attack and release "8t" apart
        * 	ampEnv.triggerAttackRelease("8t");
        * }, 1.5, 1);
        * @category Component
        */
    export class AmplitudeEnvelope extends Envelope {
            readonly name: string;
            output: Gain;
            input: Gain;
            /**
                * @param attack The amount of time it takes for the envelope to go from 0 to it's maximum value.
                * @param decay	The period of time after the attack that it takes for the envelope
                *                      	to fall to the sustain value. Value must be greater than 0.
                * @param sustain	The percent of the maximum value that the envelope rests at until
                *                               	the release is triggered.
                * @param release	The amount of time after the release is triggered it takes to reach 0.
                *                        	Value must be greater than 0.
                */
            constructor(attack?: Time, decay?: Time, sustain?: NormalRange, release?: Time);
            constructor(options?: Partial<EnvelopeOptions>);
            /**
                * Clean up
                */
            dispose(): this;
    }
}

declare module 'tone/component/envelope/Envelope' {
    import { InputNode, OutputNode } from "tone/core/context/ToneAudioNode";
    import { ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { NormalRange, Time } from "tone/core/type/Units";
    import { Signal } from "tone/signal/Signal";
    type BasicEnvelopeCurve = "linear" | "exponential";
    export type EnvelopeCurve = EnvelopeCurveName | number[];
    export interface EnvelopeOptions extends ToneAudioNodeOptions {
            attack: Time;
            decay: Time;
            sustain: NormalRange;
            release: Time;
            attackCurve: EnvelopeCurve;
            releaseCurve: EnvelopeCurve;
            decayCurve: BasicEnvelopeCurve;
    }
    /**
        * Envelope is an [ADSR](https://en.wikipedia.org/wiki/Synthesizer#ADSR_envelope)
        * envelope generator. Envelope outputs a signal which
        * can be connected to an AudioParam or Tone.Signal.
        * ```
        *           /\
        *          /  \
        *         /    \
        *        /      \
        *       /        \___________
        *      /                     \
        *     /                       \
        *    /                         \
        *   /                           \
        * ```
        * @example
        * return Tone.Offline(() => {
        * 	const env = new Tone.Envelope({
        * 		attack: 0.1,
        * 		decay: 0.2,
        * 		sustain: 0.5,
        * 		release: 0.8,
        * 	}).toDestination();
        * 	env.triggerAttackRelease(0.5);
        * }, 1.5, 1);
        * @category Component
        */
    export class Envelope extends ToneAudioNode<EnvelopeOptions> {
            readonly name: string;
            /**
                * When triggerAttack is called, the attack time is the amount of
                * time it takes for the envelope to reach it's maximum value.
                * ```
                *           /\
                *          /X \
                *         /XX  \
                *        /XXX   \
                *       /XXXX    \___________
                *      /XXXXX                \
                *     /XXXXXX                 \
                *    /XXXXXXX                  \
                *   /XXXXXXXX                   \
                * ```
                * @min 0
                * @max 2
                */
            attack: Time;
            /**
                * After the attack portion of the envelope, the value will fall
                * over the duration of the decay time to it's sustain value.
                * ```
                *           /\
                *          / X\
                *         /  XX\
                *        /   XXX\
                *       /    XXXX\___________
                *      /     XXXXX           \
                *     /      XXXXX            \
                *    /       XXXXX             \
                *   /        XXXXX              \
                * ```
                * @min 0
                * @max 2
                */
            decay: Time;
            /**
                * The sustain value is the value
                * which the envelope rests at after triggerAttack is
                * called, but before triggerRelease is invoked.
                * ```
                *           /\
                *          /  \
                *         /    \
                *        /      \
                *       /        \___________
                *      /          XXXXXXXXXXX\
                *     /           XXXXXXXXXXX \
                *    /            XXXXXXXXXXX  \
                *   /             XXXXXXXXXXX   \
                * ```
                */
            sustain: NormalRange;
            /**
                * After triggerRelease is called, the envelope's
                * value will fall to it's miminum value over the
                * duration of the release time.
                * ```
                *           /\
                *          /  \
                *         /    \
                *        /      \
                *       /        \___________
                *      /                    X\
                *     /                     XX\
                *    /                      XXX\
                *   /                       XXXX\
                * ```
                * @min 0
                * @max 5
                */
            release: Time;
            /**
                * the signal which is output.
                */
            protected _sig: Signal<"normalRange">;
            /**
                * The output signal of the envelope
                */
            output: OutputNode;
            /**
                * Envelope has no input
                */
            input: InputNode | undefined;
            /**
                * @param attack The amount of time it takes for the envelope to go from
                *                        0 to it's maximum value.
                * @param decay	The period of time after the attack that it takes for the envelope
                *                      	to fall to the sustain value. Value must be greater than 0.
                * @param sustain	The percent of the maximum value that the envelope rests at until
                *                               	the release is triggered.
                * @param release	The amount of time after the release is triggered it takes to reach 0.
                *                        	Value must be greater than 0.
                */
            constructor(attack?: Time, decay?: Time, sustain?: NormalRange, release?: Time);
            constructor(options?: Partial<EnvelopeOptions>);
            static getDefaults(): EnvelopeOptions;
            /**
                * Read the current value of the envelope. Useful for
                * synchronizing visual output to the envelope.
                */
            get value(): NormalRange;
            /**
                * The shape of the attack.
                * Can be any of these strings:
                * * "linear"
                * * "exponential"
                * * "sine"
                * * "cosine"
                * * "bounce"
                * * "ripple"
                * * "step"
                *
                * Can also be an array which describes the curve. Values
                * in the array are evenly subdivided and linearly
                * interpolated over the duration of the attack.
                * @example
                * return Tone.Offline(() => {
                * 	const env = new Tone.Envelope(0.4).toDestination();
                * 	env.attackCurve = "linear";
                * 	env.triggerAttack();
                * }, 1, 1);
                */
            get attackCurve(): EnvelopeCurve;
            set attackCurve(curve: EnvelopeCurve);
            /**
                * The shape of the release. See the attack curve types.
                * @example
                * return Tone.Offline(() => {
                * 	const env = new Tone.Envelope({
                * 		release: 0.8
                * 	}).toDestination();
                * 	env.triggerAttack();
                * 	// release curve could also be defined by an array
                * 	env.releaseCurve = [1, 0.3, 0.4, 0.2, 0.7, 0];
                * 	env.triggerRelease(0.2);
                * }, 1, 1);
                */
            get releaseCurve(): EnvelopeCurve;
            set releaseCurve(curve: EnvelopeCurve);
            /**
                * The shape of the decay either "linear" or "exponential"
                * @example
                * return Tone.Offline(() => {
                * 	const env = new Tone.Envelope({
                * 		sustain: 0.1,
                * 		decay: 0.5
                * 	}).toDestination();
                * 	env.decayCurve = "linear";
                * 	env.triggerAttack();
                * }, 1, 1);
                */
            get decayCurve(): EnvelopeCurve;
            set decayCurve(curve: EnvelopeCurve);
            /**
                * Trigger the attack/decay portion of the ADSR envelope.
                * @param  time When the attack should start.
                * @param velocity The velocity of the envelope scales the vales.
                *                             number between 0-1
                * @example
                * const env = new Tone.AmplitudeEnvelope().toDestination();
                * const osc = new Tone.Oscillator().connect(env).start();
                * // trigger the attack 0.5 seconds from now with a velocity of 0.2
                * env.triggerAttack("+0.5", 0.2);
                */
            triggerAttack(time?: Time, velocity?: NormalRange): this;
            /**
                * Triggers the release of the envelope.
                * @param  time When the release portion of the envelope should start.
                * @example
                * const env = new Tone.AmplitudeEnvelope().toDestination();
                * const osc = new Tone.Oscillator({
                * 	type: "sawtooth"
                * }).connect(env).start();
                * env.triggerAttack();
                * // trigger the release half a second after the attack
                * env.triggerRelease("+0.5");
                */
            triggerRelease(time?: Time): this;
            /**
                * Get the scheduled value at the given time. This will
                * return the unconverted (raw) value.
                * @example
                * const env = new Tone.Envelope(0.5, 1, 0.4, 2);
                * env.triggerAttackRelease(2);
                * setInterval(() => console.log(env.getValueAtTime(Tone.now())), 100);
                */
            getValueAtTime(time: Time): NormalRange;
            /**
                * triggerAttackRelease is shorthand for triggerAttack, then waiting
                * some duration, then triggerRelease.
                * @param duration The duration of the sustain.
                * @param time When the attack should be triggered.
                * @param velocity The velocity of the envelope.
                * @example
                * const env = new Tone.AmplitudeEnvelope().toDestination();
                * const osc = new Tone.Oscillator().connect(env).start();
                * // trigger the release 0.5 seconds after the attack
                * env.triggerAttackRelease(0.5);
                */
            triggerAttackRelease(duration: Time, time?: Time, velocity?: NormalRange): this;
            /**
                * Cancels all scheduled envelope changes after the given time.
                */
            cancel(after?: Time): this;
            /**
                * Connect the envelope to a destination node.
                */
            connect(destination: InputNode, outputNumber?: number, inputNumber?: number): this;
            /**
                * Render the envelope curve to an array of the given length.
                * Good for visualizing the envelope curve. Rescales the duration of the
                * envelope to fit the length.
                */
            asArray(length?: number): Promise<Float32Array>;
            dispose(): this;
    }
    interface EnvelopeCurveObject {
            In: number[];
            Out: number[];
    }
    interface EnvelopeCurveMap {
            linear: "linear";
            exponential: "exponential";
            bounce: EnvelopeCurveObject;
            cosine: EnvelopeCurveObject;
            sine: EnvelopeCurveObject;
            ripple: EnvelopeCurveObject;
            step: EnvelopeCurveObject;
    }
    type EnvelopeCurveName = keyof EnvelopeCurveMap;
    export {};
}

declare module 'tone/component/envelope/FrequencyEnvelope' {
    import { Frequency, NormalRange, Time } from "tone/core/type/Units";
    import { Envelope, EnvelopeOptions } from "tone/component/envelope/Envelope";
    export interface FrequencyEnvelopeOptions extends EnvelopeOptions {
            baseFrequency: Frequency;
            octaves: number;
            exponent: number;
    }
    /**
        * FrequencyEnvelope is an {@link Envelope} which ramps between {@link baseFrequency}
        * and {@link octaves}. It can also have an optional {@link exponent} to adjust the curve
        * which it ramps.
        * @example
        * const oscillator = new Tone.Oscillator().toDestination().start();
        * const freqEnv = new Tone.FrequencyEnvelope({
        * 	attack: 0.2,
        * 	baseFrequency: "C2",
        * 	octaves: 4
        * });
        * freqEnv.connect(oscillator.frequency);
        * freqEnv.triggerAttack();
        * @category Component
        */
    export class FrequencyEnvelope extends Envelope {
            readonly name: string;
            /**
                * @param attack	the attack time in seconds
                * @param decay		the decay time in seconds
                * @param sustain 	a percentage (0-1) of the full amplitude
                * @param release	the release time in seconds
                */
            constructor(attack?: Time, decay?: Time, sustain?: NormalRange, release?: Time);
            constructor(options?: Partial<FrequencyEnvelopeOptions>);
            static getDefaults(): FrequencyEnvelopeOptions;
            /**
                * The envelope's minimum output value. This is the value which it
                * starts at.
                */
            get baseFrequency(): Frequency;
            set baseFrequency(min: Frequency);
            /**
                * The number of octaves above the baseFrequency that the
                * envelope will scale to.
                */
            get octaves(): number;
            set octaves(octaves: number);
            /**
                * The envelope's exponent value.
                */
            get exponent(): number;
            set exponent(exponent: number);
            /**
                * Clean up
                */
            dispose(): this;
    }
}

declare module 'tone/component/filter/EQ3' {
    import { Gain } from "tone/core/context/Gain";
    import { Param } from "tone/core/context/Param";
    import { ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { Decibels, Frequency } from "tone/core/type/Units";
    import { Signal } from "tone/signal/Signal";
    import { MultibandSplit } from "tone/component/channel/MultibandSplit";
    interface EQ3Options extends ToneAudioNodeOptions {
            low: Decibels;
            mid: Decibels;
            high: Decibels;
            lowFrequency: Frequency;
            highFrequency: Frequency;
    }
    /**
        * EQ3 provides 3 equalizer bins: Low/Mid/High.
        * @category Component
        */
    export class EQ3 extends ToneAudioNode<EQ3Options> {
            readonly name: string;
            /**
                * the input
                */
            readonly input: MultibandSplit;
            /**
                * the output
                */
            readonly output: Gain<"gain">;
            /**
                * The gain in decibels of the low part
                */
            readonly low: Param<"decibels">;
            /**
                * The gain in decibels of the mid part
                */
            readonly mid: Param<"decibels">;
            /**
                * The gain in decibels of the high part
                */
            readonly high: Param<"decibels">;
            /**
                * The Q value for all of the filters.
                */
            readonly Q: Signal<"positive">;
            /**
                * The low/mid crossover frequency.
                */
            readonly lowFrequency: Signal<"frequency">;
            /**
                * The mid/high crossover frequency.
                */
            readonly highFrequency: Signal<"frequency">;
            protected _internalChannels: ToneAudioNode[];
            constructor(lowLevel?: Decibels, midLevel?: Decibels, highLevel?: Decibels);
            constructor(options: Partial<EQ3Options>);
            static getDefaults(): EQ3Options;
            /**
                * Clean up.
                */
            dispose(): this;
    }
    export {};
}

declare module 'tone/component/filter/Filter' {
    import { Gain } from "tone/core/context/Gain";
    import { ToneAudioNode } from "tone/core/context/ToneAudioNode";
    import { Frequency } from "tone/core/type/Units";
    import { Signal } from "tone/signal/Signal";
    import { BiquadFilterOptions } from "tone/component/filter/BiquadFilter";
    export type FilterRollOff = -12 | -24 | -48 | -96;
    export type FilterOptions = BiquadFilterOptions & {
            rolloff: FilterRollOff;
    };
    /**
        * Tone.Filter is a filter which allows for all of the same native methods
        * as the [BiquadFilterNode](http://webaudio.github.io/web-audio-api/#the-biquadfilternode-interface).
        * Tone.Filter has the added ability to set the filter rolloff at -12
        * (default), -24 and -48.
        * @example
        * const filter = new Tone.Filter(1500, "highpass").toDestination();
        * filter.frequency.rampTo(20000, 10);
        * const noise = new Tone.Noise().connect(filter).start();
        * @category Component
        */
    export class Filter extends ToneAudioNode<FilterOptions> {
            readonly name: string;
            readonly input: Gain<"gain">;
            readonly output: Gain<"gain">;
            /**
                * The Q or Quality of the filter
                */
            readonly Q: Signal<"positive">;
            /**
                * The cutoff frequency of the filter.
                */
            readonly frequency: Signal<"frequency">;
            /**
                * The detune parameter
                */
            readonly detune: Signal<"cents">;
            /**
                * The gain of the filter, only used in certain filter types
                */
            readonly gain: Signal<"decibels">;
            /**
                * @param frequency The cutoff frequency of the filter.
                * @param type The type of filter.
                * @param rolloff The drop in decibels per octave after the cutoff frequency
                */
            constructor(frequency?: Frequency, type?: BiquadFilterType, rolloff?: FilterRollOff);
            constructor(options?: Partial<FilterOptions>);
            static getDefaults(): FilterOptions;
            /**
                * The type of the filter. Types: "lowpass", "highpass",
                * "bandpass", "lowshelf", "highshelf", "notch", "allpass", or "peaking".
                */
            get type(): BiquadFilterType;
            set type(type: BiquadFilterType);
            /**
                * The rolloff of the filter which is the drop in db
                * per octave. Implemented internally by cascading filters.
                * Only accepts the values -12, -24, -48 and -96.
                */
            get rolloff(): FilterRollOff;
            set rolloff(rolloff: FilterRollOff);
            /**
                * Get the frequency response curve. This curve represents how the filter
                * responses to frequencies between 20hz-20khz.
                * @param  len The number of values to return
                * @return The frequency response curve between 20-20kHz
                */
            getFrequencyResponse(len?: number): Float32Array;
            /**
                * Clean up.
                */
            dispose(): this;
    }
}

declare module 'tone/component/filter/OnePoleFilter' {
    import { ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { Frequency } from "tone/core/type/Units";
    import { Gain } from "tone/core/context/Gain";
    export type OnePoleFilterType = "highpass" | "lowpass";
    export interface OnePoleFilterOptions extends ToneAudioNodeOptions {
            frequency: Frequency;
            type: OnePoleFilterType;
    }
    /**
        * A one pole filter with 6db-per-octave rolloff. Either "highpass" or "lowpass".
        * Note that changing the type or frequency may result in a discontinuity which
        * can sound like a click or pop.
        * References:
        * * http://www.earlevel.com/main/2012/12/15/a-one-pole-filter/
        * * http://www.dspguide.com/ch19/2.htm
        * * https://github.com/vitaliy-bobrov/js-rocks/blob/master/src/app/audio/effects/one-pole-filters.ts
        * @category Component
        */
    export class OnePoleFilter extends ToneAudioNode<OnePoleFilterOptions> {
            readonly name: string;
            readonly input: Gain;
            readonly output: Gain;
            /**
                * @param frequency The frequency
                * @param type The  filter type, either "lowpass" or "highpass"
                */
            constructor(frequency?: Frequency, type?: OnePoleFilterType);
            constructor(options?: Partial<OnePoleFilterOptions>);
            static getDefaults(): OnePoleFilterOptions;
            /**
                * The frequency value.
                */
            get frequency(): Frequency;
            set frequency(fq: Frequency);
            /**
                * The OnePole Filter type, either "highpass" or "lowpass"
                */
            get type(): OnePoleFilterType;
            set type(t: OnePoleFilterType);
            /**
                * Get the frequency response curve. This curve represents how the filter
                * responses to frequencies between 20hz-20khz.
                * @param  len The number of values to return
                * @return The frequency response curve between 20-20kHz
                */
            getFrequencyResponse(len?: number): Float32Array;
            dispose(): this;
    }
}

declare module 'tone/component/filter/FeedbackCombFilter' {
    import { Gain } from "tone/core/context/Gain";
    import { Param } from "tone/core/context/Param";
    import { ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { NormalRange, Time } from "tone/core/type/Units";
    import { RecursivePartial } from "tone/core/util/Interface";
    import { ToneAudioWorklet } from "tone/core/worklet/ToneAudioWorklet";
    export interface FeedbackCombFilterOptions extends ToneAudioNodeOptions {
            delayTime: Time;
            resonance: NormalRange;
    }
    /**
        * Comb filters are basic building blocks for physical modeling. Read more
        * about comb filters on [CCRMA's website](https://ccrma.stanford.edu/~jos/pasp/Feedback_Comb_Filters.html).
        *
        * This comb filter is implemented with the AudioWorkletNode which allows it to have feedback delays less than the
        * Web Audio processing block of 128 samples. There is a polyfill for browsers that don't yet support the
        * AudioWorkletNode, but it will add some latency and have slower performance than the AudioWorkletNode.
        * @category Component
        */
    export class FeedbackCombFilter extends ToneAudioWorklet<FeedbackCombFilterOptions> {
            readonly name = "FeedbackCombFilter";
            /**
                * The amount of delay of the comb filter.
                */
            readonly delayTime: Param<"time">;
            /**
                * The amount of feedback of the delayed signal.
                */
            readonly resonance: Param<"normalRange">;
            readonly input: Gain;
            readonly output: Gain;
            /**
                * @param delayTime The delay time of the filter.
                * @param resonance The amount of feedback the filter has.
                */
            constructor(delayTime?: Time, resonance?: NormalRange);
            constructor(options?: RecursivePartial<FeedbackCombFilterOptions>);
            protected _audioWorkletName(): string;
            /**
                * The default parameters
                */
            static getDefaults(): FeedbackCombFilterOptions;
            onReady(node: AudioWorkletNode): void;
            dispose(): this;
    }
}

declare module 'tone/component/filter/LowpassCombFilter' {
    import { Param } from "tone/core/context/Param";
    import { InputNode, OutputNode, ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { Frequency, NormalRange, Time } from "tone/core/type/Units";
    import { RecursivePartial } from "tone/core/util/Interface";
    interface LowpassCombFilterOptions extends ToneAudioNodeOptions {
            delayTime: Time;
            resonance: NormalRange;
            dampening: Frequency;
    }
    /**
        * A lowpass feedback comb filter. It is similar to
        * {@link FeedbackCombFilter}, but includes a lowpass filter.
        * @category Component
        */
    export class LowpassCombFilter extends ToneAudioNode<LowpassCombFilterOptions> {
            readonly name = "LowpassCombFilter";
            /**
                * The delayTime of the comb filter.
                */
            readonly delayTime: Param<"time">;
            /**
                * The amount of feedback of the delayed signal.
                */
            readonly resonance: Param<"normalRange">;
            readonly input: InputNode;
            readonly output: OutputNode;
            /**
                * @param delayTime The delay time of the comb filter
                * @param resonance The resonance (feedback) of the comb filter
                * @param dampening The cutoff of the lowpass filter dampens the signal as it is fedback.
                */
            constructor(delayTime?: Time, resonance?: NormalRange, dampening?: Frequency);
            constructor(options?: RecursivePartial<LowpassCombFilterOptions>);
            static getDefaults(): LowpassCombFilterOptions;
            /**
                * The dampening control of the feedback
                */
            get dampening(): Frequency;
            set dampening(fq: Frequency);
            dispose(): this;
    }
    export {};
}

declare module 'tone/component/filter/Convolver' {
    import { ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { ToneAudioBuffer } from "tone/core/context/ToneAudioBuffer";
    import { Gain } from "tone/core/context/Gain";
    export interface ConvolverOptions extends ToneAudioNodeOptions {
            onload: () => void;
            normalize: boolean;
            url?: string | AudioBuffer | ToneAudioBuffer;
    }
    /**
        * Convolver is a wrapper around the Native Web Audio
        * [ConvolverNode](http://webaudio.github.io/web-audio-api/#the-convolvernode-interface).
        * Convolution is useful for reverb and filter emulation. Read more about convolution reverb on
        * [Wikipedia](https://en.wikipedia.org/wiki/Convolution_reverb).
        *
        * @example
        * // initializing the convolver with an impulse response
        * const convolver = new Tone.Convolver("./path/to/ir.wav").toDestination();
        * @category Component
        */
    export class Convolver extends ToneAudioNode<ConvolverOptions> {
            readonly name: string;
            readonly input: Gain;
            readonly output: Gain;
            /**
                * @param url The URL of the impulse response or the ToneAudioBuffer containing the impulse response.
                * @param onload The callback to invoke when the url is loaded.
                */
            constructor(url?: string | AudioBuffer | ToneAudioBuffer, onload?: () => void);
            constructor(options?: Partial<ConvolverOptions>);
            static getDefaults(): ConvolverOptions;
            /**
                * Load an impulse response url as an audio buffer.
                * Decodes the audio asynchronously and invokes
                * the callback once the audio buffer loads.
                * @param url The url of the buffer to load. filetype support depends on the browser.
                */
            load(url: string): Promise<void>;
            /**
                * The convolver's buffer
                */
            get buffer(): ToneAudioBuffer | null;
            set buffer(buffer: ToneAudioBuffer | null);
            /**
                * The normalize property of the ConvolverNode interface is a boolean that
                * controls whether the impulse response from the buffer will be scaled by
                * an equal-power normalization when the buffer attribute is set, or not.
                */
            get normalize(): boolean;
            set normalize(norm: boolean);
            dispose(): this;
    }
}

declare module 'tone/component/filter/BiquadFilter' {
    import { ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { Cents, Frequency, GainFactor } from "tone/core/type/Units";
    import { Param } from "tone/core/context/Param";
    export interface BiquadFilterOptions extends ToneAudioNodeOptions {
            frequency: Frequency;
            detune: Cents;
            Q: number;
            type: BiquadFilterType;
            gain: GainFactor;
    }
    /**
        * Thin wrapper around the native Web Audio [BiquadFilterNode](https://webaudio.github.io/web-audio-api/#biquadfilternode).
        * BiquadFilter is similar to {@link Filter} but doesn't have the option to set the "rolloff" value.
        * @category Component
        */
    export class BiquadFilter extends ToneAudioNode<BiquadFilterOptions> {
            readonly name: string;
            readonly input: BiquadFilterNode;
            readonly output: BiquadFilterNode;
            /**
                * The frequency of the filter
                */
            readonly frequency: Param<"frequency">;
            /**
                * A detune value, in cents, for the frequency.
                */
            readonly detune: Param<"cents">;
            /**
                * The Q factor of the filter.
                * For lowpass and highpass filters the Q value is interpreted to be in dB.
                * For these filters the nominal range is [−𝑄𝑙𝑖𝑚,𝑄𝑙𝑖𝑚] where 𝑄𝑙𝑖𝑚 is the largest value for which 10𝑄/20 does not overflow. This is approximately 770.63678.
                * For the bandpass, notch, allpass, and peaking filters, this value is a linear value.
                * The value is related to the bandwidth of the filter and hence should be a positive value. The nominal range is
                * [0,3.4028235𝑒38], the upper limit being the most-positive-single-float.
                * This is not used for the lowshelf and highshelf filters.
                */
            readonly Q: Param<"number">;
            /**
                * The gain of the filter. Its value is in dB units. The gain is only used for lowshelf, highshelf, and peaking filters.
                */
            readonly gain: Param<"decibels">;
            /**
                * @param frequency The cutoff frequency of the filter.
                * @param type The type of filter.
                */
            constructor(frequency?: Frequency, type?: BiquadFilterType);
            constructor(options?: Partial<BiquadFilterOptions>);
            static getDefaults(): BiquadFilterOptions;
            /**
                * The type of this BiquadFilterNode. For a complete list of types and their attributes, see the
                * [Web Audio API](https://webaudio.github.io/web-audio-api/#dom-biquadfiltertype-lowpass)
                */
            get type(): BiquadFilterType;
            set type(type: BiquadFilterType);
            /**
                * Get the frequency response curve. This curve represents how the filter
                * responses to frequencies between 20hz-20khz.
                * @param  len The number of values to return
                * @return The frequency response curve between 20-20kHz
                */
            getFrequencyResponse(len?: number): Float32Array;
            dispose(): this;
    }
}

declare module 'tone/core/type/TimeBase' {
    import { BaseContext } from "tone/core/context/BaseContext";
    import { Tone } from "tone/core/Tone";
    import { BPM, Hertz, MidiNote, Milliseconds, Samples, Seconds, Ticks, Time } from "tone/core/type/Units";
    export type TimeValue = Time | TimeBaseClass<any, any>;
    /**
        * The units that the TimeBase can accept. extended by other classes
        */
    export type TimeBaseUnit = "s" | "n" | "t" | "m" | "i" | "hz" | "tr" | "samples" | "number";
    export interface TypeFunction {
            regexp: RegExp;
            method: (value: string, ...args: string[]) => number;
    }
    export interface TimeExpression<Type extends number> {
            [key: string]: {
                    regexp: RegExp;
                    method: (value: string, ...args: string[]) => Type;
            };
    }
    /**
        * TimeBase is a flexible encoding of time which can be evaluated to and from a string.
        */
    export abstract class TimeBaseClass<Type extends number, Unit extends string> extends Tone {
            readonly context: BaseContext;
            /**
                * The value of the units
                */
            protected _val?: TimeValue;
            /**
                * The units of time
                */
            protected _units?: Unit;
            /**
                * All of the conversion expressions
                */
            protected _expressions: TimeExpression<Type>;
            /**
                * The default units
                */
            readonly defaultUnits: Unit;
            /**
                * @param context The context associated with the time value. Used to compute
                * Transport and context-relative timing.
                * @param  value  The time value as a number, string or object
                * @param  units  Unit values
                */
            constructor(context: BaseContext, value?: TimeValue, units?: Unit);
            /**
                * All of the time encoding expressions
                */
            protected _getExpressions(): TimeExpression<Type>;
            /**
                * Evaluate the time value. Returns the time in seconds.
                */
            valueOf(): Type;
            /**
                * Returns the value of a frequency in the current units
                */
            protected _frequencyToUnits(freq: Hertz): Type;
            /**
                * Return the value of the beats in the current units
                */
            protected _beatsToUnits(beats: number): Type;
            /**
                * Returns the value of a second in the current units
                */
            protected _secondsToUnits(seconds: Seconds): Type;
            /**
                * Returns the value of a tick in the current time units
                */
            protected _ticksToUnits(ticks: Ticks): Type;
            /**
                * With no arguments, return 'now'
                */
            protected _noArg(): Type;
            /**
                * Return the bpm
                */
            protected _getBpm(): BPM;
            /**
                * Return the timeSignature
                */
            protected _getTimeSignature(): number;
            /**
                * Return the PPQ or 192 if Transport is not available
                */
            protected _getPPQ(): number;
            /**
                * Return the current time in whichever context is relevant
                */
            protected abstract _now(): Type;
            /**
                * Coerce a time type into this units type.
                * @param type Any time type units
                */
            fromType(type: TimeBaseClass<any, any>): this;
            /**
                * Return the value in seconds
                */
            abstract toSeconds(): Seconds;
            /**
                * Return the value as a Midi note
                */
            abstract toMidi(): MidiNote;
            /**
                * Convert the value into ticks
                */
            abstract toTicks(): Ticks;
            /**
                * Return the value in hertz
                */
            toFrequency(): Hertz;
            /**
                * Return the time in samples
                */
            toSamples(): Samples;
            /**
                * Return the time in milliseconds.
                */
            toMilliseconds(): Milliseconds;
    }
}

declare module 'tone/core/context/AbstractParam' {
    import { Time, UnitMap, UnitName } from "tone/core/type/Units";
    /**
        * Abstract base class for {@link Param} and {@link Signal}
        */
    export abstract class AbstractParam<TypeName extends UnitName> {
            /**
                * Schedules a parameter value change at the given time.
                * @param value The value to set the signal.
                * @param time The time when the change should occur.
                * @example
                * return Tone.Offline(() => {
                * 	const osc = new Tone.Oscillator(20).toDestination().start();
                * 	// set the frequency to 40 at exactly 0.25 seconds
                * 	osc.frequency.setValueAtTime(40, 0.25);
                * }, 0.5, 1);
                */
            abstract setValueAtTime(value: UnitMap[TypeName], time: Time): this;
            /**
                * Get the signals value at the given time. Subsequent scheduling
                * may invalidate the returned value.
                * @param time When to get the value
                * @example
                * const signal = new Tone.Signal().toDestination();
                * // ramp up to '8' over 3 seconds
                * signal.rampTo(8, 3);
                * // ramp back down to '0' over 3 seconds
                * signal.rampTo(0, 3, "+3");
                * setInterval(() => {
                * 	// check the value every 100 ms
                * 	console.log(signal.getValueAtTime(Tone.now()));
                * }, 100);
                */
            abstract getValueAtTime(time: Time): UnitMap[TypeName];
            /**
                * Creates a schedule point with the current value at the current time.
                * Automation methods like {@link linearRampToValueAtTime} and {@link exponentialRampToValueAtTime}
                * require a starting automation value usually set by {@link setValueAtTime}. This method
                * is useful since it will do a `setValueAtTime` with whatever the currently computed
                * value at the given time is.
                * @param time When to add a ramp point.
                * @example
                * const osc = new Tone.Oscillator().toDestination().start();
                * // set the frequency to "G4" in exactly 1 second from now.
                * osc.frequency.setRampPoint("+1");
                * osc.frequency.linearRampToValueAtTime("C1", "+2");
                */
            abstract setRampPoint(time: Time): this;
            /**
                * Schedules a linear continuous change in parameter value from the
                * previous scheduled parameter value to the given value.
                * @example
                * return Tone.Offline(() => {
                * 	const signal = new Tone.Signal(0).toDestination();
                * 	// the ramp starts from the previously scheduled value
                * 	signal.setValueAtTime(0, 0.1);
                * 	signal.linearRampToValueAtTime(1, 0.4);
                * }, 0.5, 1);
                */
            abstract linearRampToValueAtTime(value: UnitMap[TypeName], time: Time): this;
            /**
                * Schedules an exponential continuous change in parameter value from
                * the previous scheduled parameter value to the given value.
                * @example
                * return Tone.Offline(() => {
                * 	const signal = new Tone.Signal(1).toDestination();
                * 	// the ramp starts from the previously scheduled value, which must be positive
                * 	signal.setValueAtTime(1, 0.1);
                * 	signal.exponentialRampToValueAtTime(0, 0.4);
                * }, 0.5, 1);
                */
            abstract exponentialRampToValueAtTime(value: UnitMap[TypeName], time: Time): this;
            /**
                * Schedules an exponential continuous change in parameter value from
                * the current time and current value to the given value over the
                * duration of the rampTime.
                * @param value   The value to ramp to.
                * @param rampTime the time that it takes the
                *                             value to ramp from it's current value
                * @param startTime When the ramp should start.
                * @example
                * const delay = new Tone.FeedbackDelay(0.5, 0.98).toDestination();
                * // a short burst of noise through the feedback delay
                * const noise = new Tone.Noise().connect(delay).start().stop("+0.1");
                * // making the delay time shorter over time will also make the pitch rise
                * delay.delayTime.exponentialRampTo(0.01, 20);
                * @example
                * return Tone.Offline(() => {
                * 	const signal = new Tone.Signal(.1).toDestination();
                * 	signal.exponentialRampTo(5, 0.3, 0.1);
                * }, 0.5, 1);
                */
            abstract exponentialRampTo(value: UnitMap[TypeName], rampTime: Time, startTime?: Time): this;
            /**
                * Schedules an linear continuous change in parameter value from
                * the current time and current value to the given value over the
                * duration of the rampTime.
                *
                * @param  value   The value to ramp to.
                * @param  rampTime the time that it takes the
                *                              value to ramp from it's current value
                * @param startTime 	When the ramp should start.
                * @returns {Param} this
                * @example
                * const delay = new Tone.FeedbackDelay(0.5, 0.98).toDestination();
                * // a short burst of noise through the feedback delay
                * const noise = new Tone.Noise().connect(delay).start().stop("+0.1");
                * // making the delay time shorter over time will also make the pitch rise
                * delay.delayTime.linearRampTo(0.01, 20);
                * @example
                * return Tone.Offline(() => {
                * 	const signal = new Tone.Signal(1).toDestination();
                * 	signal.linearRampTo(0, 0.3, 0.1);
                * }, 0.5, 1);
                */
            abstract linearRampTo(value: UnitMap[TypeName], rampTime: Time, startTime?: Time): this;
            /**
                * Start exponentially approaching the target value at the given time. Since it
                * is an exponential approach it will continue approaching after the ramp duration. The
                * rampTime is the time that it takes to reach over 99% of the way towards the value.
                * @param  value   The value to ramp to.
                * @param  rampTime the time that it takes the
                *                              value to ramp from it's current value
                * @param startTime 	When the ramp should start.
                * @example
                * @example
                * return Tone.Offline(() => {
                * 	const signal = new Tone.Signal(1).toDestination();
                * 	signal.targetRampTo(0, 0.3, 0.1);
                * }, 0.5, 1);
                */
            abstract targetRampTo(value: UnitMap[TypeName], rampTime: Time, startTime?: Time): this;
            /**
                * Start exponentially approaching the target value at the given time. Since it
                * is an exponential approach it will continue approaching after the ramp duration. The
                * rampTime is the time that it takes to reach over 99% of the way towards the value. This methods
                * is similar to setTargetAtTime except the third argument is a time instead of a 'timeConstant'
                * @param  value   The value to ramp to.
                * @param time 	When the ramp should start.
                * @param  rampTime the time that it takes the value to ramp from it's current value
                * @example
                * const osc = new Tone.Oscillator().toDestination().start();
                * // exponential approach over 4 seconds starting in 1 second
                * osc.frequency.exponentialApproachValueAtTime("C4", "+1", 4);
                */
            abstract exponentialApproachValueAtTime(value: UnitMap[TypeName], time: Time, rampTime: Time): this;
            /**
                * Start exponentially approaching the target value at the given time with
                * a rate having the given time constant.
                * @param value
                * @param startTime
                * @param timeConstant
                */
            abstract setTargetAtTime(value: UnitMap[TypeName], startTime: Time, timeConstant: number): this;
            /**
                * Sets an array of arbitrary parameter values starting at the given time
                * for the given duration.
                *
                * @param values
                * @param startTime
                * @param duration
                * @param scaling If the values in the curve should be scaled by some value
                * @example
                * return Tone.Offline(() => {
                * 	const signal = new Tone.Signal(1).toDestination();
                * 	signal.setValueCurveAtTime([1, 0.2, 0.8, 0.1, 0], 0.2, 0.3);
                * }, 0.5, 1);
                */
            abstract setValueCurveAtTime(values: UnitMap[TypeName][], startTime: Time, duration: Time, scaling?: number): this;
            /**
                * Cancels all scheduled parameter changes with times greater than or
                * equal to startTime.
                * @example
                * return Tone.Offline(() => {
                * 	const signal = new Tone.Signal(0).toDestination();
                * 	signal.setValueAtTime(0.1, 0.1);
                * 	signal.setValueAtTime(0.2, 0.2);
                * 	signal.setValueAtTime(0.3, 0.3);
                * 	signal.setValueAtTime(0.4, 0.4);
                * 	// cancels the last two scheduled changes
                * 	signal.cancelScheduledValues(0.3);
                * }, 0.5, 1);
                */
            abstract cancelScheduledValues(time: Time): this;
            /**
                * This is similar to {@link cancelScheduledValues} except
                * it holds the automated value at time until the next automated event.
                * @example
                * return Tone.Offline(() => {
                * 	const signal = new Tone.Signal(0).toDestination();
                * 	signal.linearRampTo(1, 0.5, 0);
                * 	signal.cancelAndHoldAtTime(0.3);
                * }, 0.5, 1);
                */
            abstract cancelAndHoldAtTime(time: Time): this;
            /**
                * Ramps to the given value over the duration of the rampTime.
                * Automatically selects the best ramp type (exponential or linear)
                * depending on the `units` of the signal
                *
                * @param  value
                * @param  rampTime The time that it takes the value to ramp from it's current value
                * @param startTime When the ramp should start.
                * @example
                * const osc = new Tone.Oscillator().toDestination().start();
                * // schedule it to ramp either linearly or exponentially depending on the units
                * osc.frequency.rampTo("A2", 10);
                * @example
                * const osc = new Tone.Oscillator().toDestination().start();
                * // schedule it to ramp starting at a specific time
                * osc.frequency.rampTo("A2", 10, "+2");
                */
            abstract rampTo(value: UnitMap[TypeName], rampTime: Time, startTime?: Time): this;
            /**
                * The current value of the parameter. Setting this value
                * is equivalent to setValueAtTime(value, context.currentTime)
                */
            abstract value: UnitMap[TypeName];
            /**
                * If the value should be converted or not
                */
            abstract convert: boolean;
            /**
                * The unit type
                */
            abstract readonly units: UnitName;
            /**
                * True if the signal value is being overridden by
                * a connected signal. Internal use only.
                */
            abstract overridden: boolean;
            /**
                * The minimum value of the output given the units
                */
            abstract readonly minValue: number;
            /**
                * The maximum value of the output given the units
                */
            abstract readonly maxValue: number;
    }
}

declare module 'tone/signal/ToneConstantSource' {
    import { Param } from "tone/core/context/Param";
    import { Seconds, Time, UnitMap, UnitName } from "tone/core/type/Units";
    import { OneShotSource, OneShotSourceOptions } from "tone/source/OneShotSource";
    export interface ToneConstantSourceOptions<TypeName extends UnitName> extends OneShotSourceOptions {
            convert: boolean;
            offset: UnitMap[TypeName];
            units: TypeName;
            minValue?: number;
            maxValue?: number;
    }
    /**
        * Wrapper around the native fire-and-forget ConstantSource.
        * Adds the ability to reschedule the stop method.
        * @category Signal
        */
    export class ToneConstantSource<TypeName extends UnitName = "number"> extends OneShotSource<ToneConstantSourceOptions<TypeName>> {
            readonly name: string;
            /**
                * The offset of the signal generator
                */
            readonly offset: Param<TypeName>;
            /**
                * @param  offset   The offset value
                */
            constructor(offset: UnitMap[TypeName]);
            constructor(options?: Partial<ToneConstantSourceOptions<TypeName>>);
            static getDefaults(): ToneConstantSourceOptions<any>;
            /**
                * Start the source node at the given time
                * @param  time When to start the source
                */
            start(time?: Time): this;
            protected _stopSource(time?: Seconds): void;
            dispose(): this;
    }
}

declare module 'tone/core/util/Interface' {
    export type Omit<T, K extends keyof T> = Pick<T, Exclude<keyof T, K>>;
    /**
        * Make the property not writable using `defineProperty`. Internal use only.
        */
    export function readOnly(target: object, property: string | string[]): void;
    /**
        * Make an attribute writeable. Internal use only.
        */
    export function writable(target: object, property: string | string[]): void;
    export const noOp: (...args: any[]) => any;
    /**
        * Recursive Partial taken from here: https://stackoverflow.com/a/51365037
        */
    export type RecursivePartial<T> = {
            [P in keyof T]?: T[P] extends Array<infer U> ? Array<RecursivePartial<U>> : T[P] extends object ? RecursivePartial<T[P]> : T[P];
    };
}

declare module 'tone/core/clock/TickSignal' {
    import { Signal, SignalOptions } from "tone/signal/Signal";
    import { InputNode } from "tone/core/context/ToneAudioNode";
    import { Seconds, Ticks, Time, UnitMap, UnitName } from "tone/core/type/Units";
    import { TickParam } from "tone/core/clock/TickParam";
    interface TickSignalOptions<TypeName extends UnitName> extends SignalOptions<TypeName> {
            value: UnitMap[TypeName];
            multiplier: number;
    }
    /**
        * TickSignal extends Tone.Signal, but adds the capability
        * to calculate the number of elapsed ticks. exponential and target curves
        * are approximated with multiple linear ramps.
        *
        * Thank you Bruno Dias, H. Sofia Pinto, and David M. Matos,
        * for your [WAC paper](https://smartech.gatech.edu/bitstream/handle/1853/54588/WAC2016-49.pdf)
        * describing integrating timing functions for tempo calculations.
        */
    export class TickSignal<TypeName extends "hertz" | "bpm"> extends Signal<TypeName> {
            readonly name: string;
            /**
                * The param which controls the output signal value
                */
            protected _param: TickParam<TypeName>;
            readonly input: InputNode;
            /**
                * @param value The initial value of the signal
                */
            constructor(value?: UnitMap[TypeName]);
            constructor(options: Partial<TickSignalOptions<TypeName>>);
            static getDefaults(): TickSignalOptions<any>;
            ticksToTime(ticks: Ticks, when: Time): Seconds;
            timeToTicks(duration: Time, when: Time): Ticks;
            getTimeOfTick(tick: Ticks): Seconds;
            getDurationOfTicks(ticks: Ticks, time: Time): Seconds;
            getTicksAtTime(time: Time): Ticks;
            /**
                * A multiplier on the bpm value. Useful for setting a PPQ relative to the base frequency value.
                */
            get multiplier(): number;
            set multiplier(m: number);
            dispose(): this;
    }
    export {};
}

declare module 'tone/core/clock/Ticker' {
    import { Seconds } from "tone/core/type/Units";
    export type TickerClockSource = "worker" | "timeout" | "offline";
    /**
        * A class which provides a reliable callback using either
        * a Web Worker, or if that isn't supported, falls back to setTimeout.
        */
    export class Ticker {
            constructor(callback: () => void, type: TickerClockSource, updateInterval: Seconds, contextSampleRate?: number);
            /**
                * The rate in seconds the ticker will update
                */
            get updateInterval(): Seconds;
            set updateInterval(interval: Seconds);
            /**
                * The type of the ticker, either a worker or a timeout
                */
            get type(): TickerClockSource;
            set type(type: TickerClockSource);
            /**
                * Clean up
                */
            dispose(): void;
    }
}

declare module 'tone/source/Source' {
    import "../core/context/Destination";
    import "../core/clock/Transport";
    import { Param } from "tone/core/context/Param";
    import { OutputNode, ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { Decibels, Seconds, Time } from "tone/core/type/Units";
    import { BasicPlaybackState, StateTimeline } from "tone/core/util/StateTimeline";
    type onStopCallback = (source: Source<any>) => void;
    export interface SourceOptions extends ToneAudioNodeOptions {
            volume: Decibels;
            mute: boolean;
            onstop: onStopCallback;
    }
    /**
        * Base class for sources.
        * start/stop of this.context.transport.
        *
        * ```
        * // Multiple state change events can be chained together,
        * // but must be set in the correct order and with ascending times
        * // OK
        * state.start().stop("+0.2");
        * // OK
        * state.start().stop("+0.2").start("+0.4").stop("+0.7")
        * // BAD
        * state.stop("+0.2").start();
        * // BAD
        * state.start("+0.3").stop("+0.2");
        * ```
        */
    export abstract class Source<Options extends SourceOptions> extends ToneAudioNode<Options> {
            /**
                * The output node
                */
            output: OutputNode;
            /**
                * Sources have no inputs
                */
            input: undefined;
            /**
                * The volume of the output in decibels.
                * @example
                * const source = new Tone.PWMOscillator().toDestination();
                * source.volume.value = -6;
                */
            volume: Param<"decibels">;
            /**
                * The callback to invoke when the source is stopped.
                */
            onstop: onStopCallback;
            /**
                * Keep track of the scheduled state.
                */
            protected _state: StateTimeline<{
                    duration?: Seconds;
                    offset?: Seconds;
                    /**
                        * Either the buffer is explicitly scheduled to end using the stop method,
                        * or it's implicitly ended when the buffer is over.
                        */
                    implicitEnd?: boolean;
            }>;
            /**
                * The synced `start` callback function from the transport
                */
            protected _synced: boolean;
            constructor(options: SourceOptions);
            static getDefaults(): SourceOptions;
            /**
                * Returns the playback state of the source, either "started" or "stopped".
                * @example
                * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/ahntone_c3.mp3", () => {
                * 	player.start();
                * 	console.log(player.state);
                * }).toDestination();
                */
            get state(): BasicPlaybackState;
            /**
                * Mute the output.
                * @example
                * const osc = new Tone.Oscillator().toDestination().start();
                * // mute the output
                * osc.mute = true;
                */
            get mute(): boolean;
            set mute(mute: boolean);
            protected abstract _start(time: Time, offset?: Time, duration?: Time): void;
            protected abstract _stop(time: Time): void;
            protected abstract _restart(time: Seconds, offset?: Time, duration?: Time): void;
            /**
                * Start the source at the specified time. If no time is given,
                * start the source now.
                * @param  time When the source should be started.
                * @example
                * const source = new Tone.Oscillator().toDestination();
                * source.start("+0.5"); // starts the source 0.5 seconds from now
                */
            start(time?: Time, offset?: Time, duration?: Time): this;
            /**
                * Stop the source at the specified time. If no time is given,
                * stop the source now.
                * @param  time When the source should be stopped.
                * @example
                * const source = new Tone.Oscillator().toDestination();
                * source.start();
                * source.stop("+0.5"); // stops the source 0.5 seconds from now
                */
            stop(time?: Time): this;
            /**
                * Restart the source.
                */
            restart(time?: Time, offset?: Time, duration?: Time): this;
            /**
                * Sync the source to the Transport so that all subsequent
                * calls to `start` and `stop` are synced to the TransportTime
                * instead of the AudioContext time.
                *
                * @example
                * const osc = new Tone.Oscillator().toDestination();
                * // sync the source so that it plays between 0 and 0.3 on the Transport's timeline
                * osc.sync().start(0).stop(0.3);
                * // start the transport.
                * Tone.Transport.start();
                * // set it to loop once a second
                * Tone.Transport.loop = true;
                * Tone.Transport.loopEnd = 1;
                */
            sync(): this;
            /**
                * Unsync the source to the Transport.
                * @see {@link sync}
                */
            unsync(): this;
            /**
                * Clean up.
                */
            dispose(): this;
    }
    export {};
}

declare module 'tone/source/oscillator/OscillatorInterface' {
    import { AudioRange, Cents, Degrees, Frequency, Positive } from "tone/core/type/Units";
    import { Omit } from "tone/core/util/Interface";
    import { Signal } from "tone/signal/Signal";
    import { SourceOptions } from "tone/source/Source";
    /**
        * The common interface of all Oscillators
        */
    export interface ToneOscillatorInterface {
            /**
                * The oscillator type without the partialsCount appended to the end
                * @example
                * const osc = new Tone.Oscillator();
                * osc.type = "sine2";
                * console.log(osc.baseType); // "sine"
                */
            baseType: OscillatorType | "pulse" | "pwm";
            /**
                * The oscillator's type. Also capable of setting the first x number of partials of the oscillator.
                * For example: "sine4" would set be the first 4 partials of the sine wave and "triangle8" would
                * set the first 8 partials of the triangle wave.
                * @example
                * return Tone.Offline(() => {
                * 	const osc = new Tone.Oscillator().toDestination().start();
                * 	osc.type = "sine2";
                * }, 0.1, 1);
                */
            type: ExtendedToneOscillatorType;
            /**
                * The frequency value of the oscillator
                * @example
                * const osc = new Tone.FMOscillator("Bb4").toDestination().start();
                * osc.frequency.rampTo("D2", 3);
                */
            readonly frequency: Signal<"frequency">;
            /**
                * The detune value in cents (100th of a semitone).
                * @example
                * const osc = new Tone.PulseOscillator("F3").toDestination().start();
                * // pitch it 1 octave = 12 semitones = 1200 cents
                * osc.detune.setValueAtTime(-1200, Tone.now());
                * osc.detune.setValueAtTime(1200, Tone.now() + 0.5);
                * osc.detune.linearRampToValueAtTime(0, Tone.now() + 1);
                * osc.stop(Tone.now() + 1.5);
                */
            readonly detune: Signal<"cents">;
            /**
                * The phase is the starting position within the oscillator's cycle. For example
                * a phase of 180 would start halfway through the oscillator's cycle.
                * @example
                * return Tone.Offline(() => {
                * 	const osc = new Tone.Oscillator({
                * 		frequency: 20,
                * 		phase: 90
                * 	}).toDestination().start();
                * }, 0.1, 1);
                */
            phase: Degrees;
            /**
                * The partials describes the relative amplitude of each of the harmonics of the oscillator.
                * The first value in the array is the first harmonic (i.e. the fundamental frequency), the
                * second harmonic is an octave up, the third harmonic is an octave and a fifth, etc. The resulting
                * oscillator output is composed of a sine tone at the relative amplitude at each of the harmonic intervals.
                *
                * Setting this value will automatically set the type to "custom".
                * The value is an empty array when the type is not "custom".
                * @example
                * const osc = new Tone.Oscillator("F3").toDestination().start();
                * setInterval(() => {
                * 	// generate 8 random partials
                * 	osc.partials = new Array(8).fill(0).map(() => Math.random());
                * }, 1000);
                */
            partials: number[];
            /**
                * 'partialCount' offers an alternative way to set the number of used partials.
                * When partialCount is 0, the maximum number of partials are used when representing
                * the waveform using the periodicWave. When 'partials' is set, this value is
                * not settable, but equals the length of the partials array. A square wave wave
                * is composed of only odd harmonics up through the harmonic series. Partial count
                * can limit the number of harmonics which are used to generate the waveform.
                * @example
                * const osc = new Tone.Oscillator("C3", "square").toDestination().start();
                * osc.partialCount = 1;
                * setInterval(() => {
                * 	osc.partialCount++;
                * 	console.log(osc.partialCount);
                * }, 500);
                */
            partialCount?: number;
            /**
                * Returns an array of values which represents the waveform.
                * @param length The length of the waveform to return
                */
            asArray(length: number): Promise<Float32Array>;
    }
    /**
        * Render a segment of the oscillator to an offline context and return the results as an array
        */
    export function generateWaveform(instance: any, length: number): Promise<Float32Array>;
    /**
        * The supported number of partials
        */
    type PartialsRange = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 | 16 | 17 | 18 | 19 | 20 | 21 | 22 | 23 | 24 | 25 | 26 | 27 | 28 | 29 | 30 | 31 | 32;
    /**
        * Oscillators with partials
        */
    type SineWithPartials = `sine${PartialsRange}`;
    type SquareWithPartials = `square${PartialsRange}`;
    type SawtoothWithPartials = `sawtooth${PartialsRange}`;
    type TriangleWithPartials = `triangle${PartialsRange}`;
    type TypeWithPartials = SineWithPartials | SquareWithPartials | TriangleWithPartials | SawtoothWithPartials;
    interface BaseOscillatorOptions extends SourceOptions {
            frequency: Frequency;
            detune: Cents;
            phase: Degrees;
    }
    export type NonCustomOscillatorType = Exclude<OscillatorType, "custom">;
    type AllNonCustomOscillatorType = NonCustomOscillatorType | TypeWithPartials;
    export type ToneOscillatorType = AllNonCustomOscillatorType | "custom";
    export type ExtendedToneOscillatorType = ToneOscillatorType | "pwm" | "pulse";
    /**
        * Oscillator Interfaces
        */
    interface ToneCustomOscillatorOptions extends BaseOscillatorOptions {
            type: "custom";
            partials: number[];
    }
    interface ToneTypeOscillatorOptions extends BaseOscillatorOptions {
            type: NonCustomOscillatorType;
            partialCount?: number;
    }
    interface TonePartialOscillatorOptions extends BaseOscillatorOptions {
            type: TypeWithPartials;
    }
    export type ToneOscillatorConstructorOptions = ToneCustomOscillatorOptions | ToneTypeOscillatorOptions | TonePartialOscillatorOptions;
    export interface ToneOscillatorOptions extends BaseOscillatorOptions {
            type: ToneOscillatorType;
            partialCount: number;
            partials: number[];
    }
    /**
        * FMOscillator Interface
        */
    interface FMBaseOscillatorOptions extends BaseOscillatorOptions {
            harmonicity: Positive;
            modulationIndex: Positive;
            modulationType: AllNonCustomOscillatorType;
    }
    interface FMCustomOscillatorOptions extends FMBaseOscillatorOptions {
            type: "custom";
            partials: number[];
    }
    interface FMTypeOscillatorOptions extends FMBaseOscillatorOptions {
            type: NonCustomOscillatorType;
            partialsCount?: number;
    }
    interface FMPartialsOscillatorOptions extends FMBaseOscillatorOptions {
            type: TypeWithPartials;
    }
    export type FMConstructorOptions = FMTypeOscillatorOptions | FMCustomOscillatorOptions | FMPartialsOscillatorOptions;
    export interface FMOscillatorOptions extends ToneOscillatorOptions {
            harmonicity: Positive;
            modulationIndex: Positive;
            modulationType: AllNonCustomOscillatorType;
    }
    /**
        * AMOscillator Interface
        */
    interface AMBaseOscillatorOptions extends BaseOscillatorOptions {
            harmonicity: Positive;
            modulationType: AllNonCustomOscillatorType;
    }
    interface AMCustomOscillatorOptions extends AMBaseOscillatorOptions {
            type: "custom";
            partials: number[];
    }
    interface AMTypeOscillatorOptions extends AMBaseOscillatorOptions {
            type: NonCustomOscillatorType;
            partialsCount?: number;
    }
    interface AMPartialsOscillatorOptions extends AMBaseOscillatorOptions {
            type: TypeWithPartials;
    }
    export type AMConstructorOptions = AMCustomOscillatorOptions | AMTypeOscillatorOptions | AMPartialsOscillatorOptions;
    export interface AMOscillatorOptions extends ToneOscillatorOptions {
            harmonicity: Positive;
            modulationType: AllNonCustomOscillatorType;
    }
    /**
        * FatOscillator
        */
    interface FatBaseOscillatorOptions extends BaseOscillatorOptions {
            spread: Cents;
            count: Positive;
    }
    interface FatCustomOscillatorOptions extends FatBaseOscillatorOptions {
            type: "custom";
            partials: number[];
    }
    interface FatTypeOscillatorOptions extends FatBaseOscillatorOptions {
            type: NonCustomOscillatorType;
            partialCount?: number;
    }
    interface FatPartialsOscillatorOptions extends FatBaseOscillatorOptions {
            type: TypeWithPartials;
    }
    export type FatConstructorOptions = FatCustomOscillatorOptions | FatTypeOscillatorOptions | FatPartialsOscillatorOptions;
    export interface FatOscillatorOptions extends ToneOscillatorOptions {
            spread: Cents;
            count: Positive;
    }
    /**
        * Pulse Oscillator
        */
    export interface PulseOscillatorOptions extends BaseOscillatorOptions {
            type: "pulse";
            width: AudioRange;
    }
    /**
        * PWM Oscillator
        */
    export interface PWMOscillatorOptions extends BaseOscillatorOptions {
            type: "pwm";
            modulationFrequency: Frequency;
    }
    /**
        * FM Oscillators with partials
        */
    type FMSineWithPartials = `fmsine${PartialsRange}`;
    type FMSquareWithPartials = `fmsquare${PartialsRange}`;
    type FMSawtoothWithPartials = `fmsawtooth${PartialsRange}`;
    type FMTriangleWithPartials = `fmtriangle${PartialsRange}`;
    type FMTypeWithPartials = FMSineWithPartials | FMSquareWithPartials | FMSawtoothWithPartials | FMTriangleWithPartials;
    /**
        * AM Oscillators with partials
        */
    type AMSineWithPartials = `amsine${PartialsRange}`;
    type AMSquareWithPartials = `amsquare${PartialsRange}`;
    type AMSawtoothWithPartials = `amsawtooth${PartialsRange}`;
    type AMTriangleWithPartials = `amtriangle${PartialsRange}`;
    type AMTypeWithPartials = AMSineWithPartials | AMSquareWithPartials | AMSawtoothWithPartials | AMTriangleWithPartials;
    /**
        * Fat Oscillators with partials
        */
    type FatSineWithPartials = `fatsine${PartialsRange}`;
    type FatSquareWithPartials = `fatsquare${PartialsRange}`;
    type FatSawtoothWithPartials = `fatsawtooth${PartialsRange}`;
    type FatTriangleWithPartials = `fattriangle${PartialsRange}`;
    type FatTypeWithPartials = FatSineWithPartials | FatSquareWithPartials | FatSawtoothWithPartials | FatTriangleWithPartials;
    /**
        * Omni FM
        */
    interface OmniFMCustomOscillatorOptions extends FMBaseOscillatorOptions {
            type: "fmcustom";
            partials: number[];
    }
    interface OmniFMTypeOscillatorOptions extends FMBaseOscillatorOptions {
            type: "fmsine" | "fmsquare" | "fmsawtooth" | "fmtriangle";
            partialsCount?: number;
    }
    interface OmniFMPartialsOscillatorOptions extends FMBaseOscillatorOptions {
            type: FMTypeWithPartials;
    }
    /**
        * Omni AM
        */
    interface OmniAMCustomOscillatorOptions extends AMBaseOscillatorOptions {
            type: "amcustom";
            partials: number[];
    }
    interface OmniAMTypeOscillatorOptions extends AMBaseOscillatorOptions {
            type: "amsine" | "amsquare" | "amsawtooth" | "amtriangle";
            partialsCount?: number;
    }
    interface OmniAMPartialsOscillatorOptions extends AMBaseOscillatorOptions {
            type: AMTypeWithPartials;
    }
    /**
        * Omni Fat
        */
    interface OmniFatCustomOscillatorOptions extends FatBaseOscillatorOptions {
            type: "fatcustom";
            partials: number[];
    }
    interface OmniFatTypeOscillatorOptions extends FatBaseOscillatorOptions {
            type: "fatsine" | "fatsquare" | "fatsawtooth" | "fattriangle";
            partialsCount?: number;
    }
    interface OmniFatPartialsOscillatorOptions extends FatBaseOscillatorOptions {
            type: FatTypeWithPartials;
    }
    export type OmniOscillatorType = "fatsine" | "fatsquare" | "fatsawtooth" | "fattriangle" | "fatcustom" | FatTypeWithPartials | "fmsine" | "fmsquare" | "fmsawtooth" | "fmtriangle" | "fmcustom" | FMTypeWithPartials | "amsine" | "amsquare" | "amsawtooth" | "amtriangle" | "amcustom" | AMTypeWithPartials | TypeWithPartials | OscillatorType | "pulse" | "pwm";
    export type OmniOscillatorOptions = PulseOscillatorOptions | PWMOscillatorOptions | OmniFatCustomOscillatorOptions | OmniFatTypeOscillatorOptions | OmniFatPartialsOscillatorOptions | OmniFMCustomOscillatorOptions | OmniFMTypeOscillatorOptions | OmniFMPartialsOscillatorOptions | OmniAMCustomOscillatorOptions | OmniAMTypeOscillatorOptions | OmniAMPartialsOscillatorOptions | ToneOscillatorConstructorOptions;
    type OmitSourceOptions<T extends BaseOscillatorOptions> = Omit<T, "frequency" | "detune" | "context">;
    /**
        * The settable options for the omni oscillator inside of the source which excludes certain attributes that are defined by the parent class
        */
    export type OmniOscillatorSynthOptions = OmitSourceOptions<PulseOscillatorOptions> | OmitSourceOptions<PWMOscillatorOptions> | OmitSourceOptions<OmniFatCustomOscillatorOptions> | OmitSourceOptions<OmniFatTypeOscillatorOptions> | OmitSourceOptions<OmniFatPartialsOscillatorOptions> | OmitSourceOptions<OmniFMCustomOscillatorOptions> | OmitSourceOptions<OmniFMTypeOscillatorOptions> | OmitSourceOptions<OmniFMPartialsOscillatorOptions> | OmitSourceOptions<OmniAMCustomOscillatorOptions> | OmitSourceOptions<OmniAMTypeOscillatorOptions> | OmitSourceOptions<OmniAMPartialsOscillatorOptions> | OmitSourceOptions<ToneCustomOscillatorOptions> | OmitSourceOptions<ToneTypeOscillatorOptions> | OmitSourceOptions<TonePartialOscillatorOptions>;
    export {};
}

declare module 'tone/signal/SignalOperator' {
    import { InputNode, ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    export type SignalOperatorOptions = ToneAudioNodeOptions;
    /**
      * A signal operator has an input and output and modifies the signal.
      */
    export abstract class SignalOperator<Options extends SignalOperatorOptions> extends ToneAudioNode<Options> {
        constructor(options?: Partial<Options>);
        connect(destination: InputNode, outputNum?: number, inputNum?: number): this;
    }
}

declare module 'tone/instrument/ModulationSynth' {
    import { Signal } from "tone/signal/Signal";
    import { Multiply } from "tone/signal/Multiply";
    import { Gain } from "tone/core/context/Gain";
    import { NormalRange, Positive, Seconds, Time } from "tone/core/type/Units";
    import { EnvelopeOptions } from "tone/component/envelope/Envelope";
    import { ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { Monophonic } from "tone/instrument/Monophonic";
    import { OmniOscillator } from "tone/source/oscillator/OmniOscillator";
    import { OmniOscillatorSynthOptions } from "tone/source/oscillator/OscillatorInterface";
    import { Synth, SynthOptions } from "tone/instrument/Synth";
    import { AmplitudeEnvelope } from "tone/component/envelope/AmplitudeEnvelope";
    import { RecursivePartial } from "tone/core/util/Interface";
    export interface ModulationSynthOptions extends SynthOptions {
            harmonicity: Positive;
            modulationEnvelope: Omit<EnvelopeOptions, keyof ToneAudioNodeOptions>;
            modulation: OmniOscillatorSynthOptions;
    }
    /**
        * Base class for both AM and FM synths
        */
    export abstract class ModulationSynth<Options extends ModulationSynthOptions> extends Monophonic<Options> {
            readonly name: string;
            /**
                * The carrier voice.
                */
            protected _carrier: Synth;
            /**
                * The modulator voice.
                */
            protected _modulator: Synth;
            /**
                * The carrier's oscillator
                */
            readonly oscillator: OmniOscillator<any>;
            /**
                * The carrier's envelope
                */
            readonly envelope: AmplitudeEnvelope;
            /**
                * The modulator's oscillator which is applied to the amplitude of the oscillator
                */
            readonly modulation: OmniOscillator<any>;
            /**
                * The modulator's envelope
                */
            readonly modulationEnvelope: AmplitudeEnvelope;
            /**
                * The frequency control
                */
            readonly frequency: Signal<"frequency">;
            /**
                * The detune in cents
                */
            readonly detune: Signal<"cents">;
            /**
                * Harmonicity is the ratio between the two voices. A harmonicity of
                * 1 is no change. Harmonicity = 2 means a change of an octave.
                * @example
                * const amSynth = new Tone.AMSynth().toDestination();
                * // pitch the modulator an octave below oscillator
                * amSynth.harmonicity.value = 0.5;
                * amSynth.triggerAttackRelease("C5", "4n");
                */
            readonly harmonicity: Multiply;
            /**
                * The node where the modulation happens
                */
            protected _modulationNode: Gain;
            constructor(options?: RecursivePartial<ModulationSynthOptions>);
            static getDefaults(): ModulationSynthOptions;
            /**
                * Trigger the attack portion of the note
                */
            protected _triggerEnvelopeAttack(time: Seconds, velocity: number): void;
            /**
                * Trigger the release portion of the note
                */
            protected _triggerEnvelopeRelease(time: Seconds): this;
            getLevelAtTime(time: Time): NormalRange;
            dispose(): this;
    }
}

declare module 'tone/instrument/Monophonic' {
    import { FrequencyClass } from "tone/core/type/Frequency";
    import { Cents, Frequency, NormalRange, Seconds, Time } from "tone/core/type/Units";
    import { Instrument, InstrumentOptions } from "tone/instrument/Instrument";
    import { Signal } from "tone/signal/Signal";
    type onSilenceCallback = (instrument: Monophonic<any>) => void;
    export interface MonophonicOptions extends InstrumentOptions {
            portamento: Seconds;
            onsilence: onSilenceCallback;
            detune: Cents;
    }
    /**
        * Abstract base class for other monophonic instruments to extend.
        */
    export abstract class Monophonic<Options extends MonophonicOptions> extends Instrument<Options> {
            /**
                * The glide time between notes.
                */
            portamento: Seconds;
            /**
                * Invoked when the release has finished and the output is silent.
                */
            onsilence: onSilenceCallback;
            /**
                * The instrument's frequency signal.
                */
            abstract readonly frequency: Signal<"frequency">;
            /**
                * The instrument's detune control signal.
                */
            abstract readonly detune: Signal<"cents">;
            constructor(options?: Partial<MonophonicOptions>);
            static getDefaults(): MonophonicOptions;
            /**
                * Trigger the attack of the note optionally with a given velocity.
                * @param  note The note to trigger.
                * @param  time When the note should start.
                * @param  velocity The velocity determines how "loud" the note will be.
                * @example
                * const synth = new Tone.Synth().toDestination();
                * // trigger the note a half second from now at half velocity
                * synth.triggerAttack("C4", "+0.5", 0.5);
                */
            triggerAttack(note: Frequency | FrequencyClass, time?: Time, velocity?: NormalRange): this;
            /**
                * Trigger the release portion of the envelope.
                * @param  time If no time is given, the release happens immediately.
                * @example
                * const synth = new Tone.Synth().toDestination();
                * synth.triggerAttack("C4");
                * // trigger the release a second from now
                * synth.triggerRelease("+1");
                */
            triggerRelease(time?: Time): this;
            /**
                * Internal method which starts the envelope attack
                */
            protected abstract _triggerEnvelopeAttack(time: Seconds, velocity: NormalRange): void;
            /**
                * Internal method which starts the envelope release
                */
            protected abstract _triggerEnvelopeRelease(time: Seconds): void;
            /**
                * Get the level of the output at the given time. Measures
                * the envelope(s) value at the time.
                * @param time The time to query the envelope value
                * @return The output level between 0-1
                */
            abstract getLevelAtTime(time: Time): NormalRange;
            /**
                * Set the note at the given time. If no time is given, the note
                * will set immediately.
                * @param note The note to change to.
                * @param  time The time when the note should be set.
                * @example
                * const synth = new Tone.Synth().toDestination();
                * synth.triggerAttack("C4");
                * // change to F#6 in one quarter note from now.
                * synth.setNote("F#6", "+4n");
                */
            setNote(note: Frequency | FrequencyClass, time?: Time): this;
    }
    export {};
}

declare module 'tone/instrument/Instrument' {
    import { Param } from "tone/core/context/Param";
    import { OutputNode, ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { Decibels, Frequency, NormalRange, Time } from "tone/core/type/Units";
    export interface InstrumentOptions extends ToneAudioNodeOptions {
            volume: Decibels;
    }
    /**
        * Base-class for all instruments
        */
    export abstract class Instrument<Options extends InstrumentOptions> extends ToneAudioNode<Options> {
            output: OutputNode;
            /**
                * The instrument only has an output
                */
            input: undefined;
            /**
                * The volume of the output in decibels.
                * @example
                * const amSynth = new Tone.AMSynth().toDestination();
                * amSynth.volume.value = -6;
                * amSynth.triggerAttackRelease("G#3", 0.2);
                */
            volume: Param<"decibels">;
            constructor(options?: Partial<InstrumentOptions>);
            static getDefaults(): InstrumentOptions;
            /**
                * Sync the instrument to the Transport. All subsequent calls of
                * {@link triggerAttack} and {@link triggerRelease} will be scheduled along the transport.
                * @example
                * const fmSynth = new Tone.FMSynth().toDestination();
                * fmSynth.volume.value = -6;
                * fmSynth.sync();
                * // schedule 3 notes when the transport first starts
                * fmSynth.triggerAttackRelease("C4", "8n", 0);
                * fmSynth.triggerAttackRelease("E4", "8n", "8n");
                * fmSynth.triggerAttackRelease("G4", "8n", "4n");
                * // start the transport to hear the notes
                * Tone.Transport.start();
                */
            sync(): this;
            /**
                * set _sync
                */
            protected _syncState(): boolean;
            /**
                * Wrap the given method so that it can be synchronized
                * @param method Which method to wrap and sync
                * @param  timePosition What position the time argument appears in
                */
            protected _syncMethod(method: string, timePosition: number): void;
            /**
                * Unsync the instrument from the Transport
                */
            unsync(): this;
            /**
                * Trigger the attack and then the release after the duration.
                * @param  note     The note to trigger.
                * @param  duration How long the note should be held for before
                *                         triggering the release. This value must be greater than 0.
                * @param time  When the note should be triggered.
                * @param  velocity The velocity the note should be triggered at.
                * @example
                * const synth = new Tone.Synth().toDestination();
                * // trigger "C4" for the duration of an 8th note
                * synth.triggerAttackRelease("C4", "8n");
                */
            triggerAttackRelease(note: Frequency, duration: Time, time?: Time, velocity?: NormalRange): this;
            /**
                * Start the instrument's note.
                * @param note the note to trigger
                * @param time the time to trigger the note
                * @param velocity the velocity to trigger the note (between 0-1)
                */
            abstract triggerAttack(note: Frequency, time?: Time, velocity?: NormalRange): this;
            /**
                * Trigger the release phase of the current note.
                * @param time when to trigger the release
                */
            abstract triggerRelease(...args: any[]): this;
            /**
                * The release which is scheduled to the timeline.
                */
            protected _syncedRelease: (time: number) => this;
            /**
                * clean up
                * @returns {Instrument} this
                */
            dispose(): this;
    }
}

declare module 'tone/event/PatternGenerator' {
    /**
        * The name of the patterns
        */
    export type PatternName = "up" | "down" | "upDown" | "downUp" | "alternateUp" | "alternateDown" | "random" | "randomOnce" | "randomWalk";
    /**
        * PatternGenerator returns a generator which will yield numbers between 0 and numValues
        * according to the passed in pattern that can be used as indexes into an array of size numValues.
        * @param numValues The size of the array to emit indexes for
        * @param pattern The name of the pattern use when iterating over
        * @param index Where to start in the offset of the values array
        */
    export function PatternGenerator(numValues: number, pattern?: PatternName, index?: number): Iterator<number>;
}

declare module 'tone/effect/LFOEffect' {
    import { Effect, EffectOptions } from "tone/effect/Effect";
    import { Frequency, NormalRange, Time } from "tone/core/type/Units";
    import { LFO } from "tone/source/oscillator/LFO";
    import { ToneOscillatorType } from "tone/source/oscillator/OscillatorInterface";
    import { Signal } from "tone/signal/Signal";
    import { Param } from "tone/core/context/Param";
    export interface LFOEffectOptions extends EffectOptions {
            frequency: Frequency;
            type: ToneOscillatorType;
            depth: NormalRange;
    }
    /**
        * Base class for LFO-based effects.
        */
    export abstract class LFOEffect<Options extends LFOEffectOptions> extends Effect<Options> {
            readonly name: string;
            /**
                * the lfo which drives the filter cutoff
                */
            protected _lfo: LFO;
            /**
                * The range of the filter modulating between the min and max frequency.
                * 0 = no modulation. 1 = full modulation.
                */
            readonly depth: Param<"normalRange">;
            /**
                * How fast the filter modulates between min and max.
                */
            readonly frequency: Signal<"frequency">;
            constructor(options: LFOEffectOptions);
            static getDefaults(): LFOEffectOptions;
            /**
                * Start the effect.
                */
            start(time?: Time): this;
            /**
                * Stop the lfo
                */
            stop(time?: Time): this;
            /**
                * Sync the filter to the transport.
                * @see {@link LFO.sync}
                */
            sync(): this;
            /**
                * Unsync the filter from the transport.
                */
            unsync(): this;
            /**
                * The type of the LFO's oscillator.
                * @see {@link Oscillator.type}
                * @example
                * const autoFilter = new Tone.AutoFilter().start().toDestination();
                * const noise = new Tone.Noise().start().connect(autoFilter);
                * autoFilter.type = "square";
                */
            get type(): ToneOscillatorType;
            set type(type: ToneOscillatorType);
            dispose(): this;
    }
}

declare module 'tone/effect/Effect' {
    import { CrossFade } from "tone/component/channel/CrossFade";
    import { Gain } from "tone/core/context/Gain";
    import { ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { NormalRange } from "tone/core/type/Units";
    import { Signal } from "tone/signal/Signal";
    export interface EffectOptions extends ToneAudioNodeOptions {
            wet: NormalRange;
    }
    /**
        * Effect is the base class for effects. Connect the effect between
        * the effectSend and effectReturn GainNodes, then control the amount of
        * effect which goes to the output using the wet control.
        */
    export abstract class Effect<Options extends EffectOptions> extends ToneAudioNode<Options> {
            readonly name: string;
            /**
                * The wet control is how much of the effected
                * will pass through to the output. 1 = 100% effected
                * signal, 0 = 100% dry signal.
                */
            wet: Signal<"normalRange">;
            /**
                * connect the effectSend to the input of hte effect
                */
            protected effectSend: Gain;
            /**
                * connect the output of the effect to the effectReturn
                */
            protected effectReturn: Gain;
            /**
                * The effect input node
                */
            input: Gain;
            /**
                * The effect output
                */
            output: CrossFade;
            constructor(options: EffectOptions);
            static getDefaults(): EffectOptions;
            /**
                * chains the effect in between the effectSend and effectReturn
                */
            protected connectEffect(effect: ToneAudioNode | AudioNode): this;
            dispose(): this;
    }
}

declare module 'tone/core/worklet/ToneAudioWorklet' {
    import { ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    export type ToneAudioWorkletOptions = ToneAudioNodeOptions;
    export abstract class ToneAudioWorklet<Options extends ToneAudioWorkletOptions> extends ToneAudioNode<Options> {
            readonly name: string;
            /**
                * The processing node
                */
            protected _worklet: AudioWorkletNode;
            /**
                * A dummy audio param to use when creating Params
                */
            protected _dummyParam: AudioParam;
            /**
                * The constructor options for the node
                */
            protected workletOptions: Partial<AudioWorkletNodeOptions>;
            /**
                * Get the name of the audio worklet
                */
            protected abstract _audioWorkletName(): string;
            /**
                * Invoked when the module is loaded and the node is created
                */
            protected abstract onReady(node: AudioWorkletNode): void;
            /**
                * Callback which is invoked when there is an error in the processing
                */
            onprocessorerror: (e: string) => void;
            constructor(options: Options);
            dispose(): this;
    }
}

declare module 'tone/effect/StereoFeedbackEffect' {
    import { StereoEffect, StereoEffectOptions } from "tone/effect/StereoEffect";
    import { NormalRange } from "tone/core/type/Units";
    import { Signal } from "tone/signal/Signal";
    import { Gain } from "tone/core/context/Gain";
    import { Split } from "tone/component/channel/Split";
    import { Merge } from "tone/component/channel/Merge";
    export interface StereoFeedbackEffectOptions extends StereoEffectOptions {
            feedback: NormalRange;
    }
    /**
        * Base class for stereo feedback effects where the effectReturn is fed back into the same channel.
        */
    export class StereoFeedbackEffect<Options extends StereoFeedbackEffectOptions> extends StereoEffect<Options> {
            /**
                * The amount of feedback from the output
                * back into the input of the effect (routed
                * across left and right channels).
                */
            readonly feedback: Signal<"normalRange">;
            /**
                * the left side feedback
                */
            protected _feedbackL: Gain;
            /**
                * the right side feedback
                */
            protected _feedbackR: Gain;
            /**
                * Split the channels for feedback
                */
            protected _feedbackSplit: Split;
            /**
                * Merge the channels for feedback
                */
            protected _feedbackMerge: Merge;
            constructor(options: StereoFeedbackEffectOptions);
            static getDefaults(): StereoFeedbackEffectOptions;
            dispose(): this;
    }
}

declare module 'tone/effect/FeedbackEffect' {
    import { Param } from "tone/core/context/Param";
    import { NormalRange } from "tone/core/type/Units";
    import { Effect, EffectOptions } from "tone/effect/Effect";
    export interface FeedbackEffectOptions extends EffectOptions {
            /**
                * The feedback from the output back to the input
                * ```
                * +---<--------<---+
                * |                |
                * |  +----------+  |
                * +--> feedback +>-+
                *    +----------+
                * ```
                */
            feedback: NormalRange;
    }
    /**
        * FeedbackEffect provides a loop between an audio source and its own output.
        * This is a base-class for feedback effects.
        */
    export abstract class FeedbackEffect<Options extends FeedbackEffectOptions> extends Effect<Options> {
            readonly name: string;
            /**
                * The amount of signal which is fed back into the effect input.
                */
            feedback: Param<"normalRange">;
            constructor(options: FeedbackEffectOptions);
            static getDefaults(): FeedbackEffectOptions;
            dispose(): this;
    }
}

declare module 'tone/effect/StereoEffect' {
    import { EffectOptions } from "tone/effect/Effect";
    import { OutputNode, ToneAudioNode } from "tone/core/context/ToneAudioNode";
    import { CrossFade } from "tone/component/channel/CrossFade";
    import { Signal } from "tone/signal/Signal";
    import { Split } from "tone/component/channel/Split";
    import { Gain } from "tone/core/context/Gain";
    import { Merge } from "tone/component/channel/Merge";
    export type StereoEffectOptions = EffectOptions;
    /**
        * Base class for Stereo effects.
        */
    export class StereoEffect<Options extends StereoEffectOptions> extends ToneAudioNode<Options> {
            readonly name: string;
            readonly input: Gain;
            readonly output: CrossFade;
            /**
                * The wet control, i.e. how much of the effected
                * will pass through to the output.
                */
            readonly wet: Signal<"normalRange">;
            /**
                * Split it
                */
            protected _split: Split;
            /**
                * the stereo effect merger
                */
            protected _merge: Merge;
            constructor(options: StereoEffectOptions);
            /**
                * Connect the left part of the effect
                */
            protected connectEffectLeft(...nodes: OutputNode[]): void;
            /**
                * Connect the right part of the effect
                */
            protected connectEffectRight(...nodes: OutputNode[]): void;
            static getDefaults(): StereoEffectOptions;
            dispose(): this;
    }
}

declare module 'tone/effect/StereoXFeedbackEffect' {
    import { StereoFeedbackEffect, StereoFeedbackEffectOptions } from "tone/effect/StereoFeedbackEffect";
    import { NormalRange } from "tone/core/type/Units";
    export interface StereoXFeedbackEffectOptions extends StereoFeedbackEffectOptions {
        feedback: NormalRange;
    }
    /**
      * Just like a {@link StereoFeedbackEffect}, but the feedback is routed from left to right
      * and right to left instead of on the same channel.
      * ```
      * +--------------------------------+ feedbackL <-----------------------------------+
      * |                                                                                |
      * +-->                          +----->        +---->                          +-----+
      *      feedbackMerge +--> split        (EFFECT)       merge +--> feedbackSplit     | |
      * +-->                          +----->        +---->                          +---+ |
      * |                                                                                  |
      * +--------------------------------+ feedbackR <-------------------------------------+
      * ```
      */
    export class StereoXFeedbackEffect<Options extends StereoXFeedbackEffectOptions> extends StereoFeedbackEffect<Options> {
        constructor(options: StereoXFeedbackEffectOptions);
    }
}

declare module 'tone/effect/MidSideEffect' {
    import { Effect, EffectOptions } from "tone/effect/Effect";
    import { OutputNode, ToneAudioNode } from "tone/core/context/ToneAudioNode";
    export type MidSideEffectOptions = EffectOptions;
    /**
        * Mid/Side processing separates the the 'mid' signal
        * (which comes out of both the left and the right channel)
        * and the 'side' (which only comes out of the the side channels)
        * and effects them separately before being recombined.
        * Applies a Mid/Side seperation and recombination.
        * Algorithm found in [kvraudio forums](http://www.kvraudio.com/forum/viewtopic.php?t=212587).
        * This is a base-class for Mid/Side Effects.
        * @category Effect
        */
    export abstract class MidSideEffect<Options extends MidSideEffectOptions> extends Effect<Options> {
            readonly name: string;
            /**
                * The mid send. Connect to mid processing
                */
            protected _midSend: ToneAudioNode;
            /**
                * The side send. Connect to side processing
                */
            protected _sideSend: ToneAudioNode;
            /**
                * The mid return connection
                */
            protected _midReturn: ToneAudioNode;
            /**
                * The side return connection
                */
            protected _sideReturn: ToneAudioNode;
            constructor(options: MidSideEffectOptions);
            /**
                * Connect the mid chain of the effect
                */
            protected connectEffectMid(...nodes: OutputNode[]): void;
            /**
                * Connect the side chain of the effect
                */
            protected connectEffectSide(...nodes: OutputNode[]): void;
            dispose(): this;
    }
}

declare module 'tone/component/analysis/MeterBase' {
    import { InputNode, OutputNode, ToneAudioNode, ToneAudioNodeOptions } from "tone/core/context/ToneAudioNode";
    import { Analyser } from "tone/component/analysis/Analyser";
    export type MeterBaseOptions = ToneAudioNodeOptions;
    /**
        * The base class for Metering classes.
        */
    export class MeterBase<Options extends MeterBaseOptions> extends ToneAudioNode<Options> {
            readonly name: string;
            /**
                * The signal to be analysed
                */
            input: InputNode;
            /**
                * The output is just a pass through of the input
                */
            output: OutputNode;
            /**
                * The analyser node for the incoming signal
                */
            protected _analyser: Analyser;
            constructor(options?: Partial<MeterBaseOptions>);
            dispose(): this;
    }
}

